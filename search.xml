<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>PIPA-rs 开发手记 (三)：从 strace 开始的正确构建</title>
      <link href="/2025/10/05/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B/%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B/Rust%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B/PIPA-rs%E5%BC%80%E5%8F%91%E6%89%8B%E8%AE%B0/PIPA-rs-%E5%BC%80%E5%8F%91%E6%89%8B%E8%AE%B0-%E4%B8%89-%EF%BC%9A%E4%BB%8E-strace-%E5%BC%80%E5%A7%8B%E7%9A%84%E6%AD%A3%E7%A1%AE%E6%9E%84%E5%BB%BA/"/>
      <url>/2025/10/05/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B/%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B/Rust%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B/PIPA-rs%E5%BC%80%E5%8F%91%E6%89%8B%E8%AE%B0/PIPA-rs-%E5%BC%80%E5%8F%91%E6%89%8B%E8%AE%B0-%E4%B8%89-%EF%BC%9A%E4%BB%8E-strace-%E5%BC%80%E5%A7%8B%E7%9A%84%E6%AD%A3%E7%A1%AE%E6%9E%84%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<p>在上一篇，我们用 <code>crossterm</code> 绘制出了一个专业的 TUI 界面。现在，是时候挑战 PIPA-rs 的真正核心了：实现 <code>pipa-rs stat -- &lt;command&gt;</code>，一个 <code>perf stat</code> 的原生替代品。</p><p>这意味着，我们要直面 <code>perf_event_open</code> 这个系统调用，去精确测量一个外部命令从生到死的完整生命周期。</p><p>前期的探索，虽然没有产生一行可用的代码，但却留下了一份极其宝贵的财富：<strong>一份详尽的“此路不通”的地图。</strong> 它用 <code>ptrace</code> 和信号的失败告诉我们，任何试图在用户态通过复杂技巧来模拟内核级同步的方案，都是在与操作系统的底层调度作对，这是一场注定会失败的战争。</p><p>所以，这次我们不是在收拾烂摊子。我们怀揣着“排除法得来的宝贵知识”，进行了一次目标明确的、从零开始的正确构建。我们的任务，从“发明创造”，转变成了“<strong>探索发现</strong>”。</p><span id="more"></span><h3 id="范式转换：从“猜测”到“观察”"><a href="#范式转换：从“猜测”到“观察”" class="headerlink" title="范式转换：从“猜测”到“观察”"></a>范式转换：从“猜测”到“观察”</h3><p>既然解决方案必然存在于内核的原生能力之中，而 <code>perf</code> 工具已经完美地利用了它，那么问题就变得简单了：我们只需要“窃听” <code>perf</code> 与内核的对话。</p><p><code>strace</code> 成为了我们手中最锋利的解剖刀。我执行了那个改变一切的命令：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ strace -e trace=perf_event_open perf <span class="built_in">stat</span> -- <span class="built_in">ls</span></span><br></pre></td></tr></table></figure><p>输出的信息虽然嘈杂，但我们的目标很明确。很快，我们就有了一系列颠覆性的发现。</p><p><strong>发现一：关于“事件组”的假设是错误的</strong></p><p>我最初以为，<code>perf stat</code> 会创建一个“事件组”来同时监控多个性能事件。但在 <code>strace</code> 的输出中，我们看到 <code>perf</code> 为每一个事件都进行了一次独立的 <code>perf_event_open</code> 调用，并且每一次的 <code>group_fd</code> 参数**始终是 <code>-1</code>**。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">perf_event_open(&#123;..., config=PERF_COUNT_HW_CPU_CYCLES, ...&#125;, ..., group_fd=-1, ...)</span><br><span class="line">perf_event_open(&#123;..., config=PERF_COUNT_HW_INSTRUCTIONS, ...&#125;, ..., group_fd=-1, ...)</span><br></pre></td></tr></table></figure><p>这个证据无可辩驳地证明：<code>perf stat</code> 在这种场景下，根本没有使用事件组。它用的是更简单的东西。</p><p><strong>发现二：内核提供的“全自动”同步魔法</strong></p><p>排除了“组”这个干扰项后，我们的焦点汇聚到了 <code>perf_event_attr</code> 结构体内部。在那里，我们看到了三个之前被忽略的、共同协作的标志位：</p><ul><li><code>inherit = 1</code></li><li><code>disabled = 1</code></li><li><code>enable_on_exec = 1</code></li></ul><p>那一刻，我豁然开朗。我们之前所有关于 <code>ptrace</code> 和 <code>SIGSTOP</code> 的挣扎，都是为了在一个精确的时间点“按下秒表”。而这三个标志，相当于我们直接告诉内核：</p><blockquote><p>“我这里有一堆秒表 (<code>fd</code>)，它们现在是关闭的 (<code>disabled=1</code>)。请把这些秒表遗传给我的所有孩子 (<code>inherit=1</code>)。最关键的是，等到任何一个孩子喊出 <code>execve</code> 的那一刻，<strong>由你来替我按下启动按钮</strong> (<code>enable_on_exec=1</code>)。”</p></blockquote><p>内核，作为唯一的、全知的系统调度者，是唯一能完美执行这个任务的角色。我们之前所有的努力，都是在尝试用业余的手段，去模拟内核与生俱来的能力。</p><h3 id="优雅的重生：将-strace-日志翻译成-Rust-代码"><a href="#优雅的重生：将-strace-日志翻译成-Rust-代码" class="headerlink" title="优雅的重生：将 strace 日志翻译成 Rust 代码"></a>优雅的重生：将 <code>strace</code> 日志翻译成 Rust 代码</h3><p>在掌握了“标准答案”后，<code>raw_perf_events.rs</code> 模块的构建思路变得清晰无比：<strong>精确、无损地复制 <code>perf</code> 的行为</strong>。</p><p>我们彻底废弃了所有与“事件组”相关的复杂逻辑，只设计了一个简单的 <code>Counter</code> 结构体。其核心函数 <code>create_counter_for_command</code> 的实现，就是对 <code>strace</code> 日志的一次忠实“代码翻译”。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// crates/pipa_collector/src/raw_perf_events.rs</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">create_counter_for_command</span>(event: PerfEvent) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;Counter, PipaCollectorError&gt; &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">attrs</span> = sys::bindings::perf_event_attr &#123;</span><br><span class="line">        size: std::mem::size_of::&lt;sys::bindings::perf_event_attr&gt;() <span class="keyword">as</span> <span class="type">u32</span>,</span><br><span class="line">        ..<span class="built_in">Default</span>::<span class="title function_ invoke__">default</span>()</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="comment">// ... 设置 type 和 config ...</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 这里的每一行设置，都是对 strace 输出的直接复刻。</span></span><br><span class="line">    <span class="comment">// 我们不再有任何猜测，只有对证据的忠实转录。</span></span><br><span class="line">    attrs.<span class="title function_ invoke__">set_disabled</span>(<span class="number">1</span>);</span><br><span class="line">    attrs.<span class="title function_ invoke__">set_inherit</span>(<span class="number">1</span>);</span><br><span class="line">    attrs.<span class="title function_ invoke__">set_enable_on_exec</span>(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 参数的选择也完全基于 perf 的行为。</span></span><br><span class="line">    <span class="keyword">let</span> <span class="variable">fd</span> = <span class="keyword">unsafe</span> &#123; sys::<span class="title function_ invoke__">perf_event_open</span>(&amp;<span class="keyword">mut</span> attrs, <span class="number">0</span>, -<span class="number">1</span>, -<span class="number">1</span>, <span class="number">0</span>) &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ... 错误处理和返回 ...</span></span><br><span class="line">    <span class="title function_ invoke__">Ok</span>(Counter &#123; fd &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这段代码的简洁性，与我们之前在“同步地狱”中构想的复杂方案形成了鲜明对比，这本身就是其正确性的最好证明。</p><h3 id="点睛之笔：dup-与健壮性的最后拼图"><a href="#点睛之笔：dup-与健壮性的最后拼图" class="headerlink" title="点睛之笔：dup 与健壮性的最后拼图"></a>点睛之笔：<code>dup</code> 与健壮性的最后拼图</h3><p>在核心功能实现后，我们遇到了最后一个、也是最微妙的一个问题：如何在子进程结束后，安全地从其拥有的 <code>fd</code> 中读取数据，同时不破坏我们 <code>Counter</code> 结构体的 RAII 保证。</p><p>最初尝试的 <code>mem::forget</code> 是一个脆弱的魔术，它在错误路径上存在 <code>double-close</code> 的隐患。而最终的解决方案 <code>libc::dup</code>，则是一个精妙的、最符合 Unix 哲学的正道。</p><p>这个方案的原理，可以用一个“<strong>配钥匙</strong>”的比喻来理解：</p><p>我们的 <code>Counter</code> 结构体持有那把唯一的“原始钥匙”(<code>fd</code>)。如果直接把这把钥匙交给一个临时的 <code>File</code> 对象去读取，<code>File</code> 在被销毁时 (<code>Drop</code>) 就会把钥匙也销毁掉，导致我们的 <code>Counter</code> 无钥匙可用。</p><p><code>libc::dup()</code> 则是我们的“配钥匙机”。我们用它复制一把“临时钥匙”(<code>dup_fd</code>) 交给 <code>File</code> 去用。<code>File</code> 用完后，销毁的是这把临时钥匙。而我们自己口袋里的那把原始钥匙，自始至终，安然无恙。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// crates/pipa_cli/src/main.rs -&gt; run_stat()</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> <span class="variable">read_counter</span> = |counter: &amp;raw_perf_events::Counter| <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;<span class="type">u64</span>&gt; &#123;</span><br><span class="line">    <span class="comment">// 1. 我们不触碰原始 fd，而是创建一个它的“合法副本”。</span></span><br><span class="line">    <span class="keyword">let</span> <span class="variable">dup_fd</span> = <span class="keyword">unsafe</span> &#123; libc::<span class="title function_ invoke__">dup</span>(counter.<span class="title function_ invoke__">fd</span>()) &#125;;</span><br><span class="line">    <span class="keyword">if</span> dup_fd &lt; <span class="number">0</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="title function_ invoke__">Err</span>(io::Error::<span class="title function_ invoke__">last_os_error</span>().<span class="title function_ invoke__">into</span>());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2. 我们将这个“副本”的所有权，心安理得地交给 `File`。</span></span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">file</span> = <span class="keyword">unsafe</span> &#123; File::<span class="title function_ invoke__">from_raw_fd</span>(dup_fd) &#125;;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">buf</span> = [<span class="number">0u8</span>; <span class="number">8</span>];</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3. 无论成功还是失败，`file` 离开作用域时，只会 `close(dup_fd)`。</span></span><br><span class="line">    <span class="comment">//    原始的 `counter.fd()` 始终安全。</span></span><br><span class="line">    file.<span class="title function_ invoke__">read_exact</span>(&amp;<span class="keyword">mut</span> buf)?;</span><br><span class="line"></span><br><span class="line">    <span class="title function_ invoke__">Ok</span>(<span class="type">u64</span>::<span class="title function_ invoke__">from_le_bytes</span>(buf))</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这个方案的采纳，标志着 <code>stat</code> 子命令的构建，不仅在功能上是正确的，在健壮性和工程美学上也达到了我们所追求的高度。</p><p>这趟从复杂到简约的旅程，让我深刻理解到：<strong>优秀的系统编程，很多时候不是关于如何“操纵”内核，而是关于如何“理解”并“信任”内核。</strong></p><p>至此，<code>pipa-rs stat</code> 的核心逻辑终于完成。下一篇，我们将继续沿着 <code>perf_event</code> 这条路走下去，探索更复杂的采样模式，为实现 <code>perf record</code> 的功能打下基础。</p>]]></content>
      
      
      <categories>
          
          <category> 技术实践 </category>
          
          <category> 系统工程 </category>
          
          <category> 系统编程 </category>
          
          <category> Rust系统编程 </category>
          
          <category> PIPA-rs开发手记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 系统编程 </tag>
            
            <tag> Rust </tag>
            
            <tag> perf_event </tag>
            
            <tag> strace </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PIPA-rs 开发手记 (二)：从 /proc 文件到 TUI，一次关于“可信度”的修行</title>
      <link href="/2025/10/05/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B/%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B/Rust%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B/PIPA-rs%E5%BC%80%E5%8F%91%E6%89%8B%E8%AE%B0/PIPA-rs-%E5%BC%80%E5%8F%91%E6%89%8B%E8%AE%B0-%E4%BA%8C-%EF%BC%9A%E4%BB%8E-proc-%E6%96%87%E4%BB%B6%E5%88%B0-TUI%EF%BC%8C%E4%B8%80%E6%AC%A1%E5%85%B3%E4%BA%8E%E2%80%9C%E5%8F%AF%E4%BF%A1%E5%BA%A6%E2%80%9D%E7%9A%84%E4%BF%AE%E8%A1%8C/"/>
      <url>/2025/10/05/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B/%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B/Rust%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B/PIPA-rs%E5%BC%80%E5%8F%91%E6%89%8B%E8%AE%B0/PIPA-rs-%E5%BC%80%E5%8F%91%E6%89%8B%E8%AE%B0-%E4%BA%8C-%EF%BC%9A%E4%BB%8E-proc-%E6%96%87%E4%BB%B6%E5%88%B0-TUI%EF%BC%8C%E4%B8%80%E6%AC%A1%E5%85%B3%E4%BA%8E%E2%80%9C%E5%8F%AF%E4%BF%A1%E5%BA%A6%E2%80%9D%E7%9A%84%E4%BF%AE%E8%A1%8C/</url>
      
        <content type="html"><![CDATA[<p>在上一篇手记中，我们为 PIPA-rs 搭建了一副坚固的“骨架”——一个自律的、自动化的工程框架。现在，是时候为这副骨架注入第一股“生命力”了。我们的目标是：深入 <code>pipa_collector</code>，从零开始实现对系统核心指标的采集，并构建一个基础的 TUI 监控工具，作为 <code>sar</code> 和 <code>top</code> 的一个微型替代品。</p><p>有人可能会问，Linux 上有那么多现成的工具和 <code>crate</code>，为什么非要选择一条最“难”的路——直接去解析 <code>/proc</code> 文件系统？</p><p>答案很简单，它源于 PIPA-rs 的核心理念：“零外部二进制依赖”和“超可靠”。我们不希望 PIPA-rs 的可靠性建立在对 <code>sar</code> 命令输出格式的脆弱假设上。我们希望直接与内核提供的数据源对话，并用自己的代码来保证每一次解析的健壮性。这不仅仅是重新造轮子，更是一次关于构建“可信度”的修行。</p><span id="more"></span><h3 id="解析-proc：为应对真实世界的混乱而设计"><a href="#解析-proc：为应对真实世界的混乱而设计" class="headerlink" title="解析 &#x2F;proc：为应对真实世界的混乱而设计"></a>解析 &#x2F;proc：为应对真实世界的混乱而设计</h3><p>我的第一个目标是解析 <code>/proc/stat</code> 和 <code>/proc/meminfo</code>。这听起来很简单，不就是读取文件、按空格分割字符串吗？但很快我就意识到，一个“玩具”解析器和一个“工业级”解析器的区别，就在于你如何处理真实世界中可能发生的各种混乱。</p><p>为了确保 <code>pipa_collector</code> 的健壮性，我从一开始就定下了一个目标：这个模块的测试覆盖率必须达到 100%。</p><p>要实现这个目标，关键在于一个经典的设计模式：<strong>将 I&#x2F;O 与逻辑解耦</strong>。</p><p>我将代码分成了两层：</p><ol><li><strong>纯粹的解析函数</strong>: 比如 <code>parse_cpu_stats_from_line(line: &amp;str)</code>，它接收一个字符串切片，返回一个 <code>Result</code>。这个函数不执行任何 I&#x2F;O，它是确定的、可预测的，因此可以被轻松地 100% 测试。</li><li><strong>负责 I&#x2F;O 的函数</strong>: 比如 <code>read_cpu_stats_from_path&lt;P: AsRef&lt;Path&gt;&gt;(path: P)</code>，它负责读取文件，然后调用上面的纯函数。</li></ol><p>这种分离让测试变得非常简单。对于解析逻辑，我可以直接喂给它各种正常和异常的字符串；对于 I&#x2F;O 函数，我可以使用 <code>tempfile</code> crate 在测试时创建一个临时的假文件。</p><p>而真正体现“为混乱而设计”思想的，是我为 <code>pipa_collector</code> 精心设计的自定义错误类型 <code>PipaCollectorError</code>。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// crates/pipa_collector/src/system_stats.rs</span></span><br><span class="line"><span class="meta">#[derive(Debug)]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">enum</span> <span class="title class_">PipaCollectorError</span> &#123;</span><br><span class="line">    <span class="title function_ invoke__">Io</span>(io::Error),</span><br><span class="line">    <span class="title function_ invoke__">Parse</span>(ParseIntError),</span><br><span class="line">    <span class="title function_ invoke__">InvalidFormat</span>(<span class="type">String</span>),</span><br><span class="line">    <span class="title function_ invoke__">MissingData</span>(<span class="type">String</span>),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我没有简单地 <code>unwrap()</code> 或者抛出一个泛泛的 <code>io::Error</code>。我预想并用单元测试覆盖了各种 <code>/proc</code> 文件可能出现的“不完美”状态：</p><ul><li><strong>格式错误 (<code>InvalidFormat</code>)</strong>: 比如 <code>cpu</code> 字段被意外篡改 (<code>test_parse_cpu_stats_invalid_prefix</code>)。</li><li><strong>数据缺失 (<code>MissingData</code>)</strong>: 比如内核输出被截断，字段不够 (<code>test_parse_cpu_stats_not_enough_values</code>)。</li><li><strong>数据损坏 (<code>Parse</code>)</strong>: 比如 <code>meminfo</code> 中某一行的数据不是数字，但解析器不能因此崩溃，而是要能容错并继续 (<code>test_parse_memory_stats_malformed_value</code>)。</li></ul><p>正是这种对细节和边缘案例的执念，才让“100% 覆盖率”这个数字变得有意义。它代表着 <code>pipa_collector</code> 从诞生之初，就准备好了去面对一个不那么理想的真实世界。</p><h3 id="TUI-的进化：从“打印”思维到“绘制”思维"><a href="#TUI-的进化：从“打印”思维到“绘制”思维" class="headerlink" title="TUI 的进化：从“打印”思维到“绘制”思维"></a>TUI 的进化：从“打印”思维到“绘制”思维</h3><p>有了可靠的数据源，下一步就是把它呈现出来。我开始着手开发 <code>pipa-rs monitor</code> 命令，一个实时的 TUI 监视器。</p><p>我的 TUI 开发经历了一次典型的、从混乱到精确的进化：</p><ol><li><strong>V1 - “滚动日志”阶段</strong>: 最初我只是简单地用 <code>println!</code> 把数据打印出来。结果可想而知，终端被不断刷屏，污染了命令历史。</li><li><strong>V2 - “伪 TUI” 阶段</strong>: 我学聪明了一点，在每次 <code>println!</code> 之前，先打印一个 ANSI 清屏码 <code>\x1B[2J</code>。这创造了一种“原地刷新”的假象，但很快我就发现，即使我用格式化字符串费力地对齐，布局在终端缩放时依然是一片混乱。</li></ol><p>也正是这个无法解决的混乱，让我彻底停下来思考：<strong>问题的根源，或许根本不在于“怎么对齐”，而在于我从一开始就用错了方法。</strong></p><p>我一直在用“打印”的思维来解决一个“绘制”的问题。只要我还在向终端“流式地”发送字符，并期望它能正确处理换行和对齐，我就永远无法获得精确的控制。我需要的，是一个真正的“画布”和一支“画笔”。</p><p><code>crossterm</code> 库就是我找到的答案。它提供了两个核心工具，彻底改变了我的 TUI 范式：</p><ul><li><strong>备用屏幕 (<code>EnterAlternateScreen</code>)</strong>: 它为我的应用提供了一个独立的、干净的“画布”，退出时会自动恢复到之前的终端状态，解决了“污染历史”的问题。</li><li><strong>绝对光标定位 (<code>cursor::MoveTo(x, y)</code>)</strong>: 这才是解决布局问题的“银弹”。我不再关心上一个字符打印在哪，而是每次都明确地告诉终端：“把光标移动到 <code>(x, y)</code>，然后在这里画出你的内容。”</li></ul><p>这次从“流式输出”到“绝对定位”的思维跃迁，最终让我构建出了那个稳定、专业、无闪烁的 TUI 界面。</p><h3 id="被-TUI-掩盖的灵魂：计算逻辑的“可信度”"><a href="#被-TUI-掩盖的灵魂：计算逻辑的“可信度”" class="headerlink" title="被 TUI 掩盖的灵魂：计算逻辑的“可信度”"></a>被 TUI 掩盖的灵魂：计算逻辑的“可信度”</h3><p>一个分析工具，其界面的华丽是“面子”，而其内在逻辑的准确性，才是赢得用户信任的“里子”。</p><p>在 <code>pipa-rs monitor</code> 的 TUI 之下，隐藏着一个关键函数 <code>calculate_cpu_usage</code>。其中两个看似微不足道的细节，正是 PIPA-rs 可信度的基石。</p><ol><li><strong>对 <code>total_delta == 0.0</code> 的处理</strong>: 在一个极度空闲的系统上，或在一个极短的采样间隔内，<code>/proc/stat</code> 的累计值可能没有任何变化。如果没有 <code>if total_delta == 0.0</code> 这个检查，程序就会因为“除以零”而 <code>panic</code>。一个专业的性能工具，绝不能因为系统“太闲”而崩溃。这个检查，是<strong>健 robustness</strong>的体现。</li><li><strong>对 <code>iowait</code> 的归属判断</strong>: 我将 <code>iowait</code> 正确地归类为了“空闲时间”的一部分，因为它代表 CPU <strong>没有</strong>在执行任务，而是在等待 I&#x2F;O。如果错误地将其归为“繁忙时间”，就会在 I&#x2F;O 密集型场景下严重高估 CPU 使用率，误导用户去排查一个根本不存在的 CPU 瓶颈。这个判断，是<strong>accuracy</strong>的体现。</li></ol><h3 id="尾声：第一个可用的“小工具”"><a href="#尾声：第一个可用的“小工具”" class="headerlink" title="尾声：第一个可用的“小工具”"></a>尾声：第一个可用的“小工具”</h3><p>经过一番折腾，我终于可以运行 <code>pipa-rs monitor</code>，看到从我自己编写的解析器中流出的数据，最终在我自己的 TUI 上实时刷新。</p><p>那一刻的满足感是巨大的。这个从输入到输出的完整闭环，标志着 PIPA-rs 不再只是一堆库代码，它已经成为了一个有用的、看得见摸得着的“小工具”。</p><p>虽然它还很简陋，但它的内核是可靠的，它的界面是专业的，它的每一次输出都值得信赖。</p><p>当然，<code>monitor</code> 只是一个“开胃菜”。真正的硬仗还在后面。下一篇手记，我们将挑战 PIPA-rs 的核心——与 <code>perf_event_open</code> 系统调用正面交锋，去实现 <code>perf stat</code> 的核心功能。</p>]]></content>
      
      
      <categories>
          
          <category> 技术实践 </category>
          
          <category> 系统工程 </category>
          
          <category> 系统编程 </category>
          
          <category> Rust系统编程 </category>
          
          <category> PIPA-rs开发手记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 系统编程 </tag>
            
            <tag> Rust </tag>
            
            <tag> TUI </tag>
            
            <tag> 测试驱动开发 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PIPA-rs 开发手记 (一)：从 Workspace 到 CI，一个“自律”框架的诞生</title>
      <link href="/2025/10/05/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B/%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B/Rust%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B/PIPA-rs%E5%BC%80%E5%8F%91%E6%89%8B%E8%AE%B0/PIPA-rs-%E5%BC%80%E5%8F%91%E6%89%8B%E8%AE%B0-%E4%B8%80-%EF%BC%9A%E4%BB%8E-Workspace-%E5%88%B0-CI%EF%BC%8C%E4%B8%80%E4%B8%AA%E2%80%9C%E8%87%AA%E5%BE%8B%E2%80%9D%E6%A1%86%E6%9E%B6%E7%9A%84%E8%AF%9E%E7%94%9F/"/>
      <url>/2025/10/05/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B/%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B/Rust%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B/PIPA-rs%E5%BC%80%E5%8F%91%E6%89%8B%E8%AE%B0/PIPA-rs-%E5%BC%80%E5%8F%91%E6%89%8B%E8%AE%B0-%E4%B8%80-%EF%BC%9A%E4%BB%8E-Workspace-%E5%88%B0-CI%EF%BC%8C%E4%B8%80%E4%B8%AA%E2%80%9C%E8%87%AA%E5%BE%8B%E2%80%9D%E6%A1%86%E6%9E%B6%E7%9A%84%E8%AF%9E%E7%94%9F/</url>
      
        <content type="html"><![CDATA[<p>开新坑了。这次，我想从零开始，用 Rust 认真地做一个原生的 Linux 性能分析工具链——<code>PIPA-rs</code>。这不仅是对经典 PIPA 项目的一次重塑，也是我个人在系统编程领域的一次深度探索。</p><p>但今天这第一篇，我们不聊 <code>perf_event_open</code> 的底层魔法，也不谈 <code>/proc</code> 文件系统的精妙。在写下第一行真正的业务逻辑之前，我想先聊聊那些“看不见”的东西：项目的工程化基础。</p><p>很多人（包括曾经的我）在开始一个新项目时，总是迫不及待地 <code>cargo new</code> 然后一头扎进 <code>main.rs</code>。但这次，我决定反其道而行之。我要为 PIPA-rs 搭建一个“世界级”的工程基础。这听起来有点空，甚至有点“过度工程”的嫌疑，但一个可靠的工具，必须诞生于一个可靠的摇篮。这个摇篮，关乎开发纪律、自动化，以及在未来漫长的迭代中，我们是否还能保持从容。</p><p>所以，这篇手记，就从我们的第一块基石开始：如何搭建一个“自律”的 Rust 项目框架，以及我们在 CI&#x2F;CD 自动化之路上，踩过的那些坑和最终找到的光。</p><span id="more"></span><h3 id="第一块基石：用-Workspace-规划未来，用-resolver-购买保险"><a href="#第一块基石：用-Workspace-规划未来，用-resolver-购买保险" class="headerlink" title="第一块基石：用 Workspace 规划未来，用 resolver 购买保险"></a>第一块基石：用 Workspace 规划未来，用 <code>resolver</code> 购买保险</h3><p>从一开始，我就很清楚 PIPA-rs 不会是一个单一、庞大的可执行文件。它应该是一套分工明确、松耦合的组件集合。因此，我毫不犹豫地选择了 <code>Cargo Workspace</code>。</p><figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Cargo.toml</span></span><br><span class="line"><span class="section">[workspace]</span></span><br><span class="line"><span class="attr">resolver</span> = <span class="string">&quot;2&quot;</span></span><br><span class="line"><span class="attr">members</span> = [</span><br><span class="line">    <span class="string">&quot;crates/pipa_cli&quot;</span>,</span><br><span class="line">    <span class="string">&quot;crates/pipa_collector&quot;</span>,</span><br><span class="line">    <span class="string">&quot;crates/pipa_core&quot;</span>,</span><br><span class="line">    <span class="string">&quot;crates/pipa_parser&quot;</span>,</span><br><span class="line">    <span class="string">&quot;crates/pipad_server&quot;</span>,</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>这个 <code>members</code> 列表，就是 PIPA-rs 的蓝图：</p><ul><li><code>pipa_collector</code>: 负责从内核收集原始数据的“矿工”。</li><li><code>pipa_parser</code>: 将原始数据解析成结构化信息的“解析器”。</li><li><code>pipa_core</code>: 实现核心分析逻辑的“大脑”。</li><li><code>pipa_cli</code>: 用户与之交互的“命令行界面”。</li><li><code>pipad_server</code>: 用于数据持久化的“数据库服务”。</li></ul><p>在项目的第一天就做出这样的划分，好处是显而易见的：它强制我们思考模块间的边界，让每个 <code>crate</code> 的职责都保持单一。</p><p>而在 <code>[workspace]</code> 中，有一行看似微不足道的配置，我却认为它对项目的长期健康至关重要——<code>resolver = &quot;2&quot;</code>。</p><p>这行代码是为项目的未来“购买的一份保险”。在旧版的 Cargo 解析器 (v1) 中，当依赖关系变得复杂时，可能会为不同的 <code>crate</code> 解析出同一个依赖库的不同 <code>feature</code> 组合，这在链接时可能导致难以调试的符号冲突。而 V2 解析器会强制在整个工作区内对 <code>feature</code> 进行统一，从根本上杜绝了这类问题。对于 PIPA-rs 这样一个注定会引入复杂依赖的项目，这个决策能让我们在未来省去很多挠头的时刻。</p><h3 id="自动化之路：CI-CD-的“阵痛”与进化"><a href="#自动化之路：CI-CD-的“阵痛”与进化" class="headerlink" title="自动化之路：CI&#x2F;CD 的“阵痛”与进化"></a>自动化之路：CI&#x2F;CD 的“阵痛”与进化</h3><p>有了骨架，下一步就是注入灵魂——自动化。我立刻着手搭建了基于 GitHub Actions 的 CI&#x2F;CD 流程。</p><p>我的第一个 <code>ci.yml</code> 版本非常朴素，就是一个单 <code>job</code> 的线性工作流：<code>checkout -&gt; install -&gt; fmt -&gt; clippy -&gt; test</code>。然而，现实很快就给我上了一课，CI 管道立刻用一抹红色迎接了我。</p><p><strong>遭遇的连环坑：</strong></p><ol><li><strong>废弃的 Action</strong>: 我最初使用的 <code>dtolnay/rust-toolchain-action</code> 已经被废弃，导致 workflow 直接失败。这是一个典型的经验陷阱，提醒我在选择第三方依赖时，必须关注其维护状态。我迅速迁移到了官方维护的 <code>actions-rust-lang/setup-rust-toolchain</code>。</li><li><strong>Cargo 目录约定</strong>: 接下来是一个新手级的错误——<code>no targets specified</code>。这暴露了我的项目文件结构与 Cargo 的约定不符。虽然有点尴尬，但这恰好证明了 CI 作为第一道防线的价值：它在我合并一个有结构性缺陷的改动前，就无情地将其拦下。</li></ol><p>在解决了这些基础问题后，CI 终于跑通了。我长舒一口气，然后引入了下一个关键组件：<code>cargo-tarpaulin</code>，用于代码覆盖率统计。这是我们对代码质量的承诺。</p><p>然而，新的“灾难”降临了。一个原本几十秒就能完成的 CI run，时间瞬间飙升到数分钟。</p><p>这对我们追求的“原子化提交”工作流是致命的。如果每次微小的提交都要等待几分钟的 CI，开发者的心流会被严重打断。必须优化！</p><p>解决方案是缓存。但简单的缓存 <code>~/.cargo/bin</code> 并不够精细。<code>cargo-tarpaulin</code> 是一个体积较大且不常变动的开发工具，如果把它和其他可能频繁安装的小工具混在同一个缓存里，缓存很容易就失效了。</p><p>最终的方案是：<strong>为 <code>tarpaulin</code> 建立独立的、带稳定 key 的缓存</strong>。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># .github/workflows/ci.yml</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Cache</span> <span class="string">cargo-tarpaulin</span></span><br><span class="line">  <span class="attr">id:</span> <span class="string">cache-tarpaulin</span></span><br><span class="line">  <span class="attr">uses:</span> <span class="string">actions/cache@v4</span></span><br><span class="line">  <span class="attr">with:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">~/.cargo/bin/cargo-tarpaulin</span></span><br><span class="line">    <span class="attr">key:</span> <span class="string">$&#123;&#123;</span> <span class="string">runner.os</span> <span class="string">&#125;&#125;-cargo-tarpaulin-v1</span> <span class="comment"># 一个稳定的 key</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Install</span> <span class="string">cargo-tarpaulin</span> <span class="string">if</span> <span class="string">not</span> <span class="string">cached</span></span><br><span class="line">  <span class="comment"># 只有在缓存未命中时，才执行安装</span></span><br><span class="line">  <span class="attr">if:</span> <span class="string">steps.cache-tarpaulin.outputs.cache-hit</span> <span class="type">!=</span> <span class="string">&#x27;true&#x27;</span></span><br><span class="line">  <span class="attr">run:</span> <span class="string">cargo</span> <span class="string">install</span> <span class="string">cargo-tarpaulin</span></span><br></pre></td></tr></table></figure><p>通过这个精细化的缓存策略，<code>tarpaulin</code> 的安装步骤在绝大多数情况下都会被跳过，CI 时间也从数分钟降回了令人舒适的几十秒。一次性能阵痛，换来了一劳永逸的优化。</p><h3 id="纪律的内化：将“质量左移”进行到底"><a href="#纪律的内化：将“质量左移”进行到底" class="headerlink" title="纪律的内化：将“质量左移”进行到底"></a>纪律的内化：将“质量左移”进行到底</h3><p>CI 是一个很好的安全网，但它是一个<strong>遥远</strong>的安全网。它的反馈链条是：<code>写代码 -&gt; commit -&gt; push -&gt; 等待 CI 结果</code>。如果只是一个格式问题或者一个简单的 clippy 警告，这个等待就太浪费时间了。</p><p>我信奉一个原则：“**质量左移 (Shift-Left Quality)**”——越早在开发流程中发现问题，修复的成本就越低。</p><p>为了践行这个原则，我引入了 <code>pre-commit</code> 钩子。它将 CI 的一部分能力，直接带回了开发者的本地机器。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># .pre-commit-config.yaml</span></span><br><span class="line"><span class="attr">repos:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">repo:</span> <span class="string">https://github.com/doublify/pre-commit-rust</span></span><br><span class="line">    <span class="attr">rev:</span> <span class="string">v1.0</span></span><br><span class="line">    <span class="attr">hooks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">id:</span> <span class="string">fmt</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">id:</span> <span class="string">clippy</span></span><br><span class="line">        <span class="attr">args:</span> [<span class="string">&quot;--all-targets&quot;</span>, <span class="string">&quot;--&quot;</span>, <span class="string">&quot;-D&quot;</span>, <span class="string">&quot;warnings&quot;</span>]</span><br></pre></td></tr></table></figure><p>现在，每当我 <code>git commit</code> 时，<code>cargo fmt</code> 和 <code>cargo clippy</code> 都会自动在我的暂存文件上运行。任何格式错误或 clippy 警告都会直接阻止这次提交，并提示我修正。反馈几乎是瞬时的。</p><p>这个机制很快就展现了它的价值。在我配置 <code>clippy</code> 钩子时，就因为一个参数错误导致它无法正常工作。这个问题在本地就被 <code>pre-commit</code> 暴露了出来，我甚至不需要 push 代码，就完成了调试和修复，省下了一个完整的 CI 周期。</p><h3 id="尾声：地基之上，未来可期"><a href="#尾声：地基之上，未来可期" class="headerlink" title="尾声：地基之上，未来可期"></a>尾声：地基之上，未来可期</h3><p>至此，PIPA-rs 的地基算是搭建完成了。我们拥有了一个：</p><ul><li><strong>结构清晰</strong>的 <code>Cargo Workspace</code>。</li><li>一个<strong>快速、可靠</strong>的 CI&#x2F;CD 流程来自动化质量检查。</li><li>一套<strong>强制执行纪律</strong>的 <code>pre-commit</code> 钩子来提供即时反馈。</li></ul><p>这个“自律”的框架，让我在写下第一行业务代码时，充满了信心。我知道，有无数个自动化的守卫在保护着这个项目的代码质量，让我可以更专注于核心功能的实现。</p><p>有了这个坚实的地基，我们终于可以开始盖楼了。下一篇手记，我们将正式潜入 <code>pipa_collector</code> 的世界，从解析 <code>/proc/stat</code> 和 <code>/proc/meminfo</code> 开始，真正踏上数据采集的征程。</p>]]></content>
      
      
      <categories>
          
          <category> 技术实践 </category>
          
          <category> 系统工程 </category>
          
          <category> 系统编程 </category>
          
          <category> Rust系统编程 </category>
          
          <category> PIPA-rs开发手记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 系统编程 </tag>
            
            <tag> Rust </tag>
            
            <tag> 开源 </tag>
            
            <tag> CI/CD </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>我的程序卡在哪里？—— 用火焰图精确定位性能瓶颈</title>
      <link href="/2025/09/17/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B/%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B/Linux%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/%E6%88%91%E7%9A%84%E7%A8%8B%E5%BA%8F%E5%8D%A1%E5%9C%A8%E5%93%AA%E9%87%8C%EF%BC%9F%E2%80%94%E2%80%94-%E7%94%A8%E7%81%AB%E7%84%B0%E5%9B%BE%E7%B2%BE%E7%A1%AE%E5%AE%9A%E4%BD%8D%E6%80%A7%E8%83%BD%E7%93%B6%E9%A2%88/"/>
      <url>/2025/09/17/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B/%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B/Linux%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/%E6%88%91%E7%9A%84%E7%A8%8B%E5%BA%8F%E5%8D%A1%E5%9C%A8%E5%93%AA%E9%87%8C%EF%BC%9F%E2%80%94%E2%80%94-%E7%94%A8%E7%81%AB%E7%84%B0%E5%9B%BE%E7%B2%BE%E7%A1%AE%E5%AE%9A%E4%BD%8D%E6%80%A7%E8%83%BD%E7%93%B6%E9%A2%88/</url>
      
        <content type="html"><![CDATA[<p><code>本次环境为Arch Linux，内核版本6.12.46-3-cachyos-lts，perf版本6.16-3</code></p><h3 id="前言：从“健康报告”到“外科手术”"><a href="#前言：从“健康报告”到“外科手术”" class="headerlink" title="前言：从“健康报告”到“外科手术”"></a>前言：从“健康报告”到“外科手术”</h3><p>在上一篇文章《<a href="/2025/09/17/%E6%88%91%E7%9A%84%E7%A8%8B%E5%BA%8F%E4%B8%BA%E4%BB%80%E4%B9%88%E6%85%A2%EF%BC%9F%E2%80%94%E2%80%94-Perf-CPU-%E6%80%A7%E8%83%BD%E5%89%96%E6%9E%90/">我的程序为什么慢？—— Perf CPU 性能剖析</a>》中，我们学会了使用 <code>perf stat</code>。它就像一份体检报告，能告诉我们程序的整体健康状况——IPC 高不高、分支预测准不准。</p><p>但这还不够。如果报告说“指标异常”，我们并不知道问题出在哪个“器官”。<code>perf stat</code> 告诉我们程序慢了，但它没告诉我们<strong>慢在哪里</strong>。</p><span id="more"></span><p>要回答这个问题，我们需要进行“外科手术”，精确定位到消耗 CPU 最多的“病灶”——也就是热点函数。今天的主角，就是性能分析领域的“核磁共振仪”：<code>perf record</code> 与<strong>火焰图（Flame Graph）</strong>。</p><h3 id="实验准备：一个“意图明显”的性能靶子"><a href="#实验准备：一个“意图明显”的性能靶子" class="headerlink" title="实验准备：一个“意图明显”的性能靶子"></a>实验准备：一个“意图明显”的性能靶子</h3><p>为了让火焰图的效果一目了然，我们需要一个性能瓶颈足够明显的程序。下面这个 <code>test.cpp</code> 就是我们的靶子，它的意图很明显：<code>foo1</code> 会调用 <code>long_test</code> 100 次，<code>foo2</code> 调用 10 次，因此 <code>foo1</code> 的 CPU 开销应该是 <code>foo2</code> 的 10 倍左右。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">long</span> <span class="type">long</span> <span class="title">long_test</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> i;</span><br><span class="line">    <span class="comment">// 注意！这里的 volatile 很关键，我们后面会讲为什么</span></span><br><span class="line">    <span class="keyword">volatile</span> <span class="type">long</span> <span class="type">long</span> j = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="number">1000000</span>; i++) &#123;</span><br><span class="line">        j = i;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> j;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">long</span> <span class="type">long</span> <span class="title">foo2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> i;</span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> total = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">        total += <span class="built_in">long_test</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> total;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">long</span> <span class="type">long</span> <span class="title">foo1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> i;</span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> total = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line">        total += <span class="built_in">long_test</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> total;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> result1 = <span class="built_in">foo1</span>();</span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> result2 = <span class="built_in">foo2</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 同样关键，我们必须“使用”结果</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Result: %lld\n&quot;</span>, result1 + result2);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="探案之旅：三起谜案，揭开火焰图的真相"><a href="#探案之旅：三起谜案，揭开火焰图的真相" class="headerlink" title="探案之旅：三起谜案，揭开火焰图的真相"></a>探案之旅：三起谜案，揭开火焰图的真相</h3><p>理论是枯燥的，让我们直接动手，然后一头撞上那些新手必踩的坑。我把我的整个踩坑和破案过程记录了下来。</p><h4 id="谜案一：函数的集体“蒸发”"><a href="#谜案一：函数的集体“蒸发”" class="headerlink" title="谜案一：函数的集体“蒸发”"></a>谜案一：函数的集体“蒸发”</h4><p>满怀信心，我写了最初版的代码（没有 <code>volatile</code> 和 <code>printf</code>），然后用 <code>-O2</code> 优化编译，兴冲冲地执行了全套火焰图生成命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 编译</span></span><br><span class="line">g++ -O2 -g -o test-flame test.cpp</span><br><span class="line"><span class="comment"># 采样</span></span><br><span class="line"><span class="built_in">sudo</span> perf record -F 99 -g -- ./test-flame</span><br><span class="line"><span class="comment"># 生成火焰图</span></span><br><span class="line">perf script | stackcollapse-perf.pl | flamegraph.pl &gt; flame.svg</span><br></pre></td></tr></table></figure><p>然后，我得到了这样一张图：</p><p><img data-src="/img/2025/9/17/%E7%A9%BA%E7%9A%84%E7%81%AB%E7%84%B0%E5%9B%BE.png" alt="“空”火焰图" title="“空”火焰图"></p><p>一片荒芜！我的 <code>foo1</code>, <code>foo2</code>, <code>long_test</code> 全都不见了！<code>perf</code> 只记录到了几个程序启动初期的动态链接器的样本。</p><p><strong>破案</strong>：这是我遇到的第一个老师——<strong>编译器优化</strong>。编译器实在太聪明了，它检查了我的代码，发现 <code>long_test</code> 里的循环除了改变一个没人用的局部变量 <code>j</code> 之外，什么都没干。于是，它大笔一挥，执行了<strong>“死代码消除”（Dead Code Elimination）</strong>，把我的所有核心函数全都优化掉了。程序变成了一个空壳，自然瞬间执行完毕。</p><p><strong>解决方案</strong>：我必须“欺骗”编译器，让它相信我的代码是有用的。</p><ol><li>在 <code>long_test</code> 中使用 <code>volatile</code> 关键字，这个关键字会告诉编译器：“别动这个变量，我另有他用”，从而阻止循环被优化。</li><li>让函数返回计算结果，并在 <code>main</code> 函数中用 <code>printf</code> 打印出来。只要结果被使用，编译器就不敢轻易删除计算过程。</li></ol><h4 id="谜案二：调用栈的“破碎”"><a href="#谜案二：调用栈的“破碎”" class="headerlink" title="谜案二：调用栈的“破碎”"></a>谜案二：调用栈的“破碎”</h4><p>解决了第一个问题后，我重新生成了火焰图，得到了一张稍微好点，但依然奇怪的图：</p><p><img data-src="/img/2025/9/17/%E8%B0%83%E7%94%A8%E6%A0%88%E6%AE%8B%E7%BC%BA%E7%9A%84%E7%81%AB%E7%84%B0%E5%9B%BE.png" alt="调用栈残缺的火焰图" title="调用栈残缺的火焰图"></p><p><code>foo1</code> 出现了，但它的“孩子” <code>long_test</code> 却不见了。整个调用栈看起来像被拦腰斩断，充满了 <code>[unknown]</code>。</p><p><strong>破案</strong>：第二个老师出场了——还是<strong>编译器优化</strong>。这次是<strong>“函数内联”（Function Inlining）</strong>。编译器觉得 <code>long_test</code> 函数太简单了，每次调用它都走一遍压栈、跳转的流程太麻烦。于是，它把 <code>long_test</code> 的代码直接“复制粘贴”进了 <code>foo1</code> 和 <code>foo2</code> 的循环里。</p><p>所以，<code>perf</code> 采样时，CPU 确实在执行 <code>long_test</code> 的代码，但从调用栈的角度看，程序一直都“停留”在 <code>foo1</code> 函数内部，从未“进入”过 <code>long_test</code>。</p><h4 id="谜案三：永不妥协的优化器"><a href="#谜案三：永不妥协的优化器" class="headerlink" title="谜案三：永不妥协的优化器"></a>谜案三：永不妥协的优化器</h4><p>我怒了，我决定正面硬刚编译器。我查到了 <code>__attribute__((noinline))</code> 这个可以建议编译器不要内联的属性，还找到了 <code>-fno-omit-frame-pointer</code> 这个可以强制保留栈帧信息的编译选项。</p><p>然而，在使用 <code>-O2</code> 优化时，生成的火焰图依然不尽人意，调用栈还是残缺的。</p><p><strong>破案</strong>：我终于明白了，和全力开火的优化器“搏斗”，试图去限制它的行为，是一条很艰难的路。真正的专业思路应该是反过来：<strong>让编译器尽情优化，然后用更强大的探查器（Profiler）去适应它。</strong></p><h3 id="最终的“黄金组合”：让优化与观测和谐共存"><a href="#最终的“黄金组合”：让优化与观测和谐共存" class="headerlink" title="最终的“黄金组合”：让优化与观测和谐共存"></a>最终的“黄金组合”：让优化与观测和谐共存</h3><p>在经历了九九八十一难后，我终于找到了生成完美火焰图的“黄金组合”：</p><p><strong>1. 专业级的编译指令：</strong><br>我们依然要开启优化，但强制保留堆栈回溯的线索。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">g++ -O2 -g -fno-omit-frame-pointer -o test-flame test.cpp</span><br></pre></td></tr></table></figure><ul><li><code>-O2</code>: 开启优化，模拟生产环境。</li><li><code>-g</code>: 保留调试符号，让火焰图显示函数名。</li><li><code>-fno-omit-frame-pointer</code>: 强制保留帧指针。这是给 <code>perf</code> 堆栈回溯提供的最可靠的“路标”。</li></ul><p><strong>2. 专业级的 <code>perf</code> 指令：</strong><br>我们明确告诉 <code>perf</code>，使用它最强大的、基于 <code>DWARF</code> 调试信息的回溯引擎。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> perf record -F 99 --call-graph dwarf -g -- ./test-flame</span><br></pre></td></tr></table></figure><ul><li><code>--call-graph dwarf</code>: <strong>这才是真正的魔法</strong>。它命令 <code>perf</code> 不再依赖可能被优化掉的帧指针，而是严格根据 <code>-g</code> 生成的详细“地图”（DWARF 信息）来绘制调用栈。这种方式虽然慢一点，但无比准确。</li></ul><h3 id="胜利的果实：一张会说话的火焰图"><a href="#胜利的果实：一张会说话的火焰图" class="headerlink" title="胜利的果实：一张会说话的火焰图"></a>胜利的果实：一张会说话的火焰图</h3><p>在使用了“黄金组合”之后，我终于得到了这张梦寐以求的、完美的火焰图：</p><p><img data-src="/img/2025/9/17/%E5%AE%8C%E7%BE%8E%E7%9A%84%E7%81%AB%E7%84%B0%E5%9B%BE.png" alt="完美的火焰图" title="完美的火焰图"></p><p>现在，让我们来解读它：</p><ol><li><strong>Y 轴 - 调用栈深度</strong>：底部是 <code>_start</code> 和 <code>main</code>，顶部是 <code>long_test</code>，完美地展示了 <code>main</code> -&gt; <code>foo1</code> -&gt; <code>long_test</code> 的调用关系。</li><li><strong>X 轴 - CPU 占用时间</strong>：<ul><li><code>long_test</code> 构成了最宽的“平顶山”，说明它就是程序的绝对热点。</li><li>它下面的 <code>foo1</code> 几乎和它一样宽，而 <code>foo2</code> 则窄到几乎看不见。这精确地反映了 <code>foo1</code> 的循环次数（100 次）远大于 <code>foo2</code>（10 次），因此绝大部分对 <code>long_test</code> 的调用都发生于 <code>foo1</code> 内部。</li></ul></li></ol><p>这张图用一种无比直观的方式，将我们程序的性能瓶颈暴露无遗。</p><h3 id="结论：不只是工具，更是思想"><a href="#结论：不只是工具，更是思想" class="headerlink" title="结论：不只是工具，更是思想"></a>结论：不只是工具，更是思想</h3><p>这次火焰图的探案之旅，让我学到的远超几个命令：</p><ol><li><strong>永远不要低估编译器</strong>：它既是你最好的朋友，也是性能分析时最大的“捣蛋鬼”。</li><li><strong>基准测试代码本身必须可靠</strong>：确保你的测试代码不会被优化器“作弊”干掉。</li><li><strong>观测工具需要精调</strong>：默认参数通常不够用。理解工具（如 <code>perf</code>）的高级选项，才能应对复杂的现实世界场景。</li></ol><p>我们已经学会了如何找到 CPU 的瓶颈，但在真实的软件世界里，程序还会因为崩溃、内存泄漏等问题而倒下。在下一篇文章中，我们将拿起新的武器——GDB, ASAN 和 Valgrind，成为一名合格的“程序法医”。</p>]]></content>
      
      
      <categories>
          
          <category> 技术实践 </category>
          
          <category> 系统工程 </category>
          
          <category> 性能工程 </category>
          
          <category> Linux性能分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 性能分析 </tag>
            
            <tag> 系统编程 </tag>
            
            <tag> 开源工具 </tag>
            
            <tag> Linux Perf </tag>
            
            <tag> perf </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>我的程序为什么慢？—— Perf CPU 性能剖析</title>
      <link href="/2025/09/17/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B/%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B/Linux%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/%E6%88%91%E7%9A%84%E7%A8%8B%E5%BA%8F%E4%B8%BA%E4%BB%80%E4%B9%88%E6%85%A2%EF%BC%9F%E2%80%94%E2%80%94-Perf-CPU-%E6%80%A7%E8%83%BD%E5%89%96%E6%9E%90/"/>
      <url>/2025/09/17/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B/%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B/Linux%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/%E6%88%91%E7%9A%84%E7%A8%8B%E5%BA%8F%E4%B8%BA%E4%BB%80%E4%B9%88%E6%85%A2%EF%BC%9F%E2%80%94%E2%80%94-Perf-CPU-%E6%80%A7%E8%83%BD%E5%89%96%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p><code>本次环境为Arch Linux，内核版本6.12.46-3-cachyos-lts，perf版本6.16-3</code></p><h3 id="前言：为什么-perf-让人望而生畏？"><a href="#前言：为什么-perf-让人望而生畏？" class="headerlink" title="前言：为什么 perf 让人望而生畏？"></a>前言：为什么 <code>perf</code> 让人望而生畏？</h3><p><code>perf</code> 是 Linux 世界中无可争议的性能分析神器。然而，很多开发者（包括曾经的我）在第一次看到 <code>perf stat</code> 那满屏飞舞的专业术语时，都会感到一丝困惑和畏惧：<code>task-clock</code>, <code>IPC</code>, <code>stalled-cycles-frontend</code>… 这些到底意味着什么？</p><span id="more"></span><p>死记硬背概念是低效的。学习 <code>perf</code> 最好的方法，就是亲手创造一个实验环境，通过对比和分析，让这些冰冷的数据“开口说话”。</p><p>本文将带你通过一个极其简单却又经典的案例——实现我们自己的 <code>ls</code> 命令——来揭开 <code>perf</code> 的神秘面紗。</p><p><code>本次环境为Arch Linux，内核版本6.12.46-3-cachyos-lts，perf版本6.16-3</code></p><h3 id="第一步：我们的“实验室”-一个极简的-ls"><a href="#第一步：我们的“实验室”-一个极简的-ls" class="headerlink" title="第一步：我们的“实验室” - 一个极简的 ls"></a>第一步：我们的“实验室” - 一个极简的 <code>ls</code></h3><p><code>ls</code> 命令的核心逻辑是什么？其实非常简单：</p><ol><li>打开一个目录。</li><li>循环读取目录里的每一个条目。</li><li>（可选）获取每个条目的详细信息（元数据）。</li><li>打印出来。</li></ol><p>这个过程主要涉及文件 I&#x2F;O 和系统调用（syscalls），使其成为一个绝佳的性能分析对象。下面是我们的极简实现 <code>ls-mini.c</code>，它模拟了 <code>ls -l</code> 的核心行为：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;dirent.h&gt;</span>     <span class="comment">// 主要头文件，包含了 opendir, readdir, closedir</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/stat.h&gt;</span>   <span class="comment">// 包含了 stat 结构体和函数</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;errno.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">list_dir</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *path)</span> &#123;</span><br><span class="line">    DIR *dir_p;                 <span class="comment">// 目录流指针</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">dirent</span> *<span class="title">dir_entry</span>;</span>   <span class="comment">// 目录条目结构体指针</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">stat</span> <span class="title">file_stat</span>;</span>      <span class="comment">// 文件元数据结构体</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1. 打开目录 (对应 syscall: opendir)</span></span><br><span class="line">    <span class="comment">// 这会返回一个指向目录流的指针，后续可以从中读取条目</span></span><br><span class="line">    dir_p = opendir(path);</span><br><span class="line">    <span class="keyword">if</span> (dir_p == <span class="literal">NULL</span>) &#123;</span><br><span class="line">        perror(<span class="string">&quot;opendir failed&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2. 循环读取目录中的每一个条目 (对应 syscall: readdir)</span></span><br><span class="line">    <span class="comment">// readdir() 每次被调用，就会返回目录中的下一个条目。当没有更多条目时，返回 NULL。</span></span><br><span class="line">    <span class="keyword">while</span> ((dir_entry = readdir(dir_p)) != <span class="literal">NULL</span>) &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// dir_entry-&gt;d_name 是我们得到的文件名</span></span><br><span class="line">        <span class="type">char</span> *filename = dir_entry-&gt;d_name;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 简单的过滤，跳过 &quot;.&quot; 和 &quot;..&quot;</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">strcmp</span>(filename, <span class="string">&quot;.&quot;</span>) == <span class="number">0</span> || <span class="built_in">strcmp</span>(filename, <span class="string">&quot;..&quot;</span>) == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 获取每个文件的元数据 (对应 syscall: stat/lstat)</span></span><br><span class="line">        <span class="comment">// 为了获取详细信息（像 ls -l 那样），我们需要对每个文件调用 stat。</span></span><br><span class="line">        <span class="comment">// 注意：实际应用中需要拼接完整路径，这里为简化省略了。</span></span><br><span class="line">        <span class="keyword">if</span> (stat(filename, &amp;file_stat) == <span class="number">-1</span>) &#123;</span><br><span class="line">            <span class="comment">// 如果获取失败，打印错误并跳过</span></span><br><span class="line">            perror(<span class="string">&quot;stat failed&quot;</span>);</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 打印（解析和格式化）</span></span><br><span class="line">        <span class="comment">// 这里只是一个极其简单的打印，真实的 ls 会做复杂的格式化</span></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%lld &quot;</span>, (<span class="type">long</span> <span class="type">long</span>)file_stat.st_size); <span class="comment">// 文件大小</span></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%s\n&quot;</span>, filename);                      <span class="comment">// 文件名</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 5. 关闭目录 (对应 syscall: closedir)</span></span><br><span class="line">    <span class="comment">// 操作完成后，释放资源</span></span><br><span class="line">    closedir(dir_p);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> *argv[])</span> &#123;</span><br><span class="line">    <span class="comment">// 默认列出当前目录 &quot;.&quot;</span></span><br><span class="line">    list_dir(<span class="string">&quot;.&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们使用 GCC 的 <code>-O3</code> 优化来编译它，尽可能压榨它的性能：</p><figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -O3 -o ls-mini ls-mini.c</span><br></pre></td></tr></table></figure><h3 id="第二步：收集证据-perf-stat-登场"><a href="#第二步：收集证据-perf-stat-登场" class="headerlink" title="第二步：收集证据 - perf stat 登场"></a>第二步：收集证据 - <code>perf stat</code> 登场</h3><p>现在，我们的主角和参照物都准备好了：<code>ls-mini</code> 和系统自带的 <code>ls</code>。实验开始！<br><strong>对我们自制的 <code>ls-mini</code>：</strong></p><figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">perf <span class="built_in">stat</span> ./ls-mini</span><br><span class="line"> Performance counter stats <span class="keyword">for</span> <span class="string">&#x27;./ls-mini&#x27;</span>:</span><br><span class="line"></span><br><span class="line">              2.22 msec task-clock:u                     <span class="comment">#    0.614 CPUs utilized</span></span><br><span class="line">                 0      context-switches:u               <span class="comment">#    0.000 /sec</span></span><br><span class="line">                 0      cpu-migrations:u                 <span class="comment">#    0.000 /sec</span></span><br><span class="line">               137      page-faults:u                    <span class="comment">#   61.827 K/sec</span></span><br><span class="line">         2,216,772      instructions:u                   <span class="comment">#    0.68  insn per cycle</span></span><br><span class="line">                                                  <span class="comment">#    0.30  stalled cycles per insn</span></span><br><span class="line">         3,245,146      cycles:u                         <span class="comment">#    1.465 GHz</span></span><br><span class="line">           662,811      stalled-cycles-frontend:u        <span class="comment">#   20.42% frontend cycles idle</span></span><br><span class="line">           402,383      branches:u                       <span class="comment">#  181.593 M/sec</span></span><br><span class="line">            13,335      branch-misses:u                  <span class="comment">#    3.31% of all branches</span></span><br><span class="line"></span><br><span class="line">       0.003608686 seconds time elapsed</span><br><span class="line"></span><br><span class="line">       0.001027000 seconds user</span><br><span class="line">       0.002025000 seconds sys</span><br></pre></td></tr></table></figure><p><strong>对系统自带的 <code>ls</code>：</strong></p><figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">perf <span class="built_in">stat</span> <span class="built_in">ls</span></span><br><span class="line"></span><br><span class="line">Performance counter stats <span class="keyword">for</span> <span class="string">&#x27;ls&#x27;</span>:</span><br><span class="line"></span><br><span class="line">              0.85 msec task-clock:u                     <span class="comment">#    0.487 CPUs utilized</span></span><br><span class="line">                 0      context-switches:u               <span class="comment">#    0.000 /sec</span></span><br><span class="line">                 0      cpu-migrations:u                 <span class="comment">#    0.000 /sec</span></span><br><span class="line">                84      page-faults:u                    <span class="comment">#   98.831 K/sec</span></span><br><span class="line">           724,184      instructions:u                   <span class="comment">#    0.69  insn per cycle</span></span><br><span class="line">                                                  <span class="comment">#    0.61  stalled cycles per insn</span></span><br><span class="line">         1,042,864      cycles:u                         <span class="comment">#    1.227 GHz</span></span><br><span class="line">           439,742      stalled-cycles-frontend:u        <span class="comment">#   42.17% frontend cycles idle</span></span><br><span class="line">           146,350      branches:u                       <span class="comment">#  172.190 M/sec</span></span><br><span class="line">             5,834      branch-misses:u                  <span class="comment">#    3.99% of all branches</span></span><br><span class="line"></span><br><span class="line">       0.001745312 seconds time elapsed</span><br><span class="line"></span><br><span class="line">       0.000000000 seconds user</span><br><span class="line">       0.001757000 seconds sys</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="第三步：案件分析-解读数据的“微表情”"><a href="#第三步：案件分析-解读数据的“微表情”" class="headerlink" title="第三步：案件分析 - 解读数据的“微表情”"></a>第三步：案件分析 - 解读数据的“微表情”</h3><p>数据已经到手，现在是侦探时间。让我们逐一对比关键指标，看看它们背后隐藏了什么故事。</p><h4 id="故事主线：用户-User-时间-vs-内核-Sys-时间"><a href="#故事主线：用户-User-时间-vs-内核-Sys-时间" class="headerlink" title="故事主线：用户(User)时间 vs. 内核(Sys)时间"></a><strong>故事主线：用户(User)时间 vs. 内核(Sys)时间</strong></h4><ul><li><code>ls-mini</code>: <code>user</code> (1.027ms) ≈ <code>sys</code> (2.025ms)</li><li><code>ls</code>: <code>user</code> (0.00ms, 可忽略) &lt;&lt; <code>sys</code> (1.757ms)</li></ul><p><strong>结论</strong>：两个程序都是“系统调用密集型”的。它们的绝大部分工作都交给了内核去完成（读取目录和文件元数据）。ls 甚至将用户态的 CPU 时间压缩到了极致，体现了它作为一个成熟工具的高度优化。我们的 ls-mini 虽然用户态耗时也很短，但内核态耗时是用户态的两倍，这同样清晰地表明，程序的瓶颈在于与内核的交互，而非用户态的计算</p><h4 id="核心指标-1：IPC-每周期指令数-CPU-的效率"><a href="#核心指标-1：IPC-每周期指令数-CPU-的效率" class="headerlink" title="核心指标 1：IPC (每周期指令数) - CPU 的效率"></a><strong>核心指标 1：IPC (每周期指令数) - CPU 的效率</strong></h4><ul><li><code>ls-mini</code>: <strong>0.68</strong> insn per cycle</li><li><code>ls</code>: <strong>0.69</strong> insn per cycle</li></ul><p><strong>分析</strong>：惊人的一致性！我们自己写的简单代码，在开启 -O3 优化后，CPU 核心的计算效率竟然和官方 ls 几乎完全一样。这说明现代编译器非常智能。</p><h4 id="核心指标-2：分支预测-Branch-Misses-代码的“可预测性”"><a href="#核心指标-2：分支预测-Branch-Misses-代码的“可预测性”" class="headerlink" title="核心指标 2：分支预测 (Branch-Misses) - 代码的“可预测性”"></a><strong>核心指标 2：分支预测 (Branch-Misses) - 代码的“可预测性”</strong></h4><ul><li><code>ls-mini</code>: <strong>3.31%</strong> of all branches</li><li><code>ls</code>: <strong>3.99%</strong> of all branches</li></ul><p><strong>分析</strong>：现代 CPU 为了提速，会猜测 <code>if-else</code> 会走哪个分支并提前执行。如果猜错，代价巨大。这里的错误率非常接近，<code>ls-mini</code> 略有优势。为什么？因为我们的代码逻辑是“一本道”，几乎没有分支。而 <code>ls</code> 内部充满了对各种命令行参数（<code>-a</code>, <code>-l</code>, <code>-t</code>…）的检查，这些 <code>if</code> 判断会给分支预测器带来更多挑战。</p><h4 id="核心指标-3：-指令缓存效率-前端停滞-Frontend-Cycles-Idle-指令“塞车”了吗？"><a href="#核心指标-3：-指令缓存效率-前端停滞-Frontend-Cycles-Idle-指令“塞车”了吗？" class="headerlink" title="核心指标 3：(指令缓存效率)前端停滞 (Frontend Cycles Idle) - 指令“塞车”了吗？"></a><strong>核心指标 3：(指令缓存效率)前端停滞 (Frontend Cycles Idle) - 指令“塞车”了吗？</strong></h4><ul><li><code>ls-mini</code>: <strong>20.42%</strong> frontend cycles idle</li><li><code>ls</code>: <strong>42.17%</strong> frontend cycles idle</li></ul><p><strong>分析</strong>：既然 CPU 效率一样，性能瓶颈在哪？答案就在这里！官方 ls 因为代码量大、逻辑复杂，其指令缓存命中率远低于我们的小程序，导致 CPU 前端有超过 40% 的时间在空等指令，是 ls-mini 的两倍！这完美展示了代码体积和复杂度对缓存性能的直接影响。</p><h4 id="核心指标-4-指令数-Instructions"><a href="#核心指标-4-指令数-Instructions" class="headerlink" title="核心指标 4: 指令数 (Instructions)"></a><strong>核心指标 4: 指令数 (Instructions)</strong></h4><ul><li><code>ls-mini</code>: 2,216,772 instructions</li><li><code>ls</code>: 724,184 instructions</li></ul><p><strong>分析</strong>：<code>ls-mini</code> 执行的指令数几乎是 <code>ls</code> 的三倍。既然我们已经知道两者的核心 CPU 效率(IPC)几乎相同，那么这多出来的指令数就直接转化为了更长的执行时间。这些多出来的“工作量”从何而来？</p><p>很有可能有以下两个原因：</p><blockquote><ol><li><strong>库函数效率</strong>：我们天真地使用了 <code>printf</code> 函数。<code>printf</code> 为了处理各种复杂的格式化场景，其内部实现可能相当复杂，执行了大量指令。而 <code>ls</code> 作为性能攸关的核心工具，其输出部分几乎肯定是经过特殊优化的，可能直接通过 <code>write</code> 系统调用，避免了 <code>printf</code> 的额外开销。</li><li><strong>系统调用策略</strong>：我们的代码每次循环都调用 <code>readdir</code> 和 <code>stat</code>。而 <code>ls</code> 可能会使用更高级的系统调用（如 <code>getdents64</code>），一次性从内核读取多个目录项到用户空间的缓冲区，从而大大减少了循环次数和用户态&#x2F;内核态的切换开销。</li></ol></blockquote><h3 id="结论：我们学到了什么？"><a href="#结论：我们学到了什么？" class="headerlink" title="结论：我们学到了什么？"></a>结论：我们学到了什么？</h3><p>通过这个从零到一的简单实验，我们不仅用代码复现了 <code>ls</code> 的核心原理，更重要的是让 <code>perf</code> 的数据变得生动起来：</p><ol><li><strong>学会了诊断程序类型</strong>：通过对比 <code>user</code> 和 <code>sys</code> 时间，我们能迅速判断一个程序是 <strong>I&#x2F;O 密集型</strong> 还是 <strong>计算密集型</strong>，这是性能优化的第一步。</li><li><strong>见证了代码复杂度的代价</strong>：<code>ls-mini</code> 的简洁让它在<strong>指令缓存</strong>上表现出色（前端停滞率极低），而 <code>ls</code> 庞大的功能集则不可避免地付出了缓存性能的代价。这告诉我们，在高性能场景下，保持核心代码的<strong>小而美</strong>至关重要。</li><li><strong>理解了不同层面的性能</strong>：IPC 和分支预测揭示了 <strong>CPU 微架构层面</strong> 的效率；而指令数则反映了<strong>算法和工程实现层面</strong>的优劣。一个完整的性能画像需要兼顾两者。</li></ol><p><code>perf stat</code> 就像是医生用的听诊器，它让我们能对程序的“健康状况”有一个快速而全面的了解。但如果我们要进行“外科手术”，精确定位到是哪个函数出了问题，就需要更强大的工具。</p><p><strong>在下一篇文章中，我们将学习如何使用 <code>perf record</code> 和火焰图，来精确找到拖慢我们程序的“罪魁祸首”。敬请期待！</strong></p><h3 id="一个插曲：没去掉调试符号，公平吗？"><a href="#一个插曲：没去掉调试符号，公平吗？" class="headerlink" title="一个插曲：没去掉调试符号，公平吗？"></a>一个插曲：没去掉调试符号，公平吗？</h3><p>这是一个很好的问题。<code>gcc</code> 默认会包含调试符号，这会增大可执行文件的大小。我们可以用 <code>strip ls-mini</code> 命令去掉它们。</p><p><strong>这会影响公平性吗？</strong></p><ul><li><strong>对于核心运行时性能指标（如 IPC、分支预测），影响微乎其微。</strong> 因为这些指标衡量的是 CPU 执行代码时的行为，与文件里是否包含调试元数据无关。</li><li><strong>它会影响什么？</strong> 主要影响<strong>启动时间</strong>和**<code>page-faults</code>**。一个更大的文件需要从磁盘加载更多的页到内存，<code>page-faults</code> 可能会略高。在我们的例子中，<code>ls-mini</code> 的 <code>page-faults</code> (137) 确实比 <code>ls</code> (84) 多，部分原因可能就在于此。</li></ul><p>所以，对于我们这次的分析，这个对比<strong>足够公平</strong>，因为它恰好突出了代码大小和复杂度对缓存性能的巨大影响。</p>]]></content>
      
      
      <categories>
          
          <category> 技术实践 </category>
          
          <category> 系统工程 </category>
          
          <category> 性能工程 </category>
          
          <category> Linux性能分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 性能分析 </tag>
            
            <tag> 系统编程 </tag>
            
            <tag> 开源工具 </tag>
            
            <tag> Linux Perf </tag>
            
            <tag> perf </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>工程师的傲慢与偏见：我那价值2块钱的魔幻一小时</title>
      <link href="/2025/09/16/%E5%B7%A5%E7%A8%8B%E5%B8%88%E6%BC%AB%E8%B0%88/%E8%81%8C%E4%B8%9A%E6%80%9D%E8%80%83/%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84%E5%82%B2%E6%85%A2%E4%B8%8E%E5%81%8F%E8%A7%81%EF%BC%9A%E6%88%91%E9%82%A3%E4%BB%B7%E5%80%BC2%E5%9D%97%E9%92%B1%E7%9A%84%E9%AD%94%E5%B9%BB%E4%B8%80%E5%B0%8F%E6%97%B6/"/>
      <url>/2025/09/16/%E5%B7%A5%E7%A8%8B%E5%B8%88%E6%BC%AB%E8%B0%88/%E8%81%8C%E4%B8%9A%E6%80%9D%E8%80%83/%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84%E5%82%B2%E6%85%A2%E4%B8%8E%E5%81%8F%E8%A7%81%EF%BC%9A%E6%88%91%E9%82%A3%E4%BB%B7%E5%80%BC2%E5%9D%97%E9%92%B1%E7%9A%84%E9%AD%94%E5%B9%BB%E4%B8%80%E5%B0%8F%E6%97%B6/</url>
      
        <content type="html"><![CDATA[<h2 id="2-块钱，我学会了比-异地组网-和-SSH-更重要的一课"><a href="#2-块钱，我学会了比-异地组网-和-SSH-更重要的一课" class="headerlink" title="2 块钱，我学会了比 异地组网 和 SSH 更重要的一课"></a>2 块钱，我学会了比 异地组网 和 SSH 更重要的一课</h2><p>今天是我新实习的第二天。</p><p>上午的状态堪称完美，灵感迸发，顺手修复了团队内部工具的几个历史遗留 Bug，提交了几个赏心悦目的 PR。午饭后，我泡了杯咖啡，准备按照计划，深入学习一下性能分析领域的圣经——Brendan Gregg 的<a href="https://www.brendangregg.com/perf.html">‘perf’教程</a>。</p><span id="more"></span><p><strong>就在我打开<a href="https://www.brendangregg.com/perf.html">perf 圣经</a>的那一刻，那个“旧世界”的幽灵，通过手机震动，精准地找到了我。</strong></p><p>班长在群里艾特全体成员，语气急促地催促我们完成一个“全员心理测试”，并马上提交反馈截图。</p><p>“哇哦”，我想，“不想耽误时间，赶紧搞定它。”</p><p>我熟练地打开了手机上的“今日校园”App，点击了那个心理测评的链接。然后，屏幕上出现了一行熟悉的、令所有系统工程师血压飙升的错误提示。</p><p>打不开。</p><p>基于一个计算机人的直觉，我瞥了一眼无法访问的 URL：<code>https://xljkzx.neau.edu.cn/...</code>。</p><p><strong>NEAU 内网。</strong></p><p>妈呀，我在千里之外的宁波，一个只能访问公共互联网的地方，你要我如何访问一个大学的内网服务？我的大脑瞬间开始高速运转，一场与愚蠢设计之间的战争，就此打响。</p><h3 id="第一回合：我的“星际舰队”——Zerotier-全球组网与-SSH-动态隧道"><a href="#第一回合：我的“星际舰队”——Zerotier-全球组网与-SSH-动态隧道" class="headerlink" title="第一回合：我的“星际舰队”——Zerotier 全球组网与 SSH 动态隧道"></a>第一回合：我的“星际舰队”——Zerotier 全球组网与 SSH 动态隧道</h3><p>我马上想到了我之前为了校外租房，精心部署的一套“杀手级”远程访问方案。</p><p>在哈尔滨校内的某台实验室电脑上，我在 Hyper-V 虚拟机和宿主机中都安装了 Zerotier 客户端，并且接入了我自己部署在全球各地的 Moon 中继节点。理论上，我可以随时随地，将自己置身于那个熟悉的<code>10.10.x.x</code>网段。</p><p>我的计划堪称完美：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 通过Zerotier的虚拟网络，SSH连接到校内主机</span></span><br><span class="line"><span class="comment"># 2. 开启一个动态SOCKS5代理端口</span></span><br><span class="line">ssh -D 0.0.0.0:10086 Mice@10.10.52.9</span><br></pre></td></tr></table></figure><p>然后，我只需要让我的安卓手机，通过我现在单位的 WiFi，连接到我笔记本电脑上这个<code>10086</code>端口的代理。数据包将穿越层层网络，最终从东农的内网出口访问那个心理测试页面。优雅，太优雅了。</p><p>至于为什么不直接在远程电脑的浏览器里打开？天真！它有 SSO 单点登录和 UA 双重验证。在不知道<code>Cookie</code>和 App 原生<code>User-Agent</code>的情况下，任何模拟都无从下手。</p><p>然而，理想很美好，物理定律很骨感。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ping 10.10.52.9</span><br><span class="line"><span class="comment"># 丢包率: 40%, 延迟: 400ms</span></span><br></pre></td></tr></table></figure><p>这条横跨大半个中国的 TCP 连接，脆弱得像风中的烛火。我的“星际舰队”，在出发前就搁浅了。</p><h3 id="第二回合：降维打击的无奈——远程桌面与模拟器的“囚徒困境”"><a href="#第二回合：降维打击的无奈——远程桌面与模拟器的“囚徒困境”" class="headerlink" title="第二回合：降维打击的无奈——远程桌面与模拟器的“囚徒困境”"></a>第二回合：降维打击的无奈——远程桌面与模拟器的“囚徒困境”</h3><p>方案一失败，我立刻启动了更符合直觉的 Plan B：通过 AnyDesk 远程操作那台 Windows 电脑，在上面直接安装一个安卓模拟器。</p><p>但新的问题接踵而至。由于那台电脑开启了 Hyper-V，Windows 平台上的绝大多数安卓模拟器，都无法在不关闭 Hyper-V（需要重启）的情况下运行。唯一能“幸存”的，似乎只有蓝叠模拟器。</p><p>然而，当我费力地装好蓝叠，再装好“今日校园”后，App 启动的瞬间，它闪退了。</p><p><strong>虚拟机验证。</strong></p><p>妈呀，我幻灭了。我能想象到，这个垃圾软件的开发者，是如何通过各种手段，检测自己是否运行在虚拟环境中。而我，没有时间，也没有兴趣，去进行一场毫无意义的逆向工程战争。</p><p>就在这时，班长的微信电话打了过来，催促我快点提交。我看了看表，为了这个扯淡的问题，我已经浪费了一个多小时。</p><p>（我后来得知，当时还有很多在校内的同学也交不上，因为学校升级了锐捷 AP，现在不认证连内网都打不开了。我甚至还怀念起以前那个可以用 53 端口穿透校园网的“旧时代”。）</p><h3 id="最终回合：顿悟——“社会工程学”的胜利"><a href="#最终回合：顿悟——“社会工程学”的胜利" class="headerlink" title="最终回合：顿悟——“社会工程学”的胜利"></a>最终回合：顿悟——“社会工程学”的胜利</h3><p>就在我准备研究更复杂的 VPN 方案时，第三种方法，如同神启般浮现在我的脑海——<strong>花钱</strong>。</p><p>我打开了校园墙，输入了关键词。一条广告，像一道圣光，照亮了我愚蠢的执念：</p><p><strong>“代做心理测评，2 元全包，秒出截图。”</strong></p><p>我愣住了。</p><p>我，一个能部署全球虚拟网络、能熟练运用各种远程和虚拟化技术的“专家”，在一个愚蠢的系统面前，折腾了一个多小时，心力交瘁，一无所获。</p><p>而“专业人士”，只需要<strong>两块钱</strong>。</p><p>我速加微信，转账，发送手机号。两分钟后，一张完美的反馈截图，出现在了我的聊天窗口里。</p><p>我把它发给了班长。世界，清净了。</p><p>和那个代做的女生聊了几句，她也抱怨学校的种种险恶，说快待不下去了，也想出来。我笑着告诉她，不止计算机，可能每个专业都一样。我们相视一笑，尽在不言中。</p><p>今天，我没有学到太多<code>perf</code>的知识。但我用一个多小时的宝贵时间和两块钱的“学费”，深刻地理解了一个道理：</p><p><strong>一个优秀的工程师，不仅要懂得如何用技术解决复杂的问题。更要懂得，在什么时候，技术，恰恰是最低效、最愚蠢的解决方案。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 工程师漫谈 </category>
          
          <category> 职业思考 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 工程师思维 </tag>
            
            <tag> 技术反思 </tag>
            
            <tag> 效率 </tag>
            
            <tag> 社会工程学 </tag>
            
            <tag> 实习 </tag>
            
            <tag> 生活感悟 </tag>
            
            <tag> 技术与人性 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RKYOLO诞生记 (前传)：一切开始之前——那三个小时的“系统急救</title>
      <link href="/2025/09/10/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E9%83%A8%E7%BD%B2/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0-%E5%89%8D%E4%BC%A0-%EF%BC%9A%E4%B8%80%E5%88%87%E5%BC%80%E5%A7%8B%E4%B9%8B%E5%89%8D%E2%80%94%E2%80%94%E9%82%A3%E4%B8%89%E4%B8%AA%E5%B0%8F%E6%97%B6%E7%9A%84%E2%80%9C%E7%B3%BB%E7%BB%9F%E6%80%A5%E6%95%91/"/>
      <url>/2025/09/10/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E9%83%A8%E7%BD%B2/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0-%E5%89%8D%E4%BC%A0-%EF%BC%9A%E4%B8%80%E5%88%87%E5%BC%80%E5%A7%8B%E4%B9%8B%E5%89%8D%E2%80%94%E2%80%94%E9%82%A3%E4%B8%89%E4%B8%AA%E5%B0%8F%E6%97%B6%E7%9A%84%E2%80%9C%E7%B3%BB%E7%BB%9F%E6%80%A5%E6%95%91/</url>
      
        <content type="html"><![CDATA[<p>读到这里，你已经陪我走完了 <code>rkyolo</code> 从一个想法到一个功能完备的框架的全过程。但在这个故事开始之前，还有一段小插曲。它虽然只占了大概三个小时，却为后面所有的“顺利”铺平了道路，也算是一场有惊无险的“系统急救”演练。</p><span id="more"></span><h4 id="起因：一个不得不升的“驱动版本”"><a href="#起因：一个不得不升的“驱动版本”" class="headerlink" title="起因：一个不得不升的“驱动版本”"></a><strong>起因：一个不得不升的“驱动版本”</strong></h4><p>事情起因很简单：我开发板上的 RKNPU 驱动版本（<code>0.9.7</code>）太旧了，跑不了新模型。想接着玩，就得升级驱动。在嵌入式 Linux 上，这通常意味着一件事：<strong>得重新编译内核</strong>。</p><h4 id="过程：从编译到“系统懵了”"><a href="#过程：从编译到“系统懵了”" class="headerlink" title="过程：从编译到“系统懵了”"></a><strong>过程：从编译到“系统懵了”</strong></h4><p>对于搞过嵌入式的人来说，交叉编译内核算是个常规操作，无非是配置多、耗时长。我搭好环境，找来内核源码，第一个小麻烦就来了：</p><p>开发板上跑的内核版本是 <code>6.1.0</code>，但我在官方源码的标签里翻来翻去就是找不到完全一样的。最后靠着一行 <code>git tag -l</code> 进行地毯式搜索，才揪出了那个被“伪装”起来的特定版本——**<code>Ubuntu-rockchip-6.1.0-1025.25</code>**。算是明白了系统版的第一个小“花招”：表面版本号背后可能另有文章。</p><p>费了点功夫编译出内核产物后，真正的麻烦在部署时来了。一条看似平常的 <code>sudo tar -xzvf ... -C /</code> 指令，不知怎的，把我系统里 <code>/lib</code> 这个关键的符号链接给冲掉了。</p><p>一瞬间，系统就“懵了”。</p><p>所有依赖动态链接库的命令，像 <code>sudo</code>、<code>ls</code>、<code>mv</code>，全都报 <code>command not found</code>。系统没了最基础的“自理能力”，成了一块砖。</p><h4 id="救援：三小时“手动修砖”"><a href="#救援：三小时“手动修砖”" class="headerlink" title="救援：三小时“手动修砖”"></a><strong>救援：三小时“手动修砖”</strong></h4><p>常用的救援方法这时候都指望不上了。情况有点棘手，但还能救：</p><ol><li><p><strong>UMS 模式，“挂盘”修理</strong>：我用串口让开发板进入 UMS（USB Mass Storage）模式，然后在 Arch 主机上直接挂载了 eMMC 的分区。像做手术一样，我删掉了错误的 <code>/lib</code>，重新建好了正确的符号链接。</p></li><li><p><strong>重启，遇上新问题</strong>：系统总算活过来了，新内核也成功启动，NPU 驱动版本也更新了！可新的怪事又来了：有线网卡没了，<code>lsmod</code> 显示一片空白——内核模块全都没加载上。</p></li><li><p><strong>最后一步，“物归原处”</strong>：我愣了一下，突然想起之前救急时动过不少东西。敲了 <code>uname -a</code>，显示内核版本是 **<code>6.1.75+</code>**，但去 <code>find /lib/modules/</code> 里找，压根没这目录！我马上反应过来，估计是之前手忙脚乱，把放内核模块的整个目录给挪歪了。再次进 UMS 模式一查，果然如此。</p></li></ol><p><strong>一行 <code>mv</code> 命令，物归原处。</strong></p><p><strong>一次重启。</strong></p><p><strong>网络回来了，GPU 驱动正常了，所有模块都加载成功了。</strong></p><p><strong>好了，YOLO 程序终于可以跑起来了。</strong></p><h4 id="所以，为什么是-RKYOLO？"><a href="#所以，为什么是-RKYOLO？" class="headerlink" title="所以，为什么是 RKYOLO？"></a><strong>所以，为什么是 RKYOLO？</strong></h4><p>这紧张兮兮的三个小时，虽然没多久，却是我最后决定从头写 <code>rkyolo</code> 的真正原因。</p><p>正因为亲手经历了一次因为一个不小心就把整个系统搞崩的事，我才格外明白，在底层搞开发，<strong>代码的健壮性和行为的可预测性</strong>有多重要。</p><p>这也让我彻底想清楚了：</p><p>我需要的不是一个脆弱的、满是硬编码、构建复杂的 C++ 示例。我需要一个<strong>从设计之初就把安全和可靠放在首位的系统</strong>。</p><p>所以，我选择了 <strong>Rust</strong>，我决定自己搞一个 <strong>RKYOLO</strong>。</p><p>这个小插曲，就是 RKYOLO 之所以开始的理由。它不只是一个项目，更像是我对“怎么才能写好嵌入式软件”这个问题，交上的一份自己的答卷。</p>]]></content>
      
      
      <categories>
          
          <category> 技术实践 </category>
          
          <category> 人工智能 </category>
          
          <category> 计算机视觉 </category>
          
          <category> 边缘计算部署 </category>
          
          <category> RKYOLO诞生记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> YOLO </tag>
            
            <tag> 系统编程 </tag>
            
            <tag> Rust </tag>
            
            <tag> AI </tag>
            
            <tag> 嵌入式 </tag>
            
            <tag> 开源 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RKYOLO诞生记 (七)：小结与展望——折腾不止，快乐不息</title>
      <link href="/2025/09/10/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E9%83%A8%E7%BD%B2/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0-%E4%B8%83-%EF%BC%9A%E5%B0%8F%E7%BB%93%E4%B8%8E%E5%B1%95%E6%9C%9B%E2%80%94%E2%80%94%E6%8A%98%E8%85%BE%E4%B8%8D%E6%AD%A2%EF%BC%8C%E5%BF%AB%E4%B9%90%E4%B8%8D%E6%81%AF/"/>
      <url>/2025/09/10/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E9%83%A8%E7%BD%B2/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0-%E4%B8%83-%EF%BC%9A%E5%B0%8F%E7%BB%93%E4%B8%8E%E5%B1%95%E6%9C%9B%E2%80%94%E2%80%94%E6%8A%98%E8%85%BE%E4%B8%8D%E6%AD%A2%EF%BC%8C%E5%BF%AB%E4%B9%90%E4%B8%8D%E6%81%AF/</url>
      
        <content type="html"><![CDATA[<p>好了好了，到了给这个系列收尾的时候了。回头看看，这个叫 <code>rkyolo</code> 的小东西，从一个念头开始，居然真的被我一点点攒成了一个能跑、能看、还能给自己打分的 Rust 推理框架，想想也是挺神奇的。</p><p>在这最后一篇，咱不吹牛，就唠点实在的。说说我都捣鼓了啥，还有哪些地方让我挠头，以及以后还能怎么接着玩。</p><span id="more"></span><h4 id="技术的积累与兑现"><a href="#技术的积累与兑现" class="headerlink" title="技术的积累与兑现"></a><strong>技术的积累与兑现</strong></h4><p>这个项目的推进，很大程度上得益于之前在一些技术领域的持续投入和实践。</p><ul><li>对 <strong>Rust</strong> 的持续学习和使用，让我能相对顺利地处理 FFI 和安全问题；</li><li>对 <strong>YOLO</strong> 模型原理的理解，帮助我在遇到“指鹿为马”或结构崩溃时，能较快地定位到本质；</li><li>之前和 <strong>Linux</strong>、交叉编译打交道的经验，也为整个项目铺平了道路。</li></ul><p>回头看看，技术成长确实离不开积累，很多之前的摸索都在这个项目里用上了。</p><h4 id="哪哪都是可以接着折腾的地方"><a href="#哪哪都是可以接着折腾的地方" class="headerlink" title="哪哪都是可以接着折腾的地方"></a><strong>哪哪都是可以接着折腾的地方</strong></h4><p>写代码最怕的就是觉得自己搞出来的东西完美无缺。我心里门儿清，<code>rkyolo</code> 也就是个“能用”的水平，离“好用”还差得远呢：</p><ol><li><p><strong>一根筋的流程</strong>：现在处理视频是一帧一帧来的，等上一帧全忙活完了才下一帧。要是想同时处理好多路视频，这肯定得卡成 PPT。以后得用上 <code>tokio</code> 这类异步运行时，让它们同时干活，效率才能上去。</p></li><li><p><strong>CPU 老黄牛</strong>：缩放图片、填白边这些杂活全是 CPU 在干。但其实 RK3588 板子上有个叫 <strong>RGA</strong> 的硬件小弟（专门处理 2D 图形），活好还不占 CPU 资源。下次得想办法让它来扛活。</p></li><li><p><strong>还不够灵活</strong>：现在的后处理虽然能自适应不同输出，但基本还是围着 YOLO 转。万一以后想跑个结构完全不一样的模型（比如基于 Transformer 的），可能就歇菜了。我看 Rockchip 的 SDK 里提到了自定义算子的功能，说不定以后可以搞个<strong>插件系统</strong>，让用户自己写处理逻辑，那可就太酷了。</p></li></ol><h4 id="画个未来的大饼"><a href="#画个未来的大饼" class="headerlink" title="画个未来的大饼"></a><strong>画个未来的大饼</strong></h4><p><code>rkyolo</code> 解决了模型在板子上跑起来和评估的问题，但在这之前，还得先把模型转成 RKNN 格式。我之前用 Docker 封装了一个<a href="https://github.com/cagedbird043/RKNN-Toolkit2">转换工具</a>，一行命令就能转模型：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pt2rknn --pt_model ... --output ... --platform rk3588 --quant_mode i8 --data_yaml ...</span><br></pre></td></tr></table></figure><p>我下一个想折腾的，是<strong>把这个转换过程做成个网页服务</strong>。想象一下，以后用户只需要在网页上传个模型文件，点几下按钮，就能下载转换好的模型，是不是方便多了？最后再把模型转换和 <code>rkyolo</code> 部署连起来，搞个一条龙服务，从训练到部署都不叫事儿。</p><h4 id="最后唠点心里话"><a href="#最后唠点心里话" class="headerlink" title="最后唠点心里话"></a><strong>最后唠点心里话</strong></h4><p>捣鼓 <code>rkyolo</code> 的整个过程，让我着迷的其实不光是目标检测本身。</p><p>不管是琢磨怎么让 NPU 多核并行干活，还是死磕怎么把数据直接塞进硬件省掉拷贝，甚至是做个工具来自动找出模型在哪儿犯了蠢……我发现我真正乐在其中的，是<strong>把一个个复杂的系统理顺、调通、然后让它跑得更快更好的这个过程</strong>。</p><p><code>rkyolo</code> 就是我这个想法的一次实践，算是个开始。以后的路还长着呢，肯定还有更多好玩又烧脑的东西在等着。</p><p>我已经等不及想看看下一站又能折腾点啥出来了！</p>]]></content>
      
      
      <categories>
          
          <category> 技术实践 </category>
          
          <category> 人工智能 </category>
          
          <category> 计算机视觉 </category>
          
          <category> 边缘计算部署 </category>
          
          <category> RKYOLO诞生记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> YOLO </tag>
            
            <tag> 系统编程 </tag>
            
            <tag> Rust </tag>
            
            <tag> AI </tag>
            
            <tag> 嵌入式 </tag>
            
            <tag> 开源 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RKYOLO诞生记 (六)：构建完整评估工具链——rkyolo-eval的实践与洞察</title>
      <link href="/2025/09/10/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E9%83%A8%E7%BD%B2/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0-%E5%85%AD-%EF%BC%9A%E6%9E%84%E5%BB%BA%E5%AE%8C%E6%95%B4%E8%AF%84%E4%BC%B0%E5%B7%A5%E5%85%B7%E9%93%BE%E2%80%94%E2%80%94rkyolo-eval%E7%9A%84%E5%AE%9E%E8%B7%B5%E4%B8%8E%E6%B4%9E%E5%AF%9F/"/>
      <url>/2025/09/10/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E9%83%A8%E7%BD%B2/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0-%E5%85%AD-%EF%BC%9A%E6%9E%84%E5%BB%BA%E5%AE%8C%E6%95%B4%E8%AF%84%E4%BC%B0%E5%B7%A5%E5%85%B7%E9%93%BE%E2%80%94%E2%80%94rkyolo-eval%E7%9A%84%E5%AE%9E%E8%B7%B5%E4%B8%8E%E6%B4%9E%E5%AF%9F/</url>
      
        <content type="html"><![CDATA[<p>在完成了<code>rKYOLO</code>核心推理引擎和多种 IO 功能后，项目已经具备了完整的应用能力。然而，我深知在机器学习项目中，可靠的评估体系与高效的推理能力同等重要。为此，我构建了<code>rkyolo-eval</code>工具链，为项目增添了专业的模型评估能力。</p><span id="more"></span><h4 id="从直觉到量化：建立专业评估体系"><a href="#从直觉到量化：建立专业评估体系" class="headerlink" title="从直觉到量化：建立专业评估体系"></a><strong>从直觉到量化：建立专业评估体系</strong></h4><p>当模型从 FP32 精度量化到 INT8 并部署到边缘设备后，性能变化必须被精确衡量而非仅凭主观感受。我建立的评估体系包含两个核心指标：</p><ul><li><strong><a href="mailto:&#x6d;&#x41;&#80;&#x40;&#48;&#x2e;&#53;">&#x6d;&#x41;&#80;&#x40;&#48;&#x2e;&#53;</a></strong>：采用目标检测领域的黄金标准，确保评估结果与学术界和工业界标准完全兼容，为性能比较提供可靠基准</li><li>**R² (决定系数)**：针对实际应用场景的创新指标，专门评估模型在物体计数任务上的准确性，直接反映业务价值</li></ul><h4 id="高效评估架构：解耦推理与评估"><a href="#高效评估架构：解耦推理与评估" class="headerlink" title="高效评估架构：解耦推理与评估"></a><strong>高效评估架构：解耦推理与评估</strong></h4><p>通过设计<code>predictions.json</code>中间文件，实现了推理过程与评估过程的完全解耦。这种架构带来显著优势：</p><ul><li>无需重复运行耗时的模型推理即可进行多次评估</li><li>支持快速调整评估参数和迭代评估算法</li><li>评估结果完全可重现，确保实验的可靠性</li></ul><h4 id="智能问题定位：离群点分析系统"><a href="#智能问题定位：离群点分析系统" class="headerlink" title="智能问题定位：离群点分析系统"></a><strong>智能问题定位：离群点分析系统</strong></h4><p>我开发的离群点报告功能彻底改变了问题排查方式。以下是一次实际的离群点分析结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[INFO rkyolo_eval::map_computer]</span><br><span class="line">--- 离群点分析报告 (数量差异 &gt; 20) ---</span><br><span class="line">[INFO rkyolo_eval::map_computer] 图像名称                               | 真实数量 | 预测数量 | 差异</span><br><span class="line">[INFO rkyolo_eval::map_computer] ------------------------------------------|----------|----------|--------</span><br><span class="line">[INFO rkyolo_eval::map_computer] DJI_0992__2__0_0.JPG                     | 91       | 58       | 33</span><br><span class="line">[INFO rkyolo_eval::map_computer] DJI_0313__2__1_0.JPG                     | 112      | 79       | 33</span><br><span class="line">[INFO rkyolo_eval::map_computer] DJI_0722__2__1_0.JPG                     | 91       | 62       | 29</span><br></pre></td></tr></table></figure><p>这个自动化分析工具能够快速识别出问题最严重的样本，让开发者能够立即聚焦于关键问题，极大提升了调试效率。</p><h4 id="深度调试能力：匹配过程追踪"><a href="#深度调试能力：匹配过程追踪" class="headerlink" title="深度调试能力：匹配过程追踪"></a><strong>深度调试能力：匹配过程追踪</strong></h4><p>对于需要深入分析的情况，我还实现了细粒度的调试功能。通过 trace 级别的日志，可以完整追踪每个预测框的匹配过程：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[TRACE rkyolo_eval::map_computer] 处理预测框: conf=0.8912, bbox=(450.2, 315.8, 495.1, 360.4)</span><br><span class="line">[TRACE rkyolo_eval::map_computer] 与真实框 #44 匹配: IoU=0.8521 &gt; 阈值 0.50，判定为TP</span><br><span class="line">[TRACE rkyolo_eval::map_computer] 与真实框 #45 匹配: IoU=0.0213，继续寻找更好匹配</span><br></pre></td></tr></table></figure><p>这种深度可视化能力确保了评估算法的正确性，为算法优化提供了坚实基础。</p><h4 id="统一配置管理：dataset-yaml"><a href="#统一配置管理：dataset-yaml" class="headerlink" title="统一配置管理：dataset.yaml"></a><strong>统一配置管理：dataset.yaml</strong></h4><p>采用标准的<code>dataset.yaml</code>配置文件，确保训练、推理和评估阶段使用完全一致的数据集，避免了手动转换成数据集的麻烦。</p><p>现在，整个工作流程形成了一个完整的闭环：使用统一的配置生成预测结果，通过专业工具进行量化评估，利用智能分析定位问题，最后基于洞察进行模型优化。这套工具链不仅提供了准确的性能度量，更重要的是为持续改进提供了明确的方向和数据支持。</p><p><strong>总结</strong><br><code>rkyolo-eval</code>的构建体现了一个重要理念：完整的项目不仅需要强大的推理能力，更需要专业的评估体系。通过这套工具链，我能够准确量化模型性能，快速定位问题根源，并为优化提供数据驱动的决策依据。这套完整的解决方案确保了项目从原型到产品化的顺利过渡，体现了工程实践的成熟度和专业性。</p>]]></content>
      
      
      <categories>
          
          <category> 技术实践 </category>
          
          <category> 人工智能 </category>
          
          <category> 计算机视觉 </category>
          
          <category> 边缘计算部署 </category>
          
          <category> RKYOLO诞生记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> YOLO </tag>
            
            <tag> 系统编程 </tag>
            
            <tag> Rust </tag>
            
            <tag> AI </tag>
            
            <tag> 嵌入式 </tag>
            
            <tag> 开源 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RKYOLO诞生记 (五)：从静态图片到实时视频——全功能应用的构建之旅</title>
      <link href="/2025/09/10/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E9%83%A8%E7%BD%B2/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0-%E4%BA%94-%EF%BC%9A%E4%BB%8E%E9%9D%99%E6%80%81%E5%9B%BE%E7%89%87%E5%88%B0%E5%AE%9E%E6%97%B6%E8%A7%86%E9%A2%91%E2%80%94%E2%80%94%E5%85%A8%E5%8A%9F%E8%83%BD%E5%BA%94%E7%94%A8%E7%9A%84%E6%9E%84%E5%BB%BA%E4%B9%8B%E6%97%85/"/>
      <url>/2025/09/10/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E9%83%A8%E7%BD%B2/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0-%E4%BA%94-%EF%BC%9A%E4%BB%8E%E9%9D%99%E6%80%81%E5%9B%BE%E7%89%87%E5%88%B0%E5%AE%9E%E6%97%B6%E8%A7%86%E9%A2%91%E2%80%94%E2%80%94%E5%85%A8%E5%8A%9F%E8%83%BD%E5%BA%94%E7%94%A8%E7%9A%84%E6%9E%84%E5%BB%BA%E4%B9%8B%E6%97%85/</url>
      
        <content type="html"><![CDATA[<p>在前几轮的扎实工作后，RKYOLO 的核心推理引擎已经变得相当可靠：安全、自适应且性能良好。但它当时更像一个“库”，离一个开箱即用的“工具”还有一步之遥。我的下一个目标，就是为这个强大的引擎，打造一个完整的外壳，让它能灵活地处理现实世界中的各种视觉输入。</p><span id="more"></span><h4 id="功能一：构建统一的输入源处理"><a href="#功能一：构建统一的输入源处理" class="headerlink" title="功能一：构建统一的输入源处理"></a><strong>功能一：构建统一的输入源处理</strong></h4><p>我希望这个应用能足够通用。用户可能需要处理一张图片、一个包含多张图片的文件夹、一个视频文件，或者直接连接一个像 <code>/dev/video0</code> 这样的摄像头设备。为每种情况都写一个单独的程序显然不够优雅。</p><p>解决方案的核心在于架构设计：如何用统一的接口来处理这些不同的输入类型？在 Rust 中，<strong>枚举（enum）</strong> 完美地表达了“多种可能类型中的一种”这个概念。于是，<code>InputSource</code> 这个核心设计便应运而生。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">enum</span> <span class="title class_">InputSource</span> &#123;</span><br><span class="line">    <span class="title function_ invoke__">SingleImage</span>(PathBuf),</span><br><span class="line">    <span class="title function_ invoke__">ImageDirectory</span>(PathBuf),</span><br><span class="line">    <span class="title function_ invoke__">VideoFile</span>(PathBuf),</span><br><span class="line">    <span class="title function_ invoke__">CameraDevice</span>(<span class="type">i32</span>), <span class="comment">// 存储摄像头ID</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>有了这个枚举，<code>main.rs</code> 的逻辑变得清晰而简洁：</p><ol><li><strong>统一入口</strong>：只保留一个 <code>--source</code> 参数来接收用户输入的字符串。</li><li><strong>智能解析</strong>：在应用启动时，一段解析逻辑会检查这个字符串：<ul><li>以 <code>/dev/video</code> 开头？解析出设备 ID，包装成 <code>InputSource::CameraDevice(id)</code>。</li><li>以 <code>.mp4</code> 等视频扩展名结尾？包装成 <code>InputSource::VideoFile(path)</code>。</li><li>路径指向一个目录？包装成 <code>InputSource::ImageDirectory(path)</code>。</li><li>否则，视为 <code>InputSource::SingleImage(path)</code>。</li></ul></li><li><strong>清晰分发</strong>：解析完成后，一个简洁的 <code>match</code> 语句就能处理所有情况，每个分支调用相应的处理函数，如 <code>process_video_source</code> 或 <code>process_directory</code>。这个设计的优雅之处在于它的可扩展性——未来若要支持网络流（RTSP），只需在枚举中添加一个新变体并在 <code>match</code> 中添加一个分支即可，编译器会确保所有情况都得到处理。</li></ol><h4 id="功能二：集成-OpenCV-处理视频流"><a href="#功能二：集成-OpenCV-处理视频流" class="headerlink" title="功能二：集成 OpenCV 处理视频流"></a><strong>功能二：集成 OpenCV 处理视频流</strong></h4><p>处理视频和摄像头自然离不开 OpenCV。在 Rust 中集成这个庞大的 C++库，尤其是在交叉编译到 ARM64 开发板时，并非总是那么顺利。<code>opencv-rust</code> 这个 crate 有时会因找不到头文件或链接库而编译失败。</p><p>初始编译确实遇到了问题。基于以往的经验，我添加了 <code>features = [&quot;clang-runtime&quot;]</code> 这个特性，它使得 <code>opencv-rust</code> 的构建脚本在运行时使用 <code>libclang</code> 来解析头文件，而不是依赖可能不完整的系统预设路径。这个调整顺利解决了编译问题。</p><p>数据流转的过程比预想的要顺畅。关键在于颜色空间转换。摄像头通常输出 BGR 格式的 <code>cv::Mat</code>，而我们的 NPU 模型需要 RGB 格式。因此，处理循环的第一步总是调用 <code>imgproc::cvt_color(...)</code> 进行转换。转换后，从 RGB 格式的 <code>Mat</code> 中获取原始字节流就非常直接了，<code>mat.data_bytes()?</code> 返回一个 <code>&amp;[u8]</code> 切片，这正是我们 <code>_from_buffer</code> 系列预处理函数所需的完美输入。</p><h4 id="功能三：打造流畅的用户体验"><a href="#功能三：打造流畅的用户体验" class="headerlink" title="功能三：打造流畅的用户体验"></a><strong>功能三：打造流畅的用户体验</strong></h4><p>对于一个实时视频应用，用户体验至关重要。一个光秃秃的视频窗口是远远不够的。</p><ul><li><p><strong>FPS 计数器</strong>：需要一个直观的性能指标。实现起来简单有效：在循环外记录一个起始时间，在循环内累加帧数。每当经过一秒，就用“帧数 &#x2F; 经过的秒数”来计算平均 FPS，更新显示字符串，并重置计数器和计时器。这样得到的读数稳定，不会像瞬时 FPS 那样剧烈跳动，看起来非常专业。</p></li><li><p>**无头模式 (<code>--headless</code>)**：这个功能完全是出于通用性的考虑。<code>rkyolo</code> 不应该只是一个交互式工具。如果需要在服务器上运行批处理脚本或作为后台服务，弹出 GUI 窗口将是灾难性的。<code>--headless</code> 参数使得应用能够一键切换身份，融入任何自动化流程。</p></li><li><p><strong>优雅退出</strong>：通过 <code>waitKey(1)</code> 检测 <code>ESC</code> 键，允许用户随时优雅地终止程序。这是一个合格实时应用的基本素养。</p></li></ul><h4 id="功能四：探索硬件加速编码"><a href="#功能四：探索硬件加速编码" class="headerlink" title="功能四：探索硬件加速编码"></a><strong>功能四：探索硬件加速编码</strong></h4><p>这是整个视频功能开发中一次令人兴奋的探索！</p><p>在实现了视频录制功能(<code>--output-video</code>)后，我通过 <code>htop</code> 观察到 CPU 占用率较高，原因是 OpenCV 在使用 <code>libx264</code> 进行软件编码。我知道 RK3588 拥有强大的 RKMPP 硬件视频编码器，便思考如何让 OpenCV 利用它。</p><p>最初的想法比较复杂，考虑修改 <code>opencv</code> crate 的源码或自行封装 FFmpeg 接口。随后，我记起了一个经典的 Linux&#x2F;Unix 哲学：<strong>“一切皆可配置”</strong>。是否存在一种方式，能够在不修改代码的情况下，“影响”底层库的行为？</p><p>果然，我找到了！OpenCV 的 <code>VideoWriter</code> 底层调用 FFmpeg，而 FFmpeg 的行为可以通过<strong>环境变量</strong>来注入参数。这个发现非常巧妙。</p><p>接下来的实现充满了创造性。我没有在程序启动前全局设置环境变量，那样过于粗暴。相反，我使用了 <code>std::env::set_var</code>，在调用 <code>VideoWriter::new()</code> <strong>之前</strong>，临时将环境变量 <code>OPENCV_FFMPEG_WRITER_OPTIONS</code> 设置为 <code>-codec:v h264_rkmpp</code>。这个操作被封装在一个 Guard 对象中，确保在该对象离开作用域时，环境变量会自动恢复原样。这是一种极其精准、非侵入式的方法，成功地“引导”了 OpenCV 去尝试调用 RKMPP 硬件编码器。</p><p><strong>（实事求是的说明）</strong></p><blockquote><p>需要坦诚的是，在后续的深入测试中，由于 OpenCV、FFmpeg 版本与底层驱动之间复杂的交互，当前设置的环境变量<strong>并未能 100%成功激活</strong>RKMPP 硬件编码。但这并不能否定该方法所展现的思路的巧妙性。它证明了我们有能力在不修改第三方库源码的情况下，对其行为进行精准干预。我相信，随着对底层细节的进一步探索，完全激活硬件编码是可行的。</p></blockquote><p>当我成功录制视频并构想出未来 CPU 占用率大幅降低的场景时，我知道，我们又在扩展功能边界上前进了一步。从一个处理静态图片的库，到一个能够应对多种输入、提供良好体验的全功能应用，整个构建过程充满了探索和实现的乐趣。</p>]]></content>
      
      
      <categories>
          
          <category> 技术实践 </category>
          
          <category> 人工智能 </category>
          
          <category> 计算机视觉 </category>
          
          <category> 边缘计算部署 </category>
          
          <category> RKYOLO诞生记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> YOLO </tag>
            
            <tag> 系统编程 </tag>
            
            <tag> Rust </tag>
            
            <tag> AI </tag>
            
            <tag> 嵌入式 </tag>
            
            <tag> 开源 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RKYOLO诞生记 (四)：零拷贝踩坑记 —— 和内存搬运说再见</title>
      <link href="/2025/09/10/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E9%83%A8%E7%BD%B2/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0-%E5%9B%9B-%EF%BC%9A%E9%9B%B6%E6%8B%B7%E8%B4%9D%E8%B8%A9%E5%9D%91%E8%AE%B0-%E2%80%94%E2%80%94-%E5%92%8C%E5%86%85%E5%AD%98%E6%90%AC%E8%BF%90%E8%AF%B4%E5%86%8D%E8%A7%81/"/>
      <url>/2025/09/10/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E9%83%A8%E7%BD%B2/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0-%E5%9B%9B-%EF%BC%9A%E9%9B%B6%E6%8B%B7%E8%B4%9D%E8%B8%A9%E5%9D%91%E8%AE%B0-%E2%80%94%E2%80%94-%E5%92%8C%E5%86%85%E5%AD%98%E6%90%AC%E8%BF%90%E8%AF%B4%E5%86%8D%E8%A7%81/</url>
      
        <content type="html"><![CDATA[<p>前面的文章里，我们给 RKYOLO 搭好了结实的地基——安全的 FFI 层和聪明的后处理。项目是能跑了，但作为一个爱折腾的人，我总觉得还能再抠点性能出来。</p><p>当我琢磨怎么用它来处理实时视频流时，我意识到真正的挑战来了。目标不再是“能跑”，而是得“跑得飞起”。为此，我决定去碰一碰性能优化里最硬的那块骨头——**零拷贝(Zero-Copy)**。</p><span id="more"></span><h4 id="为啥先跟“零拷贝”过不去？"><a href="#为啥先跟“零拷贝”过不去？" class="headerlink" title="为啥先跟“零拷贝”过不去？"></a><strong>为啥先跟“零拷贝”过不去？</strong></h4><p>你可能会想，为啥不先做视频播放这些看得见的功能呢？</p><p>我的想法很简单：得先把基础打牢。零拷贝是底层性能的根基。处理一张图时，省下那几毫秒可能感觉不出来，但要是每秒处理 30 帧、60 帧视频，这点时间省下来就是天壤之别。我得先让“引擎”马力十足，再去考虑“车身”漂不漂亮。</p><h4 id="性能暗坑：那个偷偷干活的memcpy"><a href="#性能暗坑：那个偷偷干活的memcpy" class="headerlink" title="性能暗坑：那个偷偷干活的memcpy"></a><strong>性能暗坑：那个偷偷干活的<code>memcpy</code></strong></h4><p>首先得找到问题在哪儿。在标准的推理流程里，<code>rknn_inputs_set</code> 这个函数看起来没啥，但它背后偷偷执行了一次内存拷贝（<code>memcpy</code>）。CPU 得把预处理好的图像数据，从用户态内存复制一份到 NPU 能直接访问的物理内存（DMA 缓冲区）里。</p><p>这就像有个手脚麻利的厨师（NPU），但每次做菜前，都得等一个慢悠悠的服务员（CPU）把食材从仓库（CPU 内存）搬到灶台（NPU 内存）上。厨师大部分时间都在干等，整体效率自然高不了。</p><p>零拷贝就是想绕开这个服务员，让食材直接出现在厨师的灶台上，彻底省掉“搬运”这步。</p><h4 id="三步搞定零拷贝：和硬件直接打交道"><a href="#三步搞定零拷贝：和硬件直接打交道" class="headerlink" title="三步搞定零拷贝：和硬件直接打交道"></a><strong>三步搞定零拷贝：和硬件直接打交道</strong></h4><p>要实现零拷贝，就不能再用现成的高级 API 了。我啃了瑞芯微的官方开发文档，总算摸清了门路。</p><p><strong>(图：官方零拷贝 API 调用流程图)</strong><br><img data-src="/img/2025/9/10/rknn_zero_copy_flow.png" alt="图：官方零拷贝 API 调用流程图" title="瑞芯微官方文档里的零拷贝流程图，指明了rknn_create_mem和rknn_set_io_mem是关键。"><br><em>图注：瑞芯微官方文档里的零拷贝流程图，指明了<code>rknn_create_mem</code>和<code>rknn_set_io_mem</code>是关键。</em></p><p>照着这份“地图”，我开始了零拷贝的“三步走”：</p><p><strong>1. 先问问 NPU 喜欢啥样的“盘子” (<code>query_native_input_attrs</code>)</strong></p><p>文档里特别强调了要查“原生”属性：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rknn_query()</span><br><span class="line">输入:</span><br><span class="line">用RKNN_QUERY_NATIVE_INPUT_ATTR查询相关的属性（注意，不是</span><br><span class="line">RKNN_QUERY_INPUT_ATTR）. ... 该方式查询出来的是输入硬件效率最优的layout和type。</span><br></pre></td></tr></table></figure><p>这个 <code>NATIVE</code> 版本的查询特别关键，它能告诉我 NPU 硬件<strong>原生的</strong>内存布局要求，这些要求往往很具体：</p><p><strong>(图：官方零拷贝输入对齐要求)</strong><br><img data-src="/img/2025/9/10/rknn_zero_copy_alignment.png" alt="图：官方零拷贝输入对齐要求" title="瑞芯微官方文档里关于零拷贝输入的对齐要求。"><br><em>图注：官方文档说，在 RK3588 上，4 维输入的通道需要做 16 字节对齐。</em></p><p>这个对齐要求，最终体现在 <code>rknn_tensor_attr</code> 结构体的一个参数上——<code>w_stride</code>（行步长）。这是搞定零拷贝的第一把钥匙。</p><p><strong>2. 在厨房申请个“专用灶台” (<code>rknn_create_mem</code>)</strong></p><p>下一步是 <code>rknn_create_mem</code>。这个函数会在 DMA（直接内存访问）区域申请一块“专用灶台”。这块内存很神奇，CPU 和 NPU 都能直接访问。</p><p><strong>3. 告诉 NPU 以后就用这个“灶台” (<code>rknn_set_io_mem</code>)</strong></p><p>最后，通过 <code>rknn_set_io_mem</code>，我告诉 NPU：“以后你的输入，就直接从我刚申请的那块 DMA 内存里读，别的地方不用看了。”</p><h4 id="踩坑实录：零拷贝从来不会乖乖工作"><a href="#踩坑实录：零拷贝从来不会乖乖工作" class="headerlink" title="踩坑实录：零拷贝从来不会乖乖工作"></a><strong>踩坑实录：零拷贝从来不会乖乖工作</strong></h4><p>当我按这个流程实现完，一运行——得，模型输出又花屏了！得，又掉进和硬件打交道的坑里了。</p><h5 id="第一个坑：步长单位的迷惑"><a href="#第一个坑：步长单位的迷惑" class="headerlink" title="第一个坑：步长单位的迷惑"></a><strong>第一个坑：步长单位的迷惑</strong></h5><p>我马上打开详细日志，在预处理函数里加打印。很快就发现了关键线索：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[DEBUG rkyolo_core] Quantization and stride-aware copy complete. Line bytes=1920, Stride bytes=640</span><br></pre></td></tr></table></figure><p><strong>出问题了！</strong> 一行图像数据实际有 <code>640*3=1920</code> 字节，但日志显示步长只有 <code>640</code>。我立刻反应过来：我搞错了 <code>w_stride</code> 的单位！我以为是<strong>字节</strong>，其实它代表的是<strong>像素</strong>！</p><p>我回去翻文档，看到这么一句：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">b. 当layout为 RKNN_TENSOR_NHWC 时，... 需要注意的是当 pass_through=1 时，width可能需要做stride对齐，具体取决于查询出来的 w_stride的值。</span><br></pre></td></tr></table></figure><p>果然如此。NPU 为了对齐内存，硬件层面处理的“行”宽度（<code>w_stride</code>，单位像素）可能比图像实际宽度大。我之前的理解错了，导致内存写飞了。</p><p>赶紧修正步长计算：<code>let stride_bytes = w_stride as usize * 3;</code>。就这小小的 <code>* 3</code>，是我踩坑换来的教训。</p><h5 id="第二个坑：隐藏的数据类型陷阱"><a href="#第二个坑：隐藏的数据类型陷阱" class="headerlink" title="第二个坑：隐藏的数据类型陷阱"></a><strong>第二个坑：隐藏的数据类型陷阱</strong></h5><p>修好步长，结果还是不对。我想起上次“指鹿为马”的教训，马上怀疑是数据类型问题。在零拷贝模式下，我需要把 <code>i8</code> 类型的量化值直接写入 <code>&amp;mut [u8]</code> 类型的 DMA 缓冲区。我一开始这么写：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 错误写法</span></span><br><span class="line"><span class="keyword">let</span> <span class="variable">val_i8</span>: <span class="type">i8</span> = -<span class="number">10</span>;</span><br><span class="line"><span class="keyword">let</span> <span class="variable">val_u8</span>: <span class="type">u8</span> = val_i8 <span class="keyword">as</span> <span class="type">u8</span>; <span class="comment">// 数值转换！-10会变成246</span></span><br></pre></td></tr></table></figure><p>这是个很隐蔽的坑。<code>as u8</code> 做的是<strong>数值转换</strong>，会彻底破坏负数的二进制表示。正确做法是<strong>按位转换</strong>，保留原始的二进制位。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 正确做法</span></span><br><span class="line"><span class="keyword">let</span> <span class="variable">val_i8</span>: <span class="type">i8</span> = -<span class="number">10</span>;</span><br><span class="line"><span class="keyword">let</span> <span class="variable">byte</span>: <span class="type">u8</span> = val_i8.<span class="title function_ invoke__">to_le_bytes</span>()[<span class="number">0</span>]; <span class="comment">// 按位转换</span></span><br></pre></td></tr></table></figure><p>修好这个隐藏的 Bug 后，零拷贝模式下的推理结果，总算和标准模式一样了！</p><h4 id="留个后路：追求速度，但不能不顾稳定"><a href="#留个后路：追求速度，但不能不顾稳定" class="headerlink" title="留个后路：追求速度，但不能不顾稳定"></a><strong>留个后路：追求速度，但不能不顾稳定</strong></h4><p>零拷贝是搞定了，但我又想了想：万一程序跑在旧驱动上，不支持零拷贝咋办？直接崩了可不行。</p><p>所以，我做了个<strong>“优雅降级”</strong>机制。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">enum</span> <span class="title class_">ExecutionMode</span> &#123;</span><br><span class="line">    ZeroCopy &#123; ... &#125;,</span><br><span class="line">    Standard,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我搞了个 <code>ExecutionMode</code> 枚举来代表两种运行模式。程序启动时，会调用 <code>try_setup_zero_copy</code> 函数尝试初始化零拷贝。这里每一步都包在 <code>Result</code> 里，任何一步失败了，它不会崩，而是打条警告日志，然后退回 <code>Standard</code> 模式。主逻辑里用一个 <code>match</code> 语句无缝处理两种模式。</p><p><strong>这是个设计原则：稳字当头。</strong> 程序得先能跑，再追求跑得快。</p><h4 id="最终成果：每毫秒都来之不易"><a href="#最终成果：每毫秒都来之不易" class="headerlink" title="最终成果：每毫秒都来之不易"></a><strong>最终成果：每毫秒都来之不易</strong></h4><p>折腾这么久，零拷贝到底提升多少？我用 <code>time</code> 命令给单张图片处理做了性能测试。</p><p><strong>标准模式（要拷贝内存）</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; time target/release/rkyolo-app ...</span><br><span class="line">... 0.32s user 0.10s system 76% cpu 0.550 total</span><br></pre></td></tr></table></figure><p><strong>零拷贝模式</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; time target/release/rkyolo-app ...</span><br><span class="line">... 0.29s user 0.10s system 76% cpu 0.507 total</span><br></pre></td></tr></table></figure><p><strong>战果汇报：</strong></p><ul><li><strong>省了多少时间</strong>: <code>0.550s - 0.507s =</code> <strong>43 毫秒</strong></li><li><strong>性能提升</strong>: <code>(43ms / 550ms) * 100% ≈</code> <strong>7.8%</strong></li></ul><p>单张图片上，我们拿到了近 8%的性能提升。这点提升在实时视频流里会被放大，直接决定应用流不流畅。这 43 毫秒的胜利，是我跟硬件死磕、细读文档、狠抓细节、不忘稳健的结果。</p><p>看到单张图片节省 43 毫秒的结果，可能有人会觉得投入产出比不高。确实，如果只处理几张图片，这个优化的意义不大。但我之所以坚持先攻克它，源于我对构建高性能系统的一种理解：优化必须自底向上，先夯实基础，再搭建上层建筑。</p><p>为什么必须先做零拷贝，再做视频流？</p><p>这背后是一种简单的工程哲学：如果我连单张图片的数据传输都无法优化到极致，又怎么可能处理好连续不断的视频流呢？视频流本质上是海量图片的连续处理，任何微小的效率损耗都会被无限放大。如果底层基础不稳，上层应用越是复杂，整个系统就会越摇摇欲坠。</p><p>我希望先打造一个尽可能高效的“引擎”，确保核心推理路径是最优的，然后再去为它添加“轮子”和“外壳”（比如视频流处理、结果显示等功能）。这个顺序不能颠倒。</p><p>零拷贝的“可怕”之处在于规模的放大效应</p><p>虽然单次节省 43 毫秒看似不起眼，但当我们将其置于真实的、高负载的应用场景中时，它的价值就会以惊人的方式展现出来：</p><p>场景一：多路视频流处理<br>假设我们需要同时处理 4 路 1080p@30fps 的视频流。</p><p>标准模式下的额外开销：每秒会产生 4 路 _ 30 帧 _ 43 毫秒 ≈ 5.16 秒 的 CPU 计算量。这意味着，仅内存拷贝就会占用超过 5 个 CPU 核心的算力，极易造成系统卡顿和丢帧。</p><p>零拷贝模式下的开销：这部分开销几乎降为零。释放出的巨大 CPU 资源可以用于处理更多路视频或更复杂的算法，从根本上提升了系统的吞吐能力和稳定性。</p><p>场景二：应对 4K@60fps 的极限挑战<br>4K 分辨率的数据量大约是 1080p 的 4 倍。我们保守估计，其单帧拷贝耗时约为 1080p 的 2.5 倍，即 107.5 毫秒。</p><p>标准模式下的瓶颈：处理一路 4K@60fps 视频，仅拷贝数据每年秒就需要 60 帧 * 107.5 毫秒 &#x3D; 6.45 秒 的 CPU 时间。这个数字是毁灭性的，它直接宣告了在嵌入式设备上实现实时处理是不可能的。</p><p>零拷贝带来的可能性：正是通过消除这个巨大的瓶颈，我们才为后续所有的优化（模型量化、算子融合等）争取了宝贵的资源，使得挑战这种极限场景成为了可能。</p><p>结论<br>因此，这 43 毫秒的优化，远不止是一个数字游戏。它是我对系统底层性能的一种执着，是对“兵马未动，粮草先行”这一理念的实践。它意味着系统架构拥有了一个高效、可靠的地基。在这个地基上，我们才能放心地去构建各种强大而复杂的上层应用（如多路视频流分析），并确保它们能够稳健、高效地运行。这种对底层细节的关注和投入，正是追求极致性能的必经之路。</p>]]></content>
      
      
      <categories>
          
          <category> 技术实践 </category>
          
          <category> 人工智能 </category>
          
          <category> 计算机视觉 </category>
          
          <category> 边缘计算部署 </category>
          
          <category> RKYOLO诞生记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> YOLO </tag>
            
            <tag> 系统编程 </tag>
            
            <tag> Rust </tag>
            
            <tag> AI </tag>
            
            <tag> 嵌入式 </tag>
            
            <tag> 开源 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RKYOLO诞生记 (三)：和模型输出玩“配对游戏”——折腾出一个能自适应变化的笨办法</title>
      <link href="/2025/09/10/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E9%83%A8%E7%BD%B2/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0-%E4%B8%89-%EF%BC%9A%E5%92%8C%E6%A8%A1%E5%9E%8B%E8%BE%93%E5%87%BA%E7%8E%A9%E2%80%9C%E9%85%8D%E5%AF%B9%E6%B8%B8%E6%88%8F%E2%80%9D%E2%80%94%E2%80%94%E6%8A%98%E8%85%BE%E5%87%BA%E4%B8%80%E4%B8%AA%E8%83%BD%E8%87%AA%E9%80%82%E5%BA%94%E5%8F%98%E5%8C%96%E7%9A%84%E7%AC%A8%E5%8A%9E%E6%B3%95/"/>
      <url>/2025/09/10/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E9%83%A8%E7%BD%B2/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0-%E4%B8%89-%EF%BC%9A%E5%92%8C%E6%A8%A1%E5%9E%8B%E8%BE%93%E5%87%BA%E7%8E%A9%E2%80%9C%E9%85%8D%E5%AF%B9%E6%B8%B8%E6%88%8F%E2%80%9D%E2%80%94%E2%80%94%E6%8A%98%E8%85%BE%E5%87%BA%E4%B8%80%E4%B8%AA%E8%83%BD%E8%87%AA%E9%80%82%E5%BA%94%E5%8F%98%E5%8C%96%E7%9A%84%E7%AC%A8%E5%8A%9E%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>上一篇文章里，我们好不容易打赢了“数值之战”，让模型终于能看清楚东西了。我美滋滋地想，导师给的玉米穗模型部署任务，这下总该顺利了吧？</p><p>于是，我满心期待地把模型从 COCO 的<code>yolo11n.rknn</code>换成了自己的<code>MTDC-UAV.rknn</code>。结果……程序又扑街了。</p><span id="more"></span><h4 id="新副本：从“看错”到“崩溃”"><a href="#新副本：从“看错”到“崩溃”" class="headerlink" title="新副本：从“看错”到“崩溃”"></a><strong>新副本：从“看错”到“崩溃”</strong></h4><p>这次倒不是瞎指认了，而是干脆利落的**段错误(Segmentation Fault)**——程序在推理成功后，刚进后处理函数就当场崩溃。</p><p>吃一堑长一智，我第一反应就是：模型结构又作什么妖了？赶紧加日志，把模型真实的输入输出张量数量打印出来瞅瞅。果然：</p><ul><li>COCO <code>yolo11n.rknn</code> 模型：<strong>9 个输出</strong></li><li>我的 <code>MTDC-UAV.rknn</code> 模型：<strong>7 个输出</strong></li></ul><p>破案了。我之前写的后处理代码，和那些 C++示例一样，天真地以为模型永远会吐出 9 个输出。当它试图去访问我模型里压根不存在的第 8、第 9 个输出张量时，就直接一头撞墙上——内存访问越界了。</p><p>这时候我才算彻底明白，为啥当初 C++示例跑不通我的模型，为啥我非得折腾这个重构项目。<strong>真不是我闲得慌非要追新，是这坑就摆在这，不填平它，任务根本进行不下去啊！</strong></p><h4 id="关键破局点：别猜了，让模型自己“交代”"><a href="#关键破局点：别猜了，让模型自己“交代”" class="headerlink" title="关键破局点：别猜了，让模型自己“交代”"></a><strong>关键破局点：别猜了，让模型自己“交代”</strong></h4><p>我悟了：不能再<strong>猜</strong>模型长啥样了，得写个代码让它自己<strong>交代</strong>。我需要个“模型侦察兵”，而“侦察情报”就是模型自己的元数据。</p><p>我没瞎琢磨，而是干了件挺有用的事：<strong>数据驱动调试</strong>。我让程序分别加载两个模型，把它们所有输出张量的属性（维度、名称等）全打印出来。</p><p><strong>情报一：YOLOv11n (COCO) 的输出张量属性</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">--- 输出张量属性诊断 ---</span><br><span class="line">- Attr 0: ... dims=[1, 64, 80, 80]  (Box @ 80x80)</span><br><span class="line">- Attr 1: ... dims=[1, 80, 80, 80]  (Score @ 80x80, 80 classes)</span><br><span class="line">... (中间省略) ...</span><br><span class="line">- Attr 8: ... dims=[1, 1, 20, 20]   (Score_sum @ 20x20)</span><br><span class="line">--------------------------</span><br></pre></td></tr></table></figure><p><strong>情报二：YOLOv11n (玉米穗) 的输出张量属性</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">--- 输出张量属性诊断 ---</span><br><span class="line">- Attr 0: ... dims=[1, 64, 80, 80]  (Box @ 80x80)</span><br><span class="line">- Attr 1: ... dims=[1, 1, 80, 80]   (Score @ 80x80, 1 class)</span><br><span class="line">... (中间省略) ...</span><br><span class="line">- Attr 6: ... dims=[1, 64, 20, 20]  (Box @ 20x20)</span><br><span class="line">--------------------------</span><br></pre></td></tr></table></figure><p>把这两份“情报”放一块，谜底揭晓了：</p><ol><li><strong>“套路”还是那个套路</strong>：虽然输出总数不同，但它们都遵循一个基本模式——在同一个空间尺寸（比如<code>80x80</code>）上，总会有一组相关的张量。</li><li><strong>张量的“身份证”</strong>：我摸到一个还算靠谱的<strong>启发式规则</strong>来区分它们。负责预测框的<strong>Box 张量</strong>，其通道数<code>dims[1]</code>是个固定值（比如<code>64</code>）；而负责预测类别的<strong>Score 张量</strong>，其通道数<code>dims[1]</code>恰恰就是<strong>类别总数</strong>（COCO 是 80，玉米穗就 1 个）。</li><li><strong>“被优化”了</strong>：最有趣的是，玉米穗模型在<code>20x20</code>这个尺度上，<strong>只有 Box 张量，没对应的 Score 张量</strong>！怪不得少俩输出。估计是 ONNX 转 RKNN 时，优化器觉得这小目标检测分支对我的任务没啥用，顺手就给“剪”了。</li></ol><h4 id="算法的演进：从“写死”到“动态配对”"><a href="#算法的演进：从“写死”到“动态配对”" class="headerlink" title="算法的演进：从“写死”到“动态配对”"></a><strong>算法的演进：从“写死”到“动态配对”</strong></h4><p>真相大白。不能依赖任何固定的输出数量或顺序，唯一可靠的，就是<strong>“相同空间尺寸的 Box 和 Score 张量是一对儿”</strong>这个基本原理。</p><p>基于这，我琢磨出一个新的、能自适应的后处理算法。我不再关心总共是 7 个还是 9 个输出，我的代码现在像是在玩一个动态的“配对游戏”：</p><p><strong>第一步：给所有张量发“身份证”（动态识别）</strong></p><p>我遍历所有输出张量，根据刚摸清的规则，给它们贴上“身份”标签，然后塞进一个列表里。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// rkyolo-core/src/postprocess.rs</span></span><br><span class="line"><span class="meta">#[derive(Debug)]</span></span><br><span class="line"><span class="keyword">enum</span> <span class="title class_">TensorInfo</span> &#123;</span><br><span class="line">    <span class="type">Box</span> &#123; h: <span class="type">u32</span>, w: <span class="type">u32</span>, index: <span class="type">usize</span> &#125;,</span><br><span class="line">    Score &#123; h: <span class="type">u32</span>, w: w: <span class="type">u32</span>, index: <span class="type">usize</span> &#125;,</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// ... 遍历所有输出张量的属性 ...</span></span><br><span class="line"><span class="keyword">let</span> <span class="variable">c</span> = attr.dims[<span class="number">1</span>]; <span class="comment">// 通道数</span></span><br><span class="line"><span class="keyword">let</span> <span class="variable">h</span> = attr.dims[<span class="number">2</span>];</span><br><span class="line"><span class="keyword">let</span> <span class="variable">w</span> = attr.dims[<span class="number">3</span>];</span><br><span class="line"></span><br><span class="line"><span class="comment">// 就用通道数这个土办法，先区分看看</span></span><br><span class="line"><span class="keyword">if</span> c == <span class="number">64</span> &#123;</span><br><span class="line">    identified_tensors.<span class="title function_ invoke__">push</span>(TensorInfo::<span class="type">Box</span> &#123; h, w, index: i &#125;);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    identified_tensors.<span class="title function_ invoke__">push</span>(TensorInfo::Score &#123; h, w, index: i &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>第二步：按尺寸配对并处理（动态配对与调用）</strong></p><p>接下来是核心部分。代码不再写死循环，而是遍历所有被认出是<code>Box</code>的，然后为每一个去找尺寸一模一样的<code>Score</code>。只要配上一对，就立马把它们塞给解码函数去处理。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// rkyolo-core/src/postprocess.rs</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 2. 动态配对：遍历所有Box，给它们找对象（尺寸一样的Score）</span></span><br><span class="line"><span class="keyword">for</span> <span class="variable">tensor_info</span> <span class="keyword">in</span> &amp;identified_tensors &#123;</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">let</span> &amp;TensorInfo::<span class="type">Box</span> &#123;</span><br><span class="line">        h,</span><br><span class="line">        w,</span><br><span class="line">        index: box_idx,</span><br><span class="line">    &#125; = tensor_info</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// 给它找个尺寸一样的Score</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">paired_score_info</span> = identified_tensors.<span class="title function_ invoke__">iter</span>().<span class="title function_ invoke__">find</span>(|&amp;t| &#123;</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">let</span> &amp;TensorInfo::Score &#123; h: sh, w: sw, .. &#125; = t &#123;</span><br><span class="line">                sh == h &amp;&amp; sw == w</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="literal">false</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 找到了就送去解码</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">let</span> <span class="variable">Some</span>(&amp;TensorInfo::Score &#123;</span><br><span class="line">            index: score_idx, ..</span><br><span class="line">        &#125;) = paired_score_info</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// ... (这里拿到对应的数据，然后调用解码函数) ...</span></span><br><span class="line">            <span class="keyword">let</span> <span class="variable">branch_detections</span> = <span class="title function_ invoke__">decode_branch</span>(...);</span><br><span class="line">            all_detections.<span class="title function_ invoke__">extend</span>(branch_detections);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这代码妙就妙在它的<strong>描述性</strong>。它没死命令式地去“访问第 0、1、3 个……”张量，而是描述了个匹配规则：“<strong>给我找个 Box，再给它配个一样大的 Score，然后你俩一起处理去</strong>”。这么一来，张量数量变没变、顺序乱没乱，它根本不在乎。</p><h4 id="小结与收获：从“搞定”到“学乖”"><a href="#小结与收获：从“搞定”到“学乖”" class="headerlink" title="小结与收获：从“搞定”到“学乖”"></a><strong>小结与收获：从“搞定”到“学乖”</strong></h4><p>当我用这套新的“动态配对”算法换掉旧的硬编码后，嘿，还真成了！</p><p>无论是 9 个输出的 COCO 模型，还是被“剪枝”成 7 个输出的玉米穗模型，甚至以后别的什么妖魔鬼怪模型，我这后处理代码<strong>一个字都不用改</strong>，大概率都能蒙混过关。</p><p>这次折腾下来，最大的感触就是：</p><ul><li><strong>别脑补，看日志</strong>：与其瞎猜，不如让数据（模型元数据）自己说话，让它指导代码该怎么写。</li><li><strong>拥抱变化</strong>：写死的代码最怕变化。一个皮实的系统，得能优雅地处理各种意外（比如模型被优化了）。</li><li><strong>挖到底</strong>：只有挖到问题的根上（模型输出的内在模式），才能想出“一劳永逸”的笨办法，而不是不停打补丁。</li></ul><p>这个过程让我学到的，不止是修好一个程序，更是对怎么写“抗造”的代码有了点感觉。算是从一个只会埋头解决问题的“码农”，朝一个能预感到变化、会写适应性代码的“码农 plus”挪了一小步吧。</p>]]></content>
      
      
      <categories>
          
          <category> 技术实践 </category>
          
          <category> 人工智能 </category>
          
          <category> 计算机视觉 </category>
          
          <category> 边缘计算部署 </category>
          
          <category> RKYOLO诞生记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> YOLO </tag>
            
            <tag> 系统编程 </tag>
            
            <tag> Rust </tag>
            
            <tag> AI </tag>
            
            <tag> 嵌入式 </tag>
            
            <tag> 开源 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RKYOLO诞生记 (二)：模型“指鹿为马”？我的Bug侦探笔记</title>
      <link href="/2025/09/10/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E9%83%A8%E7%BD%B2/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0-%E4%BA%8C-%EF%BC%9A%E6%A8%A1%E5%9E%8B%E2%80%9C%E6%8C%87%E9%B9%BF%E4%B8%BA%E9%A9%AC%E2%80%9D%EF%BC%9F%E6%88%91%E7%9A%84Bug%E4%BE%A6%E6%8E%A2%E7%AC%94%E8%AE%B0/"/>
      <url>/2025/09/10/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E9%83%A8%E7%BD%B2/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0-%E4%BA%8C-%EF%BC%9A%E6%A8%A1%E5%9E%8B%E2%80%9C%E6%8C%87%E9%B9%BF%E4%B8%BA%E9%A9%AC%E2%80%9D%EF%BC%9F%E6%88%91%E7%9A%84Bug%E4%BE%A6%E6%8E%A2%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p>上一篇文章，我们聊了为什么我选择用 Rust 来为 RKNN 库构建一个安全、独立的地基。当地基打好，我信心满满地将所有模块串联起来，加载了官方示例中那张经典的<code>bus.jpg</code>，期待着一次完美的推理。</p><p>程序没有崩溃，有输出了！我兴奋地将结果绘制出来，然后……我傻眼了。</p><h4 id="案发现场：一切混乱的开始"><a href="#案发现场：一切混乱的开始" class="headerlink" title="案发现场：一切混乱的开始"></a><strong>案发现场：一切混乱的开始</strong></h4><p>眼前的景象让我大跌眼镜。这哪里是目标检测，这简直是抽象艺术……</p><span id="more"></span><p><strong>图一：最初的错乱图</strong><br><img data-src="/img/2025/9/10/first_messy_coco1.png" alt="图一：最初的错乱图" title="最初的推理结果，大量的框重叠、错位，甚至把远处的建筑识别成了“truck"><br><em>图注：最初的推理结果，大量的框重叠、错位，甚至把远处的建筑识别成了“truck”</em></p><p>大量的检测框毫无逻辑地堆叠在一起，置信度都低得可怜。很明显，有什么东西从根上就错了。</p><h4 id="第一轮审讯：NMS-与置信度的“嫌疑”"><a href="#第一轮审讯：NMS-与置信度的“嫌疑”" class="headerlink" title="第一轮审讯：NMS 与置信度的“嫌疑”"></a><strong>第一轮审讯：NMS 与置信度的“嫌疑”</strong></h4><p>我的第一反应是：是不是后处理的参数太松了？我尝试调整 NMS（非极大值抑制）的阈值和置信度阈值，希望能过滤掉这些杂乱的框。经过一番调整，我得到了一张稍微“干净”一点的图，但问题也更清晰了：</p><p><strong>图二：初步清理后的结果</strong><br><img data-src="/img/2025/9/10/milestone_but_bug2.png" alt="图二：初步清理后的结果" title="提高阈值后，大部分杂乱的框消失了，但暴露了两个核心问题"><br><em>提高阈值后，大部分杂乱的框消失了，但暴露了两个核心问题</em></p><p>这张图暴露了两个致命问题：</p><ol><li><strong>那么大个 Bus 呢？</strong> 画面中最显眼的主体——公交车，完全没有被识别出来。</li><li><strong>诡异的检测框</strong>：中间那个黑衣人，检测框从半个脑袋一直延伸到了脚底，明显是错位的。</li></ol><p>我当时陷入了一个错误的猜想，但这个猜想推动了调查的进行：“是不是我的 NMS 算法和官方的有出入，导致它抑制错了框？比如，其实模型已经预测出了很多个完美的框，但我的 NMS 算法选了一个最差的留了下来？”</p><h4 id="案情转折：一个无法忽视的线索"><a href="#案情转折：一个无法忽视的线索" class="headerlink" title="案情转折：一个无法忽视的线索"></a><strong>案情转折：一个无法忽视的线索</strong></h4><p>为了验证这个猜想，我继续调整代码，并设法让公交车的框出现了。但结果却让我更加困惑：</p><p><strong>图三：公交车出现，但身份成谜</strong><br><img data-src="/img/2025/9/10/another_milestone_bug_still_bug3.png" alt="图三：公交车出现，但身份成谜" title="公交车终于被检测到了，但它的身份却是“truck”，且置信度低得可怜。"><br><em>图注：公交车终于被检测到了，但它的身份却是“truck”，且置信度低得可怜。</em></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">--- 检测结果 (4 个) ---</span><br><span class="line">类别: 0 (person), 置信度: 0.9054, ...</span><br><span class="line">类别: 0 (person), 置信度: 0.7923, ...</span><br><span class="line">类别: 0 (person), 置信度: 0.6791, ...</span><br><span class="line">类别: 7 (truck), 置信度: 0.4254, 框: BoundingBox &#123; ... &#125; &lt;-- 在这里！</span><br><span class="line">--------------------------</span><br></pre></td></tr></table></figure><p>这个结果让我瞬间否定了之前对 NMS 的怀疑。NMS 只会抑制或保留检测框，它不可能改变一个物体的类别。<strong>公交车被识别成了卡车，这绝对不是后处理能干出来的事！</strong></p><p><strong>我当时就断定：一定是输入模型的图像就有问题！</strong></p><p>这个想法如同一道闪电，让我瞬间跳出了后-处理的思维定势，开始审视整个数据流的源头——<strong>图像预处理</strong>。</p><h4 id="最终审判：揭开“黑盒”的真相"><a href="#最终审判：揭开“黑盒”的真相" class="headerlink" title="最终审判：揭开“黑盒”的真相"></a><strong>最终审判：揭开“黑盒”的真相</strong></h4><p>我决定做一个对照实验来最终确认我的猜想。我用 Python 和 OpenCV（被认为是“黄金标准”）生成了一份预处理好的“完美”输入数据，然后让我的 Rust 程序去加载这份数据进行推理。</p><p>结果，程序在调用后处理函数后，就“沉默”了，一个检测结果都没打印出来。</p><p>这意味着什么？这意味着，即使喂给模型的数据在<strong>几何层面</strong>（缩放、灰边）是完美的，模型推理出的所有置信度分数都低得可怜，全部都被我的阈值过滤掉了。</p><p>案件的真相至此水落石出。问题不在于后处理，也不在于<code>image-rs</code>库的几何变换，而在于那个我一直忽略的、也是唯一的“黑盒”：<strong>RKNN 驱动内部，从 <code>UINT8</code> 到模型实际需要的 <code>INT8</code> 类型的隐式转换。</strong></p><p>我一直天真地以为，只要把<code>[0, 255]</code>的<code>u8</code>像素喂给驱动，它就能“自动”转换成模型需要的<code>i8</code>数据。事实证明，这个“自动转换”的行为和我的预期完全不符。</p><h4 id="胜利时刻：放弃幻想，掌控一切"><a href="#胜利时刻：放弃幻想，掌控一切" class="headerlink" title="胜利时刻：放弃幻想，掌控一切"></a><strong>胜利时刻：放弃幻想，掌控一切</strong></h4><p>在追求极致性能和确定性的嵌入式 AI 领域，我们不能信任任何“黑盒”。我必须亲手实现这个转换，确保送入 NPU 的数据在<strong>数值层面</strong>是 100%正确的。</p><p>正确的流程应该是：<br><strong><code>u8 [0, 255]</code> -&gt; 归一化为 <code>f32 [0.0, 1.0]</code> -&gt; 再用模型自身的 <code>scale</code> 和 <code>zp</code> 参数量化为 <code>i8 [-128, 127]</code></strong></p><p>我立刻重写了我的预处理函数，将<strong>归一化</strong>和<strong>手动量化</strong>这两个关键步骤加了进去。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// rkyolo-core/src/lib.rs (重构后的位置)</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">preprocess_letterbox_quantize</span>(</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;(<span class="type">Vec</span>&lt;<span class="type">i8</span>&gt;, LetterboxInfo), image::ImageError&gt; &#123;</span><br><span class="line">    <span class="comment">// 1. Letterbox 几何变换 (已验证无误)</span></span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    <span class="keyword">let</span> <span class="variable">u8_data</span> = canvas.<span class="title function_ invoke__">into_raw</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2. 【制胜关键】手动归一化并量化</span></span><br><span class="line">    <span class="keyword">let</span> <span class="variable">i8_data</span>: <span class="type">Vec</span>&lt;<span class="type">i8</span>&gt; = u8_data</span><br><span class="line">        .<span class="title function_ invoke__">into_iter</span>()</span><br><span class="line">        .<span class="title function_ invoke__">map</span>(|val_u8| &#123;</span><br><span class="line">            <span class="comment">// 决胜一步：先将u8像素归一化到0-1的浮点数</span></span><br><span class="line">            <span class="keyword">let</span> <span class="variable">f_val</span> = val_u8 <span class="keyword">as</span> <span class="type">f32</span> / <span class="number">255.0</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 再根据模型自身的参数进行量化</span></span><br><span class="line">            <span class="keyword">let</span> <span class="variable">q_val</span> = (f_val / scale + zp <span class="keyword">as</span> <span class="type">f32</span>).<span class="title function_ invoke__">round</span>() <span class="keyword">as</span> <span class="type">i32</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 最后裁剪到i8范围</span></span><br><span class="line">            q_val.<span class="title function_ invoke__">clamp</span>(<span class="type">i8</span>::MIN <span class="keyword">as</span> <span class="type">i32</span>, <span class="type">i8</span>::MAX <span class="keyword">as</span> <span class="type">i32</span>) <span class="keyword">as</span> <span class="type">i8</span></span><br><span class="line">        &#125;)</span><br><span class="line">        .<span class="title function_ invoke__">collect</span>();</span><br><span class="line"></span><br><span class="line">    <span class="title function_ invoke__">Ok</span>((i8_data, info))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当我用这套全新的预处理流程再次运行<code>bus.jpg</code>时——“王者归来”。</p><p><strong>(图四：最终的正确结果)</strong><br><img data-src="/img/2025/9/10/the_king4.png" alt="图四：最终的正确结果" title="在修正了数值问题后，公交车被高置信度地正确识别，所有可见的人物也都被精准框出。"><br><em>图注：在修正了数值问题后，公交车被高置信度地正确识别，所有可见的人物也都被精准框出。</em></p><h4 id="复盘总结"><a href="#复盘总结" class="headerlink" title="复盘总结"></a><strong>复盘总结</strong></h4><p>这次艰难的调试经历，教会了我三件事：</p><ol><li><strong>数据是第一原则</strong>：当代码逻辑看似无懈可击时，首先要怀疑数据的“纯净度”，尤其是在数值层面。</li><li><strong>别信“自动挡”</strong>：在底层交互中，任何看似方便的“黑盒”都可能隐藏着与你预期不符的行为。掌控每一个转换环节，才能获得确定性的结果。</li><li><strong>调试是一门科学</strong>：通过观察现象、大胆假设、设计实验、层层排除，再复杂的 Bug 也终将水落石出。</li></ol><p>此战之后，我的项目不仅走上了正轨，更重要的是，我真正理解了“模型部署”这四个字的重量。我们不再是 API 的调用者，而是能够深入数值细节，确保数据在整个流水线中正确流动的系统构建者。</p>]]></content>
      
      
      <categories>
          
          <category> 技术实践 </category>
          
          <category> 人工智能 </category>
          
          <category> 计算机视觉 </category>
          
          <category> 边缘计算部署 </category>
          
          <category> RKYOLO诞生记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> YOLO </tag>
            
            <tag> 系统编程 </tag>
            
            <tag> Rust </tag>
            
            <tag> AI </tag>
            
            <tag> 嵌入式 </tag>
            
            <tag> 开源 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RKYOLO诞生记 (一)：告别C++&quot;动物园&quot;，为何我选择用Rust从零开始？</title>
      <link href="/2025/09/10/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E9%83%A8%E7%BD%B2/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0-%E4%B8%80-%EF%BC%9A%E5%91%8A%E5%88%ABC-%E2%80%9C%E5%8A%A8%E7%89%A9%E5%9B%AD%E2%80%9D%EF%BC%8C%E4%B8%BA%E4%BD%95%E6%88%91%E9%80%89%E6%8B%A9%E7%94%A8Rust%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%EF%BC%9F/"/>
      <url>/2025/09/10/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E9%83%A8%E7%BD%B2/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0/RKYOLO%E8%AF%9E%E7%94%9F%E8%AE%B0-%E4%B8%80-%EF%BC%9A%E5%91%8A%E5%88%ABC-%E2%80%9C%E5%8A%A8%E7%89%A9%E5%9B%AD%E2%80%9D%EF%BC%8C%E4%B8%BA%E4%BD%95%E6%88%91%E9%80%89%E6%8B%A9%E7%94%A8Rust%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%EF%BC%9F/</url>
      
        <content type="html"><![CDATA[<p>大家好，我是个大三的学生。最近因为导师的一个课题，需要把一个我自己训练的、用于识别玉米穗的 YOLO11n 模型，部署到一块 Rockchip RK3588 开发板上。</p><p>这其实还有个“前传”：为了让板子支持最新的模型，我已经折腾了好一阵子，把整个 Linux 内核连带 RKNPU 驱动都给交叉编译升级了一遍。所以，当底层环境就绪，模型也转换成<code>.rknn</code>格式后，我当时觉得，接下来应该就是顺理成章的“应用开发”了。</p><p>很自然地，我找到了野火社区的“鲁班猫”AI 教程，他们提供了一个<code>yolo11</code>的 C++示例。我寻思着，既然有现成的，改改用就行了呗？</p><p>事实证明，我还是太年轻了。</p><span id="more"></span><p>当我把官方提供的<code>yolo11.rknn</code>模型（COCO 数据集，80 个类别）跑起来时，一切正常。但当我换上我自己的、只有一个类别的玉米穗模型时，程序就陷入了沉默的崩溃，连个像样的错误日志都没有。</p><p>这次失败，让我下定决心：<strong>放弃修改，从零重构。</strong></p><p>这个决定看似冲动，但其实背后有一个在我脑子里盘旋了好几个月的执念：<strong>一个 AI 模型推理能力，如果不能被轻松地集成到其他应用里，那它的价值就大打折扣。</strong> 无论是导师的农业项目，还是我一直想玩的、带目标检测的 ROS 机器人，它们需要的都不是一个只能在终端里敲命令运行的独立程序，而是一个稳定、可靠、可以被轻松调用的<strong>“能力模块”</strong>。</p><p>这篇博客，就是想聊聊我看到的那个 C++示例是如何打破了我这个“集成梦”，以及为什么最终选择了 Rust 作为我的“破局之刃”。</p><h4 id="解剖-C-“动物园”：一些让我无法妥协的设计"><a href="#解剖-C-“动物园”：一些让我无法妥协的设计" class="headerlink" title="解剖 C++“动物园”：一些让我无法妥协的设计"></a><strong>解剖 C++“动物园”：一些让我无法妥协的设计</strong></h4><p>首先要说明一点，野火的这个示例项目（<a href="https://gitee.com/LubanCat/lubancat_ai_manual_code">LubanCat AI Manual Code</a>），它的项目结构很大程度上继承自 Rockchip 的官方模型仓库（<a href="https://github.com/airockchip/rknn_model_zoo">rknn_model_zoo</a>）。所以，我接下来要吐槽的，并不仅仅是某一个示例项目的问题，而是一种在嵌入式 C++开发中相当普遍的、让我难以忍受的设计惯性。</p><p><strong>1. 硬编码的“想当然”</strong></p><p>当我开始寻找程序崩溃的原因时，<code>postprocess.h</code>里的这几行代码让我瞬间明白了问题所在：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// yolo11/cpp/postprocess.h</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> OBJ_NAME_MAX_SIZE 64</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> OBJ_NUMB_MAX_SIZE 128</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> OBJ_CLASS_NUM 80  <span class="comment">// &lt;--- 喂喂喂！</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> NMS_THRESH 0.45</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> BOX_THRESH 0.25</span></span><br></pre></td></tr></table></figure><p><code>OBJ_CLASS_NUM</code>，这个代表物体类别总数的宏，被“想当然”地写死成了<code>80</code>。整个后处理代码，包括各种循环和内存计算，都依赖这个写死的值。我的玉米穗模型只有一个类别，当后处理逻辑试图去访问它根本不存在的第 2 到第 80 个类别的预测数据时，不出错才怪了。</p><p>这还只是冰山一-角。代码里还假设模型永远有 3 个输出分支，用<code>app_ctx-&gt;io_num.n_output / 3</code>来计算每个分支的张量数。这种写法，让代码变得极其脆弱。<strong>这已经不是一个“框架”了，它更像一个“一次性脚本”</strong>，只能和特定模型绑定。每次模型结构发生丁点变化，都得回来改代码，然后重新编译，太麻烦了。</p><p><strong>2. 紧耦合的“大杂烩”——我的“集成梦”是如何被打破的</strong></p><p>这，才是我最无法容忍的一点。看看它的构建系统，<code>CMakeLists.txt</code>里赫然写着：</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">// yolo11/cpp/CMakeLists.txt</span><br><span class="line"><span class="keyword">add_subdirectory</span>(<span class="variable">$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;</span>/../../<span class="number">3</span>rdparty/ <span class="number">3</span>rdparty.out)</span><br><span class="line"><span class="keyword">add_subdirectory</span>(<span class="variable">$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;</span>/../../utils/ utils.out)</span><br></pre></td></tr></table></figure><p>这意味着，为了编译这一个<code>yolo11</code>的小小示例，我需要把整个包含<code>3rdparty</code>和<code>utils</code>的上层代码库——也就是那个庞大的“动物园”(Zoo)——完整地下载下来。</p><p><strong>集成个屁！</strong></p><p>我魂牵梦绕了几个月，想的是怎么把 YOLO 能力作为一个干净的库，轻松地链接到其他项目里。结果这个 Demo 告诉我，想用我？行啊，先把我的整个“动物园”亲戚都请过来。这还怎么集成？难道我的 ROS 项目也要被迫依赖这一大堆它根本用不上的<code>utils</code>和<code>3rdparty</code>吗？</p><p>这种设计，彻底扼杀了我将其作为“能力模块”进行二次开发的可能性。</p><p><strong>3. 手动管理的“安全隐患”</strong></p><p>最后，是老生常谈的 C++资源管理问题。代码里充斥着手动<code>malloc</code>&#x2F;<code>free</code>，以及经典的<code>goto cleanup;</code>模式。</p><p>这种写法本身没错，但在复杂的逻辑中，它完全依赖开发者的记忆力和纪律性。少写一个<code>free</code>，或者在某个错误处理分支忘了<code>goto</code>，就意味着一次隐蔽的内存泄漏。在需要 7x24 小时稳定运行的嵌入式设备上，这种隐患是致命的。</p><h4 id="我的破局之道：选择-Rust-的三重考量"><a href="#我的破局之道：选择-Rust-的三重考量" class="headerlink" title="我的破局之道：选择 Rust 的三重考量"></a><strong>我的破局之道：选择 Rust 的三重考量</strong></h4><p>面对以上种种，我意识到“缝缝补补”是没有出路的。我需要的是一个<strong>安全、独立、现代化</strong>的解决方案。于是，我决定用 Rust 来重写这一切。</p><p><strong>1. 从“记住释放”到“自动管理”——RAII 带来的心智解放</strong></p><p>我最看重 Rust 的一点，就是它的 RAII（资源获取即初始化）机制。我做的第一件事，就是创建一个专门的<code>rknn-ffi</code> Crate，然后把需要手动管理的<code>rknn_context</code>句柄用一个 Rust 结构体包起来：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// rkyolo/rknn-ffi/src/context.rs</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">RknnContext</span> &#123;</span><br><span class="line">    ctx: raw::rknn_context,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">Drop</span> <span class="keyword">for</span> <span class="title class_">RknnContext</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">drop</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) &#123;</span><br><span class="line">        <span class="comment">// 当RknnContext对象离开作用域时，这里的代码会自动执行</span></span><br><span class="line">        debug!(<span class="string">&quot;Dropping RknnContext and calling rknn_destroy...&quot;</span>);</span><br><span class="line">        <span class="keyword">unsafe</span> &#123;</span><br><span class="line">            raw::<span class="title function_ invoke__">rknn_destroy</span>(<span class="keyword">self</span>.ctx);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>就这么简单。<code>Drop</code> trait 就像一个和编译器签下的“契约”，保证了只要<code>RknnContext</code>对象消亡，<code>rknn_destroy</code>就一定会被调用。我再也不用担心忘记释放资源了，因为编译器会帮我记住。这种心智上的解放，让我可以更专注于业务逻辑本身。</p><p><strong>2. 从“依赖泥潭”到“清晰边界”——Cargo 带来的工程尊严</strong></p><p>告别了复杂的<code>CMakeLists.txt</code>，Rust 的包管理器 Cargo 让项目工程变得前所未有的清爽。</p><p>我的<code>rkyolo</code>项目通过 Cargo 的<code>workspace</code>功能，从一开始就被划分为职责分明的几个部分：<code>rknn-ffi</code>（负责与 C 库交互）、<code>rkyolo-core</code>（核心算法）、<code>rkyolo-app</code>（应用程序）。每个部分都是一个独立的 Crate，依赖关系在各自的<code>Cargo.toml</code>里一目了然。</p><p>这种设计带来了极大的灵活性，<strong>完美地回应了我最初的“集成梦”</strong>。未来任何项目想复用我的核心推理能力，只需要依赖<code>rkyolo-core</code>这个 Crate 就行，完全不会被其他不相关的东西所拖累。</p><p><strong>3. 从“处处<code>unsafe</code>”到“安全封装”——FFI 带来的健壮抽象</strong></p><p>Rust 并没有回避与 C 交互时<code>unsafe</code>的必要性，但它提供了一套机制，让我们能把这些“危险”的操作关进一个可控的“笼子”里。</p><p>我的<code>rknn-ffi</code> Crate 就是这样一个“笼子”。所有与 C 库的裸指针交互、内存操作，都被严格限制在其中，并被封装成安全的、返回<code>Result</code>类型的 Rust 函数。这样一来，上层的<code>rkyolo-core</code>和<code>rkyolo-app</code>就可以在 100% safe 的 Rust 环境中开发，享受编译器提供的全部安全检查。</p><h4 id="结论：一项值得的战略投资"><a href="#结论：一项值得的战略投资" class="headerlink" title="结论：一项值得的战略投资"></a><strong>结论：一项值得的战略投资</strong></h4><p>是的，用 Rust 重写这一切花了我两天时间。但这两天并不是“重复造轮子”，而是在<strong>打地基</strong>。</p><p>我投入时间，换来的是一个<strong>在编译时就杜绝了内存泄漏、依赖清晰、易于集成、核心逻辑与应用完全解耦</strong>的坚固地基。我相信，这项前期的“战略投资”，为我后续快速、高质量地完成导师的任务，甚至探索更有趣的机器人项目，铺平了道路。</p><p>当然，地基打好只是开始。很快，我就在这块坚实的地基上，遇到了第一个真正的拦路虎——模型能跑了，但结果却“指鹿为-马”。</p><p>下一篇，我们就来聊聊我是如何侦破这个棘手的数值迷案的。</p>]]></content>
      
      
      <categories>
          
          <category> 技术实践 </category>
          
          <category> 人工智能 </category>
          
          <category> 计算机视觉 </category>
          
          <category> 边缘计算部署 </category>
          
          <category> RKYOLO诞生记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> YOLO </tag>
            
            <tag> 系统编程 </tag>
            
            <tag> Rust </tag>
            
            <tag> AI </tag>
            
            <tag> 嵌入式 </tag>
            
            <tag> 开源 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一次对香港服务器的网络优化与安全加固笔记</title>
      <link href="/2025/09/10/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E5%BC%80%E5%8F%91%E8%BF%90%E7%BB%B4/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4/%E7%BD%91%E7%BB%9C%E4%B8%8E%E5%AE%89%E5%85%A8/%E4%B8%80%E6%AC%A1%E5%AF%B9%E9%A6%99%E6%B8%AF%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96%E4%B8%8E%E5%AE%89%E5%85%A8%E5%8A%A0%E5%9B%BA%E7%AC%94%E8%AE%B0/"/>
      <url>/2025/09/10/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E5%BC%80%E5%8F%91%E8%BF%90%E7%BB%B4/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4/%E7%BD%91%E7%BB%9C%E4%B8%8E%E5%AE%89%E5%85%A8/%E4%B8%80%E6%AC%A1%E5%AF%B9%E9%A6%99%E6%B8%AF%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96%E4%B8%8E%E5%AE%89%E5%85%A8%E5%8A%A0%E5%9B%BA%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p>最近抽了点时间，准备把个人博客 <code>miceworld.top</code> 和一些自托管服务迁移到一台新的香港云服务器上。想着能有更完全的控制权，也方便自己折腾。</p><p>服务器的初始化很顺利，Debian 系统，Nginx + Hexo 部署网站，再用 Certbot 跑一下，HTTPS 的小绿锁很快就亮起来了。一切都按部就班。</p><span id="more"></span><p>麻烦是在日常管理时出现的。</p><p>当我准备通过 SSH 或者 Web 面板管理服务器时，发现直连的延迟非常高，终端的卡顿已经到了影响工作的程度。</p><p>起初，我尝试通过本地的代理软件（sing-box）来优化。为服务器 IP 单独设置直连规则，可以解决 Web 面板的访问问题；再为 SSH 的 22 端口设置一个出口选择器，也能在一定程度上缓解终端的卡顿。虽然能用，但总觉得不够优雅，而且每次 SSH 都需要手动选择节点，还是有些繁琐。</p><p>更重要的是，我内心对安全有种执念。把 SSH 端口直接暴露在公网上，哪怕用了密钥登录，也总让我感觉不踏实。毕竟，服务本身存在，就意味着存在被扫描和被未知漏洞攻击的风险。我的网站既然用了 Cloudflare 保护，源站 IP 就必须隐藏，端口也必须隔离，这才是完整的安全保障。</p><p>于是，我决定采用我过去习惯的一套方案，来从根本上解决这个问题。</p><h3 id="第一次尝试：自建-ZeroTier-Planet"><a href="#第一次尝试：自建-ZeroTier-Planet" class="headerlink" title="第一次尝试：自建 ZeroTier Planet"></a>第一次尝试：自建 ZeroTier Planet</h3><p>我之前的经验是，通过自建 ZeroTier Planet，可以让所有设备脱离官方服务器，进行点对点的内网通信，在国内服务器之间的效果非常好，延迟极低。</p><p>于是我熟练地使用 <code>xubiaolin/docker-zerotier-planet</code> 工具在服务器上部署了私有 Planet，并将配置文件分发到了我的电脑上。</p><p>然而，结果却不尽人意。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">tracepath xxx.xxx.xxx.xxx</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">... (路由绕行，延迟飙升) ...</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">ping xxx.xxx.xxx.xxx</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">... (高达70%的丢包率和3-4秒的延迟) ...</span></span><br></pre></td></tr></table></figure><p><code>tracepath</code> 和 <code>ping</code> 的结果很明确地告诉我，这次的情况和国内不同。夜间大陆访问香港的国际出口线路质量非常糟糕，丢包和高延迟是常态。在这样恶劣的物理链路上，ZeroTier 很难建立起稳定的 P2P 连接。</p><p>看来，过去成功的经验，并不能简单地复制到新的网络环境中。</p><h3 id="改变思路：Planet-不行，那就用-Moon"><a href="#改变思路：Planet-不行，那就用-Moon" class="headerlink" title="改变思路：Planet 不行，那就用 Moon"></a>改变思路：Planet 不行，那就用 Moon</h3><p>既然完全独立的 Planet 方案受限于物理线路，我转而尝试了更灵活的 Moon 方案。Moon 作为官方 Planet 的一个自定义补充节点，可以辅助设备进行寻址和中继，增加 P2P 打洞成功的概率。</p><p>我从服务器上提取了 <code>.moon</code> 配置文件，部署到本地客户端的 <code>moons.d</code> 目录下，然后重启了 ZeroTier 服务。</p><p>这一次，网络状况得到了质的改善。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">ping 10.10.52.124</span></span><br><span class="line">--- 10.10.52.124 ping 统计 ---</span><br><span class="line">已发送 19 个包， 已接收 19 个包, 0% packet loss, time 18031ms</span><br><span class="line">rtt min/avg/max/mdev = 57.315/58.608/65.970/1.802 ms</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">tracepath 10.10.52.124</span></span><br><span class="line"> 1?: [本地主机]                   PMTU 2800</span><br><span class="line"> 1:  10.10.52.124                                         58.757 毫秒 到达</span><br><span class="line"> ...</span><br></pre></td></tr></table></figure><p><strong>0%丢包，延迟稳定在 58 毫秒，一跳直达。</strong></p><p>这证明，在 Moon 节点的辅助下，ZeroTier 成功地为我找到了一条可以避开骨干网拥堵的 P2P 隧道。管理服务器所需要的稳定连接，现在有了。</p><h3 id="最后一步：彻底“隐形”"><a href="#最后一步：彻底“隐形”" class="headerlink" title="最后一步：彻底“隐形”"></a>最后一步：彻底“隐形”</h3><p>有了可靠的内网通道，我终于可以开始实施我最初的目标——将管理端口从公网上彻底移除。</p><p>我登录了云厂商的防火墙（安全组）控制台，修改了访问策略：</p><ul><li>删除了所有允许公网 (<code>0.0.0.0/0</code>) 访问服务器 TCP <code>22</code> 和 <code>3443</code> 端口的规则。</li><li>新增了一条规则，只允许来自我的 ZeroTier 子网 (<code>10.10.52.0/24</code>) 的 IP 地址访问这些端口。</li></ul><p>至于这个操作在 OSI 模型里算哪一层？</p><blockquote><p>ZeroTier 本身是一个构建在 OSI 第三层（网络层）之上的、为用户提供第二层（数据链路层）服务的虚拟网络解决方案。它像一个虚拟的以太网交换机，将二层数据帧封装在 UDP 包里，通过三层网络进行传输。<br>而我在云防火墙上的操作，是一个在基础设施虚拟化层实现的、作用于网络层和传输层（基于 IP 和 TCP 端口）的访问控制，但其效果，近乎于物理隔离。</p></blockquote><h4 id="图-1：改造前的“门户大开”架构"><a href="#图-1：改造前的“门户大开”架构" class="headerlink" title="图 1：改造前的“门户大开”架构"></a><strong>图 1：改造前的“门户大开”架构</strong></h4><pre class="mermaid">graph TD    subgraph "互联网 (公网)"        A[我的电脑]        B[香港 VPS<br>xxx.xxx.xxx.xxx<br>开放端口: 22, 443, 3443]    end    A -- "高延迟, 70%丢包<br>SSH端口暴露" --> B    style B fill:#f9f,stroke:#333,stroke-width:2px</pre><h4 id="图-2：改造后的“零信任”安全架构"><a href="#图-2：改造后的“零信任”安全架构" class="headerlink" title="图 2：改造后的“零信任”安全架构"></a><strong>图 2：改造后的“零信任”安全架构</strong></h4><pre class="mermaid">graph TD    subgraph " "        direction LR        subgraph "公网访问 (Public Access)"            C[全世界访客] --> D{Cloudflare CDN};        end        subgraph "服务器 (Server)"            direction LR            D --> E[香港 VPS<br><b>源站IP已隐藏</b><br>公网入口: 443];        end    end    subgraph " "        direction LR        subgraph "私有管理网络 (Management Network)"            F[我的设备<br>ZT: 10.10.52.159]            G[香港 VPS<br>ZT: 10.10.52.124<br><b>管理端口仅对内监听</b>]            F <== "ZeroTier P2P加密隧道<br>稳定58ms延迟" ==> G        end    end    style E fill:#9cf,stroke:#333,stroke-width:2px    style G fill:#9cf,stroke:#333,stroke-width:2px</pre><p>最终，我的服务器实现了“内外分离”：博客网站通过 Cloudflare 面向公网提供服务，源站 IP 被完美隐藏；而所有的管理入口，都“沉入”了仅对我可见的 ZeroTier 虚拟内网中。</p><p>虽然过程有些波折，但最终还是用自己熟悉的方式，解决了一个不大不小的问题。记录一下。</p>]]></content>
      
      
      <categories>
          
          <category> 技术实践 </category>
          
          <category> 开发运维 </category>
          
          <category> 服务器运维 </category>
          
          <category> 网络与安全 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 服务器运维 </tag>
            
            <tag> 网络优化 </tag>
            
            <tag> ZeroTier </tag>
            
            <tag> 安全加固 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>U-Net 学习总结</title>
      <link href="/2024/11/16/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E6%A8%A1%E5%9E%8B%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/U-Net-%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
      <url>/2024/11/16/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E6%A8%A1%E5%9E%8B%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/U-Net-%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h2 id="1-什么是-U-Net？"><a href="#1-什么是-U-Net？" class="headerlink" title="1. 什么是 U-Net？"></a>1. 什么是 U-Net？</h2><p>U-Net 是一种用于图像分割的卷积神经网络，最初由 Olaf Ronneberger 等人在 2015 年为医学图像分割设计。其独特的 U 形架构使其在生成高质量分割图像方面表现出色。</p><span id="more"></span><h2 id="2-U-Net-模型结构"><a href="#2-U-Net-模型结构" class="headerlink" title="2. U-Net 模型结构"></a>2. U-Net 模型结构</h2><p>U-Net 的架构可以分为两个主要部分：<strong>编码器(Encoder)</strong>和<strong>解码器(Decoder)</strong>.<br><img data-src="/img/2024/11/16/U-Net.png" alt="U-Net" title="U-Net"></p><ul><li><p>编码器</p><p>编码器部分由多个 <strong>卷积层</strong> 和 <strong>池化层</strong> 组成。每个卷积层后会接一个 <strong>ReLU 激活函数</strong>，并且通常在每两层卷积之后，插入一个 <strong>最大池化层</strong>，通过池化操作逐步减小空间分辨率(即进行下采样)。为了保持特征表达的丰富性，在每次下采样后，通道数通常会翻倍，从而允许网络学习更多的特征。</p></li><li><p>解码器</p><p>解码器部分负责逐步恢复编码器部分下采样后的特征图，并生成最终的分割结果。它由多个 <strong>上采样层</strong> 和 <strong>卷积层</strong> 组成。每次上采样操作会增大特征图的空间分辨率(随之通道数减半)，同时通过卷积层进一步处理特征。在解码器中，通常会通过 <strong>跳跃连接</strong> 将编码器对应层的特征图与解码器中的上采样特征图进行拼接，以保留空间细节信息，帮助恢复图像的精确结构。</p></li><li><p>跳跃连接</p><p><strong>跳跃连接(Skip Connection)</strong>是将编码器中某一层的特征图直接传递到解码器中的对应层。它通过拼接(或相加)操作，帮助解码器恢复空间细节信息，避免在下采样过程中丢失重要的局部特征。每个编码器层与解码器层之间都有一个跳跃连接，确保了解码器能够利用编码器的低层次特征进行精确的图像恢复。</p></li><li><p>瓶颈层</p><p><strong>瓶颈(BottleNeck)</strong>位于 U-Net 的<strong>编码器</strong>和<strong>解码器</strong>之间，是网络中<strong>最深</strong>的一层，也是 U-UNet 网络从编码器切换到解码器的地方。它由多个卷积层和激活函数组成，负责压缩输入特征并提取最重要的高层次信息。瓶颈层的输出特征图随后传递给解码器，帮助解码器恢复空间分辨率并生成最终的分割结果。</p></li></ul><h2 id="3-U-Net-处理过程"><a href="#3-U-Net-处理过程" class="headerlink" title="3. U-Net 处理过程"></a>3. U-Net 处理过程</h2><p>如下图</p><p><img data-src="/img/2024/11/16/U-Net-processing.png" alt="U-Net处理过程" title="U-Net处理过程"></p><p>U-Net 的训练过程实际上是在优化人工分割图（Ground Truth）与网络生成的分割图之间的差异。通过损失函数（如交叉熵或 Dice 系数损失）来衡量这两者之间的差异，网络通过反向传播逐步调整权重，最终使得生成的分割图越来越接近人工标注的真实分割图。</p><h2 id="4-总结"><a href="#4-总结" class="headerlink" title="4. 总结"></a>4. 总结</h2><p>U-Net 是一种经典的图像分割网络，其结构由编码器、瓶颈和解码器组成。编码器负责逐步提取图像特征，瓶颈部分压缩特征并提取高层次信息，而解码器则通过上采样和跳跃连接逐步恢复图像的空间分辨率，最终生成分割结果。与残差网络（ResNet）类似，U-Net 通过跳跃连接在编码器和解码器之间传递重要特征，确保细节信息在网络中不丢失。残差连接和跳跃连接都能帮助网络更有效地学习特征，减缓训练中的信息丢失问题，从而提升性能。</p><h2 id="5-参考资料"><a href="#5-参考资料" class="headerlink" title="5. 参考资料"></a>5. 参考资料</h2><ol><li><a href="https://youtu.be/NhdzGfB1q74?si=kK_bsYA_j8S_hbOh">The U-Net (actually) explained in 10 minutes</a></li><li><a href="https://ar5iv.labs.arxiv.org/html/1505.04597">U-Net: Convolutional Networks for Biomedical Image Segmentation</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 技术实践 </category>
          
          <category> 人工智能 </category>
          
          <category> 计算机视觉 </category>
          
          <category> 模型理论与实践 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> U-Net </tag>
            
            <tag> 图像分割 </tag>
            
            <tag> 神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2024.11.16随笔</title>
      <link href="/2024/11/16/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E6%A8%A1%E5%9E%8B%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/2024-11-16%E9%9A%8F%E7%AC%94/"/>
      <url>/2024/11/16/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E6%A8%A1%E5%9E%8B%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/2024-11-16%E9%9A%8F%E7%AC%94/</url>
      
        <content type="html"><![CDATA[<p>开始的地方：数据集和准备工作<br>最开始，我选择了 MTDC-UAV 数据集，这个数据集包含了许多图像和标注，适合做目标检测和回归任务。我编写了一个脚本，把 800 张有标注的图像按照 7:2:1 的比例随机分配成 Train、Valid、Test 集。重要的是，确保每个集合里的图片都是随机选取的，三个集合之间没有重复，并且每张图像都能找到对应的标注文件。</p><span id="more"></span><p>YOLOv5 的初步实验：尺寸与置信度的探索<br>一开始，我决定用 YOLOv5 来做一些基础实验，主要测试不同的训练和预测输入尺寸。具体来说，就是使用 640 和 1280 的组合来看看效果。最开始我随便设置了一个置信度（conf）值，然后再根据结果调整。可是后来发现这种方法效率太低了，一次次手动调整实在太浪费时间。</p><p>转折点：写脚本优化效率<br>意识到这个问题后，我写了个脚本，可以自动调整 conf 值的范围，来提高实验效率。我先把这个脚本用在了 YOLOv5 上，结果发现效果有了明显提升。</p><p>数据存储与可视化<br>为了方便分析，我写了个功能，把每次调整的结果存储到 Excel 中。这样我就可以直观地看到每个参数组合下的回归结果。接着，我又加了一个功能，能够根据 Excel 生成 MAE、RMSE、R² 的统计图，这样就能清晰地看到哪些配置最优。</p><p>继续实验：YOLOv8 和 YOLO11<br>接下来，我把相同的方法应用到了 YOLOv8 和 YOLO11 上，分别对它们进行了同样的实验。每个模型的不同配置下的表现都不错，我得到了 36 张统计图 和 3 个版本的统计表。</p><p>最终的结果：12 条最优组合<br>根据这些实验结果，我得出了 12 条最优数据组合。这些组合代表了每个模型和配置的最佳表现，可以通过下表查看。</p><table border="1">  <thead>    <tr style="background-color: green;">      <th>YOLO Ver.</th>      <th>Train Img</th>      <th>Test Img</th>      <th>SOpt. Conf.</th>      <th>MAE</th>      <th>RMSE</th>      <th>R²</th>    </tr>  </thead>  <tbody>    <tr>      <td>yolov5n</td>      <td>640</td>      <td>640</td>      <td>0.31</td>      <td>5.9375</td>      <td>7.8509554</td>      <td>0.9541248</td>    </tr>    <tr>      <td>yolov5n</td>      <td>640</td>      <td>1280</td>      <td>0.47</td>      <td>6.2125</td>      <td>8.1693023</td>      <td>0.950329</td>    </tr>    <tr>      <td>yolov5n</td>      <td>1280</td>      <td>640</td>      <td>0.18</td>      <td>6.7375</td>      <td>9.1917082</td>      <td>0.9371181</td>    </tr>    <tr>      <td>yolov5n</td>      <td>1280</td>      <td>1280</td>      <td>0.33</td>      <td>5.4</td>      <td>7.0816665</td>      <td>0.9626746</td>    </tr>    <tr>      <td>yolov8n</td>      <td>640</td>      <td>640</td>      <td>0.29</td>      <td>6.2625</td>      <td>7.9348913</td>      <td>0.9531386</td>    </tr>    <tr>      <td>yolov8n</td>      <td>640</td>      <td>1280</td>      <td>0.39</td>      <td>6.275</td>      <td>8.4926439</td>      <td>0.9463192</td>    </tr>    <tr>      <td>yolov8n</td>      <td>1280</td>      <td>640</td>      <td>0.29</td>      <td>6.2625</td>      <td>7.9348913</td>      <td>0.9531386</td>    </tr>    <tr>      <td>yolov8n</td>      <td>1280</td>      <td>1280</td>      <td>0.39</td>      <td>6.275</td>      <td>8.4926439</td>      <td>0.9463192</td>    </tr>    <tr>      <td>yolo11n</td>      <td>640</td>      <td>640</td>      <td>0.35</td>      <td>6</td>      <td>7.930952</td>      <td>0.9531851</td>    </tr>    <tr>      <td>yolo11n</td>      <td>640</td>      <td>1280</td>      <td>0.51</td>      <td>7.0875</td>      <td>9.2472969</td>      <td>0.9363552</td>    </tr>    <tr>      <td>yolo11n</td>      <td>1280</td>      <td>640</td>      <td>0.23</td>      <td>7.0125</td>      <td>9.3828301</td>      <td>0.9344759</td>    </tr>    <tr>      <td>yolo11n</td>      <td>1280</td>      <td>1280</td>      <td>0.32</td>      <td>5.1875</td>      <td>7.1388024</td>      <td>0.9620699</td>    </tr>  </tbody></table><p>总结<br>YOLO 在回归计数任务中的表现非常出色，尤其是当我通过调整 conf 值后，性能提升显著。这些实验结果表明，YOLO 不仅在目标检测中表现出色，在回归任务中也能大展拳脚，尤其是在密集计数或小物体检测场景下。</p>]]></content>
      
      
      <categories>
          
          <category> 技术实践 </category>
          
          <category> 人工智能 </category>
          
          <category> 计算机视觉 </category>
          
          <category> 模型理论与实践 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> YOLO </tag>
            
            <tag> 玉米穗检测 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 计算机视觉 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2024.11.12随笔</title>
      <link href="/2024/11/12/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E6%A8%A1%E5%9E%8B%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/2024-11-12%E9%9A%8F%E7%AC%94/"/>
      <url>/2024/11/12/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E6%A8%A1%E5%9E%8B%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/2024-11-12%E9%9A%8F%E7%AC%94/</url>
      
        <content type="html"><![CDATA[<h2 id="Papers-Summary"><a href="#Papers-Summary" class="headerlink" title="Papers Summary:"></a>Papers Summary:</h2><h3 id="Fusing-Global-and-Local-Information-Network-for-Tassel-Detection-in-UAV-Imagery"><a href="#Fusing-Global-and-Local-Information-Network-for-Tassel-Detection-in-UAV-Imagery" class="headerlink" title="Fusing Global and Local Information Network for Tassel Detection in UAV Imagery"></a>Fusing Global and Local Information Network for Tassel Detection in UAV Imagery</h3><p>作者提到过去的三种玉米穗计数方法，分别是如下三种：</p><span id="more"></span><p>Faster R-CNN：用于检测玉米雄花，但由于其只利用单层特征映射，精度受限。</p><p>YOLOX：通过嵌入通道注意力来提高处理速度，但其对小物体的检测能力有限。</p><p>YOLOv5-Tassel：一种增强方法，结合浅层信息增强小物体感知，但结构复杂且参数较多。</p><p>上述三种方法要么是为了提升速度却导致精度过低，要么就是为了增强精度使得消耗资源过多速度太慢，为了解决这个问题，作者提出并公开了一种网络架构 FGLNet，并基于 Lu 等人的点标注数据集<a href="https://github.com/poppinace/mtc-uav">MTC-UAV</a>，主动为其增加了边框标注，并将其命名为玉米雄花检测与计数数据集<a href="https://github.com/Ye-Sk/MTDC-UAV">MTDC-UAV</a>。该数据集现已公开发布。</p><p>MTDC-UAV 数据集是基于原始的 MTC-UAV 数据集扩展而来，用于玉米雄花的检测与计数。原 MTC-UAV 数据集中包含 306 张图像，作者从中抽取了 106 张保留点标注用于计数测试，并将它们存放在 Counting 文件夹中。剩余的 200 张图像则被四等分生成 800 张子图，并重新进行了框标注，其中前 500 张作为训练集，后 300 张作为检测测试集，存放在 Detection 文件夹中。</p><p>FGLNet 采用了特征金字塔结构，通过在不同层级的特征图（如 C2、C3、C4）上提取信息，实现对各种尺度的目标进行检测。这种多尺度特征融合方式有效提升了小目标的检测精度，尤其适用于复杂场景中的细节捕捉。</p><p>在 FGLNet 中，为了高效结合全局与局部信息，模型使用了 CSPDarknet 作为特征提取骨干网络，并引入了 G-Fusion 模块用于全局信息的提取。通过对多尺度特征图（C2、C3、C4）的加权平均和对齐，该模块在保持计算效率的同时，增强了对细节的捕捉。随后，利用 Inject 模块，通过注意力机制将全局与局部信息进一步融合。</p><p>最后，FGLNet 的损失函数包含两部分：分类损失和定位损失。分类损失采用二元交叉熵损失（BCE）来评估类别匹配的准确性，定位损失则使用完整 IoU（CIoU）来精确测量预测框与真实框之间的距离、面积和形状差异。这种设计提高了 FGLNet 在目标检测和定位上的表现，有助于更准确地识别和计数作物花序。</p><h3 id="实验与分析："><a href="#实验与分析：" class="headerlink" title="实验与分析："></a>实验与分析：</h3><p>实现细节：FGLNet 在相同配置下训练和测试，基于 PyTorch 并用 CUDA 加速。图像缩放到 1216 像素，使用 COCO 上预训练的<strong>CSPDarknet</strong>作为骨干网络。优化器采用<strong>AdamW</strong>，学习率为 0.002，批量大小为<strong>4</strong>，训练<strong>150</strong>轮，并应用数据增强以防过拟合。</p><p>评价指标：检测性能通过精确率 (P)、召回率 (R)、AP50 和 AP50-95 来评估，以衡量模型的定位与分类能力。</p><p>对比结果：FGLNet 优于 Faster R-CNN、FCOS、Yolov8、WheatLFANet 和 TasselLFANet，尤其在小物体检测上表现出色，主要得益于其更大特征图与全局-局部信息融合的架构设计。</p><h3 id="计数实验与可视化："><a href="#计数实验与可视化：" class="headerlink" title="计数实验与可视化："></a>计数实验与可视化：</h3><p>在 106 张 MTDC-UAV 图像上进行计数评估，并与 TasselNetV2 进行比较。结果显示，FGLNet 在计数精度和鲁棒性上优于其他方法，参数规模为 0.77M，紧随其后的是 WheatLFANet。Faster R-CNN 在计数性能上表现较差，主要由于信息丢失，无法有效适应 UAV 图像。尽管提高分辨率有助于性能提升，但会带来较高的计算成本。通过使用特征金字塔网络（FPN）可进一步优化性能。</p>]]></content>
      
      
      <categories>
          
          <category> 技术实践 </category>
          
          <category> 人工智能 </category>
          
          <category> 计算机视觉 </category>
          
          <category> 模型理论与实践 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> YOLO </tag>
            
            <tag> 玉米穗检测 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 计算机视觉 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>利用termux实现免root的code-server</title>
      <link href="/2024/10/15/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E5%BC%80%E5%8F%91%E8%BF%90%E7%BB%B4/%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/%E7%A7%BB%E5%8A%A8%E7%AB%AF/Termux/%E5%88%A9%E7%94%A8termux%E5%AE%9E%E7%8E%B0%E5%85%8Droot%E7%9A%84code-server/"/>
      <url>/2024/10/15/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E5%BC%80%E5%8F%91%E8%BF%90%E7%BB%B4/%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/%E7%A7%BB%E5%8A%A8%E7%AB%AF/Termux/%E5%88%A9%E7%94%A8termux%E5%AE%9E%E7%8E%B0%E5%85%8Droot%E7%9A%84code-server/</url>
      
        <content type="html"><![CDATA[<p>很多小伙伴由于各种原因无法在自己的安卓设备上获取 root 权限，从而无法配置 chroot 容器，不过，虽然没有 chroot 环境，但我们仍然可以配置一个 code-server,以下是配置过程。</p><p>测试机: <strong>华为 matepad 11.5s 灵动版, Android 12</strong></p><span id="more"></span><p><img data-src="/img/2024/10/6/code-server.png" alt="Code-server" title="Code-server"></p><p align="center">code-server运行截图</p><h2 id="1-硬件要求"><a href="#1-硬件要求" class="headerlink" title="1. 硬件要求"></a>1. <strong>硬件要求</strong></h2><p>一台 Android 10 及以上系统的手机。</p><h2 id="2-系统要求"><a href="#2-系统要求" class="headerlink" title="2. 系统要求"></a>2. <strong>系统要求</strong></h2><p>已安装 <strong><a href="https://termux.dev/">Termux</a></strong></p><h2 id="3-Termux-换源"><a href="#3-Termux-换源" class="headerlink" title="3. Termux 换源"></a>3. <strong>Termux 换源</strong></h2><p><strong>图形界面（TUI）替换</strong></p><p>在较新版的 Termux 中，官方提供了图形界面（TUI）来半自动替换镜像，推荐使用该种方式以规避其他风险。<br>在 Termux 中执行如下命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">termux-change-repo</span><br><span class="line">apt update&amp;&amp;apt upgrade</span><br></pre></td></tr></table></figure><p>在图形界面引导下，使用自带方向键可上下移动。<br>第一步使用空格选择需要更换的仓库，之后在第二步选择国内镜像源，如清华大学开源镜像站。确认无误后回车，镜像源会自动完成更换。</p><h2 id="4-安装-Node-js"><a href="#4-安装-Node-js" class="headerlink" title="4. 安装 Node.js"></a>4. <strong>安装 Node.js</strong></h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">apt install -y \</span><br><span class="line">  build-essential \</span><br><span class="line">  binutils \</span><br><span class="line">  pkg-config \</span><br><span class="line">  python3 \</span><br><span class="line">  nodejs-lts</span><br></pre></td></tr></table></figure><h2 id="5-安装-code-server"><a href="#5-安装-code-server" class="headerlink" title="5. 安装 code-server"></a>5. <strong>安装 code-server</strong></h2><p>配置 android_ndk_path</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/../usr/etc/bash.bashrc</span><br></pre></td></tr></table></figure><p>加入一行如下内容并保存</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> GYP_DEFINES=<span class="string">&quot;android_ndk_path=&#x27;&#x27;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> NODE_OPTIONS=<span class="string">&quot;--require /data/data/com.termux/files/home/android-as-linux.js&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> EXTENSIONS_GALLERY=<span class="string">&#x27;&#123;&quot;serviceUrl&quot;: &quot;https://marketplace.visualstudio.com/_apis/public/gallery&quot;,&quot;itemUrl&quot;: &quot;https://marketplace.visualstudio.com/items&quot;&#125;&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>第一个环境变量是为了顺利通过 code-server 的编译</p><p>第二个则是将 termux 伪装成 Linux</p><p>第三个是替换 code-server 的 marketplace 为微软官方 marketplace</p><p>创建 android-as-linux.js</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">touch</span> ~/android-as-linux.js</span><br><span class="line">vim ~/android-as-linux.js</span><br></pre></td></tr></table></figure><p>输入如下内容并保存</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// android-as-linux.js</span></span><br><span class="line"><span class="title class_">Object</span>.<span class="title function_">defineProperty</span>(process, <span class="string">&quot;platform&quot;</span>, &#123;</span><br><span class="line">  <span class="title function_">get</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;linux&quot;</span>;</span><br><span class="line">  &#125;,</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>应用环境变量</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> ~/../usr/etc/bash.bashrc</span><br></pre></td></tr></table></figure><p>安装<a href="https://github.com/coder/code-server">code-server</a></p><p>注意 ⚠️:此操作可能需要梯子 🪜，请自备</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install --global code-server</span><br></pre></td></tr></table></figure><h2 id="6-配置-code-server"><a href="#6-配置-code-server" class="headerlink" title="6.配置 code-server"></a>6.<strong>配置 code-server</strong></h2><ol><li><p>先启动 code-server 以自动创建配置文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">code-server</span><br></pre></td></tr></table></figure></li><li><p>修改 code-server 监听地址和密码</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.config/code-server/config.yaml</span><br></pre></td></tr></table></figure><p>改为如下内容</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bind-addr: 0.0.0.0:8080 //0.0.0.0是允许局域网设备访问的ip地址</span><br><span class="line">auth: none //无密码，不建议为它设置密码，由于使用环境较为安全，密码没有什么意义</span><br><span class="line">cert: false //无加密，局域网SSL证书过于麻烦</span><br></pre></td></tr></table></figure></li><li><p>启动 code-server 并用浏览器访问</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">code-server</span><br></pre></td></tr></table></figure><p>此时可以在本机浏览器测试，输入 localhost:8080 即可</p><p>其他局域网设备则输入 ip:8080</p></li><li><p>(可选)配置 Chrome&#x2F;Edge 浏览器以完全启用网页端 code-server 功能<br>访问 Chrome:&#x2F;&#x2F;flags 或 Edge:&#x2F;&#x2F;flags，并搜索 Insecure origins treated as secure，在下面输入 http:&#x2F;&#x2F;<span></span>ip:8080，此后再访问就不会提示不安全和部分 js 脚本无法正常执行</p></li><li><p>具体 vscode 的配置过程这里暂时不介绍了</p></li></ol><h2 id="7-设置一键启动脚本"><a href="#7-设置一键启动脚本" class="headerlink" title="7.设置一键启动脚本"></a>7.<strong>设置一键启动脚本</strong></h2><p>Termux 有一个好用的插件，叫作 <a href="https://f-droid.org/zh_Hant/packages/com.termux.widget/">Termux:Widget</a>,这个插件可以在桌面创建启动脚本的快捷方式，按如下步骤操作</p><ol><li>先安装<a href="https://f-droid.org/zh_Hant/packages/com.termux.widget/">Termux:Widget</a></li><li>为 Termux 授权 [显示在其他应用上方] 权限</li><li>编辑启动脚本<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> vim /data/local/tmp/Code-Server</span><br></pre></td></tr></table></figure></li><li>将 busybox chroot $UBUNTUPATH &#x2F;bin&#x2F;su - root 中的 root 改成你的用户名。</li><li>新建快捷方式脚本<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">touch</span> ~/.shortcuts/Code-Server</span><br><span class="line"><span class="built_in">chmod</span> +x ~/.shortcuts/Code-Server</span><br><span class="line">vim ~/.shortcuts/Code-Server</span><br></pre></td></tr></table></figure>填入如下内容<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">code-server</span><br></pre></td></tr></table></figure></li><li>修复 shebang 以便 termux:widget 能够识别<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">termux-fix-shebang ~/bin/code-server</span><br></pre></td></tr></table></figure></li><li>回到手机桌面，拖动 Termux:Widget 小部件到桌面</li></ol><h2 id="8-参考资料"><a href="#8-参考资料" class="headerlink" title="8. 参考资料"></a>8. <strong>参考资料</strong></h2><p><a href="https://github.com/coder/code-server">code-server</a></p><p><a href="https://www.cnblogs.com/mcayear/p/18407607">termux 使用 npm 拉取出现 gyp: Undefined variable android_ndk_path in binding.gyp while trying to load binding.gyp</a></p>]]></content>
      
      
      <categories>
          
          <category> 技术实践 </category>
          
          <category> 开发运维 </category>
          
          <category> 开发环境 </category>
          
          <category> 移动端 </category>
          
          <category> Termux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Termux </tag>
            
            <tag> code-server </tag>
            
            <tag> 随身IDE </tag>
            
            <tag> 集成开发环境 </tag>
            
            <tag> 移动开发工具 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>在手机上打造随身开发环境：Termux与code-server的完美结合</title>
      <link href="/2024/10/06/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E5%BC%80%E5%8F%91%E8%BF%90%E7%BB%B4/%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/%E7%A7%BB%E5%8A%A8%E7%AB%AF/Termux/%E5%9C%A8%E6%89%8B%E6%9C%BA%E4%B8%8A%E6%89%93%E9%80%A0%E9%9A%8F%E8%BA%AB%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%EF%BC%9ATermux%E4%B8%8Ecode-server%E7%9A%84%E5%AE%8C%E7%BE%8E%E7%BB%93%E5%90%88/"/>
      <url>/2024/10/06/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/%E5%BC%80%E5%8F%91%E8%BF%90%E7%BB%B4/%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/%E7%A7%BB%E5%8A%A8%E7%AB%AF/Termux/%E5%9C%A8%E6%89%8B%E6%9C%BA%E4%B8%8A%E6%89%93%E9%80%A0%E9%9A%8F%E8%BA%AB%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%EF%BC%9ATermux%E4%B8%8Ecode-server%E7%9A%84%E5%AE%8C%E7%BE%8E%E7%BB%93%E5%90%88/</url>
      
        <content type="html"><![CDATA[<p>在使用 <strong>Linux Deploy</strong> 配置 Chroot 环境时，我发现虽然它提供了便利，但其长期无人维护的问题逐渐显露出来。可选的 <strong>Linux</strong> 发行版过于老旧，导致一些功能失效，且细节设置也不尽人意。为了解决这些问题，我决定转向 <strong>Termux</strong> 来配置 Chroot 环境。这样一来，我不仅能够使用更新的发行版，还能进行更加精细的设置，从而打造出一个更符合我需求的 <strong>Chroot</strong> 环境。</p><p>本文以 <strong>Ubuntu 24.04.1 LTS</strong> 为例，建立了一个安装了 <strong>code-server</strong> 的 Chroot 容器，文末会提供一键启动脚本。</p><p>测试机: <strong>Oneplus 9, Android 14</strong></p><span id="more"></span><p><img data-src="/img/2024/10/6/code-server.png" alt="Code-server" title="Code-server"></p><p align="center">code-server运行截图</p><h2 id="1-硬件要求"><a href="#1-硬件要求" class="headerlink" title="1. 硬件要求"></a>1. <strong>硬件要求</strong></h2><p>一台 Android 10 及以上系统的手机。</p><h2 id="2-系统要求"><a href="#2-系统要求" class="headerlink" title="2. 系统要求"></a>2. <strong>系统要求</strong></h2><ol><li>手机已刷入<a href="https://topjohnwu.github.io/Magisk/">Magisk</a>、<a href="https://kernelsu.org/">KernelSU</a>以及 <a href="https://apatch.dev/">Apatch</a>中的任何一种。</li><li>已安装 <strong><a href="https://termux.dev/">Termux</a></strong></li></ol><h2 id="3-Termux-换源"><a href="#3-Termux-换源" class="headerlink" title="3. Termux 换源"></a>3. <strong>Termux 换源</strong></h2><p><strong>图形界面（TUI）替换</strong></p><p>在较新版的 Termux 中，官方提供了图形界面（TUI）来半自动替换镜像，推荐使用该种方式以规避其他风险。<br>在 Termux 中执行如下命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">termux-change-repo</span><br></pre></td></tr></table></figure><p>在图形界面引导下，使用自带方向键可上下移动。<br>第一步使用空格选择需要更换的仓库，之后在第二步选择国内镜像源，如清华大学开源镜像站。确认无误后回车，镜像源会自动完成更换。</p><h2 id="4-安裝-Ubuntu-Chroot-環境"><a href="#4-安裝-Ubuntu-Chroot-環境" class="headerlink" title="4. 安裝 Ubuntu Chroot 環境"></a>4. <strong>安裝 Ubuntu Chroot 環境</strong></h2><ol><li><p>开启 Termux，并安装<strong>tsu</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">apt update</span><br><span class="line">apt install tsu</span><br></pre></td></tr></table></figure></li><li><p>切换到 su shell</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">su</span><br></pre></td></tr></table></figure></li><li><p>选择&#x2F;data&#x2F;local&#x2F;tmp 创建 chroot 目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /data/local/tmp/Ubuntu</span><br><span class="line"><span class="built_in">cd</span> /data/local/tmp/Ubuntu</span><br></pre></td></tr></table></figure><p>&#x2F;data&#x2F;local&#x2F;tmp 目录的权限问题最少，故选择此目录</p></li><li><p>下载 Ubuntu 24.04.1 base 系统的 rootfs 压缩包</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://mirror.tuna.tsinghua.edu.cn/ubuntu-cdimage/ubuntu-base/releases/24.04.1/release/ubuntu-base-24.04.1-base-arm64.tar.gz</span><br></pre></td></tr></table></figure></li><li><p>解压并建立&#x2F;sdcard 的共享点</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar xpvf ubuntu-base-24.04.1-base-arm64.tar.gz --numeric-owner</span><br><span class="line"><span class="built_in">mkdir</span> sdcard</span><br><span class="line"><span class="built_in">cd</span> ..</span><br></pre></td></tr></table></figure></li><li><p>新建 chroot 启动脚本:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi Ubuntu.sh</span><br></pre></td></tr></table></figure><p>并填入以下内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Ubuntu所在目录</span></span><br><span class="line">UBUNTUPATH=<span class="string">&quot;/data/local/tmp/Ubuntu&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 解决setuid问题</span></span><br><span class="line">busybox mount -o remount,dev,suid /data</span><br><span class="line"></span><br><span class="line">busybox mount --<span class="built_in">bind</span> /dev <span class="variable">$UBUNTUPATH</span>/dev</span><br><span class="line">busybox mount --<span class="built_in">bind</span> /sys <span class="variable">$UBUNTUPATH</span>/sys</span><br><span class="line">busybox mount --<span class="built_in">bind</span> /proc <span class="variable">$UBUNTUPATH</span>/proc</span><br><span class="line">busybox mount -t devpts devpts <span class="variable">$UBUNTUPATH</span>/dev/pts</span><br><span class="line"></span><br><span class="line"><span class="comment"># 挂载内部存储空间</span></span><br><span class="line">busybox mount --<span class="built_in">bind</span> /sdcard <span class="variable">$UBUNTUPATH</span>/sdcard</span><br><span class="line"></span><br><span class="line"><span class="comment"># chroot至Ubuntu</span></span><br><span class="line">busybox <span class="built_in">chroot</span> <span class="variable">$UBUNTUPATH</span> /bin/su - root</span><br><span class="line"></span><br><span class="line"><span class="comment"># 取消挂载</span></span><br><span class="line">busybox umount <span class="variable">$UBUNTUPATH</span>/dev/pts</span><br><span class="line">busybox umount <span class="variable">$UBUNTUPATH</span>/dev</span><br><span class="line">busybox umount <span class="variable">$UBUNTUPATH</span>/proc</span><br><span class="line">busybox umount <span class="variable">$UBUNTUPATH</span>/sys</span><br><span class="line">busybox umount <span class="variable">$UBUNTUPATH</span>/sdcard</span><br></pre></td></tr></table></figure></li><li><p>授予脚本执行权限</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">chmod</span> +x Ubuntu.sh</span><br></pre></td></tr></table></figure></li><li><p>进入 chroot</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh Ubuntu.sh</span><br></pre></td></tr></table></figure></li><li><p>设置 dns 和主机名</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置AliDNS</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;nameserver 223.5.5.5&quot;</span> &gt; /etc/resolv.conf</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;127.0.0.1 localhost&quot;</span> &gt; /etc/hosts</span><br></pre></td></tr></table></figure></li><li><p>授予 socket 权限以便 chroot 容器联网</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">groupadd -g 3003 aid_inet</span><br><span class="line">groupadd -g 3004 aid_net_raw</span><br><span class="line">groupadd -g 1003 aid_graphics</span><br><span class="line">usermod -g 3003 -G 3003,3004 -a _apt</span><br><span class="line">usermod -G 3003 -a root</span><br></pre></td></tr></table></figure></li><li><p>更新 Ubuntu 软件源和系统并更换镜像源</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> /dev/null &gt; /etc/apt/sources.list</span><br><span class="line"></span><br><span class="line"><span class="built_in">touch</span> /etc/apt/sources.list.d/debian.sources</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;</span></span><br><span class="line"><span class="string">Types: deb</span></span><br><span class="line"><span class="string">Types: deb</span></span><br><span class="line"><span class="string">URIs: https://mirrors.tuna.tsinghua.edu.cn/ubuntu</span></span><br><span class="line"><span class="string">Suites: noble noble-updates noble-backports</span></span><br><span class="line"><span class="string">Components: main restricted universe multiverse</span></span><br><span class="line"><span class="string">Signed-By: /usr/share/keyrings/ubuntu-archive-keyring.gpg</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Types: deb</span></span><br><span class="line"><span class="string">URIs: http://security.ubuntu.com/ubuntu/</span></span><br><span class="line"><span class="string">Suites: noble-security</span></span><br><span class="line"><span class="string">Components: main restricted universe multiverse</span></span><br><span class="line"><span class="string">Signed-By: /usr/share/keyrings/ubuntu-archive-keyring.gpg</span></span><br><span class="line"><span class="string">&#x27;</span> &gt; /etc/apt/sources.list.d/ubuntu.sources</span><br><span class="line"></span><br><span class="line">apt update&amp;&amp;apt upgrade -y</span><br><span class="line">apt install vim net-tools <span class="built_in">sudo</span> git</span><br></pre></td></tr></table></figure></li><li><p>新增普通用户及本地化</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设定时区为中国上海</span></span><br><span class="line"><span class="built_in">ln</span> -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改root密码</span></span><br><span class="line">passwd root</span><br><span class="line"></span><br><span class="line"><span class="comment"># 新增普通用户</span></span><br><span class="line">groupadd storage</span><br><span class="line">groupadd wheel</span><br><span class="line">useradd -m -g <span class="built_in">users</span> -G wheel,audio,video,storage,aid_inet -s /bin/bash user</span><br><span class="line">passwd user</span><br><span class="line"></span><br><span class="line"><span class="comment"># 編輯：vim /etc/sudoers，在root ALL=(ALL) ALL的下一行加入以下內容:</span></span><br><span class="line">user    ALL=(ALL:ALL) ALL</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切换到普通用户</span></span><br><span class="line">su user</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装locales并切换为简体中文</span></span><br><span class="line"><span class="built_in">sudo</span> apt install locales</span><br><span class="line"><span class="built_in">sudo</span> locale-gen zh_CN.UTF-8</span><br></pre></td></tr></table></figure></li><li><p>卸载并禁止 Snap</p><p>卸载 snap</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt autopurge snapd</span><br></pre></td></tr></table></figure><p>禁止 snap 安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &lt;&lt;<span class="string">EOF | sudo tee /etc/apt/preferences.d/nosnap.pref</span></span><br><span class="line"><span class="string"># To prevent repository packages from triggering the installation of Snap,</span></span><br><span class="line"><span class="string"># this file forbids snapd from being installed by APT.</span></span><br><span class="line"><span class="string"># For more information: https://linuxmint-user-guide.readthedocs.io/en/latest/snap.html</span></span><br><span class="line"><span class="string">Package: snapd</span></span><br><span class="line"><span class="string">Pin: release a=*</span></span><br><span class="line"><span class="string">Pin-Priority: -10</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure></li><li><p>设置一键启动脚本</p><p>Termux 有一个好用的插件，叫作 <a href="https://f-droid.org/zh_Hant/packages/com.termux.widget/">Termux:Widget</a>,这个插件可以在桌面创建启动脚本的快捷方式，按如下步骤操作</p><ol><li><p>退出 chroot 环境</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">exit</span><br></pre></td></tr></table></figure></li><li><p>先安装<a href="https://f-droid.org/zh_Hant/packages/com.termux.widget/">Termux:Widget</a></p></li><li><p>为 Termux 授权 [显示在其他应用上方] 权限</p></li><li><p>编辑 chroot 启动脚本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> vim /data/local/tmp/Ubuntu.sh</span><br></pre></td></tr></table></figure></li><li><p>将 busybox chroot $UBUNTUPATH &#x2F;bin&#x2F;su - root 中的 root 改成你的用户名。</p></li><li><p>新建快捷方式脚本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">touch</span> ~/.shortcuts/Ubuntu</span><br><span class="line"><span class="built_in">chmod</span> +x ~/.shortcuts/Ubuntu</span><br><span class="line">vim ~/.shortcuts/Ubuntu</span><br></pre></td></tr></table></figure><p>填入如下内容</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"><span class="built_in">export</span> ASH_STANDALONE=1</span><br><span class="line"></span><br><span class="line">su -c cmd wifi force-low-latency-mode enabled</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;启用Wi-Fi低延迟模式&quot;</span></span><br><span class="line">su -c busybox mount --<span class="built_in">bind</span> <span class="variable">$PREFIX</span>/tmp /data/local/tmp/ubuntu/tmp</span><br><span class="line"></span><br><span class="line">su -c <span class="string">&quot;sh /data/local/tmp/startu.sh&quot;</span></span><br><span class="line">su -c cmd wifi force-low-latency-mode disabled</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;禁用Wi-Fi低延迟模式&quot;</span></span><br></pre></td></tr></table></figure></li><li><p>回到手机桌面，拖动 Termux:Widget 小部件到桌面</p></li></ol></li></ol><h2 id="5-安装-code-server"><a href="#5-安装-code-server" class="headerlink" title="5. 安装 code-server"></a>5. <strong>安装 code-server</strong></h2><ol><li><p>安装<a href="https://github.com/coder/code-server">code-server</a></p><p>进入 chroot，执行如下命令，若 curl 报错请确定自己是否开启了科学上网工具，这里暂不介绍其如何使用</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -fsSL https://code-server.dev/install.sh | sh</span><br></pre></td></tr></table></figure></li><li><p>先启动 code-server 以自动创建配置文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">code-server</span><br></pre></td></tr></table></figure></li><li><p>配置 code-server 使用微软官方 marketplace</p><p>由于微软的用户政策使得开源版本的 code 都不被允许使用微软官方的插件商城，导致开源版本的 code 只能使用开源的 marketplace，其中很多插件版本过旧，无法使用，因此我在这里附上如何修改内置的 marketplace</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bashrc</span><br><span class="line">//sudo vim /etc/profile //修改这个文件也可以</span><br></pre></td></tr></table></figure><p>向文件中插入一行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> EXTENSIONS_GALLERY = <span class="string">&quot;&#123;&quot;</span>serviceUrl<span class="string">&quot;: &quot;</span>https://marketplace.visualstudio.com/_apis/public/gallery<span class="string">&quot;,&quot;</span>itemUrl<span class="string">&quot;: &quot;</span>https://marketplace.visualstudio.com/items<span class="string">&quot;&#125;&quot;</span></span><br></pre></td></tr></table></figure></li><li><p>修改 code-server 监听地址和密码</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.config/code-server/config.yaml</span><br></pre></td></tr></table></figure><p>改为如下内容</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bind-addr: 0.0.0.0:8080 //0.0.0.0是允许局域网设备访问的ip地址</span><br><span class="line">auth: none //无密码，不建议为它设置密码，由于使用环境较为安全，密码没有什么意义</span><br><span class="line">cert: false //无加密，局域网SSL证书过于麻烦</span><br></pre></td></tr></table></figure></li><li><p>启动 code-server 并用浏览器访问</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">code-server</span><br></pre></td></tr></table></figure><p>此时可以在本机浏览器测试，输入 localhost:8080 即可</p><p>其他局域网设备则输入 ip:8080</p></li><li><p>(可选)配置 Chrome&#x2F;Edge 浏览器以完全启用网页端 code-server 功能<br>访问 Chrome:&#x2F;&#x2F;flags 或 Edge:&#x2F;&#x2F;flags，并搜索 Insecure origins treated as secure，在下面输入 http:&#x2F;&#x2F;<span></span>ip:8080，此后再访问就不会提示不安全和部分 js 脚本无法正常执行</p></li><li><p>具体 vscode 的配置过程这里暂时不介绍了</p></li></ol><h2 id="6-安全退出和删除-Chroot-环境"><a href="#6-安全退出和删除-Chroot-环境" class="headerlink" title="6. 安全退出和删除 Chroot 环境"></a>6. <strong>安全退出和删除 Chroot 环境</strong></h2><ol><li>退出 chroot 环境<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">exit</span></span><br></pre></td></tr></table></figure></li><li>如何安全删除 chroot 环境<br>请务必在 exit 后并确定取消挂载一切 chroot 相关目录后删除 chroot 文件夹，本例中文件夹在&#x2F;data&#x2F;local&#x2F;tmp&#x2F;Ubuntu，否则可能会导致&#x2F;sdcard 甚至系统文件被删除，最稳妥的方式是重启后删除，重启后所有挂载都会重置</li></ol><h2 id="7-参考资料"><a href="#7-参考资料" class="headerlink" title="7. 参考资料"></a>7. <strong>参考资料</strong></h2><p><a href="https://ivonblog.com/posts/termux-chroot-ubuntu/#7-%E8%A8%AD%E5%AE%9A%E4%B8%80%E9%8D%B5%E5%95%9F%E5%8B%95%E6%8C%87%E4%BB%A4%E7%A8%BF">[Root] 手機 Termux 建立 chroot Ubuntu 環境，免 Linux Deploy · Ivon 的部落格</a></p><p><a href="https://github.com/coder/code-server">code-server</a></p>]]></content>
      
      
      <categories>
          
          <category> 技术实践 </category>
          
          <category> 开发运维 </category>
          
          <category> 开发环境 </category>
          
          <category> 移动端 </category>
          
          <category> Termux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Termux </tag>
            
            <tag> code-server </tag>
            
            <tag> 随身IDE </tag>
            
            <tag> 集成开发环境 </tag>
            
            <tag> 移动开发工具 </tag>
            
            <tag> Chroot </tag>
            
            <tag> Ubuntu </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
