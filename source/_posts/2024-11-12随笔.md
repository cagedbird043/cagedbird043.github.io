---
title: 2024.11.12随笔
date: 2024-11-12 12:14:34
tags:
  - YOLO
  - 玉米穗检测
  - 深度学习
  - 计算机视觉
categories: 随笔
cover: /img/2024/11/12/MTDC-UAV.png
---

## Papers Summary:

### Fusing Global and Local Information Network for Tassel Detection in UAV Imagery

作者提到过去的三种玉米穗计数方法，分别是如下三种：

<!-- more -->

Faster R-CNN：用于检测玉米雄花，但由于其只利用单层特征映射，精度受限。

YOLOX：通过嵌入通道注意力来提高处理速度，但其对小物体的检测能力有限。

YOLOv5-Tassel：一种增强方法，结合浅层信息增强小物体感知，但结构复杂且参数较多。

上述三种方法要么是为了提升速度却导致精度过低，要么就是为了增强精度使得消耗资源过多速度太慢，为了解决这个问题，作者提出并公开了一种网络架构 FGLNet，并基于 Lu 等人的点标注数据集[MTC-UAV](https://github.com/poppinace/mtc-uav)，主动为其增加了边框标注，并将其命名为玉米雄花检测与计数数据集[MTDC-UAV](https://github.com/Ye-Sk/MTDC-UAV)。该数据集现已公开发布。

MTDC-UAV 数据集是基于原始的 MTC-UAV 数据集扩展而来，用于玉米雄花的检测与计数。原 MTC-UAV 数据集中包含 306 张图像，作者从中抽取了 106 张保留点标注用于计数测试，并将它们存放在 Counting 文件夹中。剩余的 200 张图像则被四等分生成 800 张子图，并重新进行了框标注，其中前 500 张作为训练集，后 300 张作为检测测试集，存放在 Detection 文件夹中。

FGLNet 采用了特征金字塔结构，通过在不同层级的特征图（如 C2、C3、C4）上提取信息，实现对各种尺度的目标进行检测。这种多尺度特征融合方式有效提升了小目标的检测精度，尤其适用于复杂场景中的细节捕捉。

在 FGLNet 中，为了高效结合全局与局部信息，模型使用了 CSPDarknet 作为特征提取骨干网络，并引入了 G-Fusion 模块用于全局信息的提取。通过对多尺度特征图（C2、C3、C4）的加权平均和对齐，该模块在保持计算效率的同时，增强了对细节的捕捉。随后，利用 Inject 模块，通过注意力机制将全局与局部信息进一步融合。

最后，FGLNet 的损失函数包含两部分：分类损失和定位损失。分类损失采用二元交叉熵损失（BCE）来评估类别匹配的准确性，定位损失则使用完整 IoU（CIoU）来精确测量预测框与真实框之间的距离、面积和形状差异。这种设计提高了 FGLNet 在目标检测和定位上的表现，有助于更准确地识别和计数作物花序。

### 实验与分析：

实现细节：FGLNet 在相同配置下训练和测试，基于 PyTorch 并用 CUDA 加速。图像缩放到 1216 像素，使用 COCO 上预训练的**CSPDarknet**作为骨干网络。优化器采用**AdamW**，学习率为 0.002，批量大小为**4**，训练**150**轮，并应用数据增强以防过拟合。

评价指标：检测性能通过精确率 (P)、召回率 (R)、AP50 和 AP50-95 来评估，以衡量模型的定位与分类能力。

对比结果：FGLNet 优于 Faster R-CNN、FCOS、Yolov8、WheatLFANet 和 TasselLFANet，尤其在小物体检测上表现出色，主要得益于其更大特征图与全局-局部信息融合的架构设计。

### 计数实验与可视化：

在 106 张 MTDC-UAV 图像上进行计数评估，并与 TasselNetV2 进行比较。结果显示，FGLNet 在计数精度和鲁棒性上优于其他方法，参数规模为 0.77M，紧随其后的是 WheatLFANet。Faster R-CNN 在计数性能上表现较差，主要由于信息丢失，无法有效适应 UAV 图像。尽管提高分辨率有助于性能提升，但会带来较高的计算成本。通过使用特征金字塔网络（FPN）可进一步优化性能。
